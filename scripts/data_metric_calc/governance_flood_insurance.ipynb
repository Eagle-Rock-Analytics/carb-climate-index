{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cal-CRAI metric calculation for flood insurance policies\n",
    "* Enrollment in national flood insurance program -- community preparedness\n",
    "* num. of NFIP participants -- personal preparedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T14:59:45.465796Z",
     "iopub.status.busy": "2024-06-28T14:59:45.465087Z",
     "iopub.status.idle": "2024-06-28T14:59:46.216621Z",
     "shell.execute_reply": "2024-06-28T14:59:46.216031Z",
     "shell.execute_reply.started": "2024-06-28T14:59:45.465761Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import geopandas as gpd\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "\n",
    "from scripts.utils.file_helpers import pull_csv_from_directory, upload_csv_aws, filter_counties\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T14:59:46.626356Z",
     "iopub.status.busy": "2024-06-28T14:59:46.625218Z",
     "iopub.status.idle": "2024-06-28T14:59:47.564525Z",
     "shell.execute_reply": "2024-06-28T14:59:47.563798Z",
     "shell.execute_reply.started": "2024-06-28T14:59:46.626319Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '2a_subset/governance/community_preparedness/fema/nfip_community_status/fema_community_status_subset.csv'\n",
    "\n",
    "pull_csv_from_directory(bucket_name, aws_dir, search_zipped=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric 1:\n",
    "* Enrollment in national flood insurance program -- community preparedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T14:59:47.997355Z",
     "iopub.status.busy": "2024-06-28T14:59:47.996518Z",
     "iopub.status.idle": "2024-06-28T14:59:48.029682Z",
     "shell.execute_reply": "2024-06-28T14:59:48.029201Z",
     "shell.execute_reply.started": "2024-06-28T14:59:47.997307Z"
    }
   },
   "outputs": [],
   "source": [
    "community_flood_insurance_data = pd.read_csv('fema_community_status_subset.csv')\n",
    "print(len(community_flood_insurance_data))\n",
    "community_flood_insurance_data.head(5)\n",
    "# os.remove('fema_community_status_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T15:00:47.100499Z",
     "iopub.status.busy": "2024-06-28T15:00:47.099753Z",
     "iopub.status.idle": "2024-06-28T15:00:47.112023Z",
     "shell.execute_reply": "2024-06-28T15:00:47.110728Z",
     "shell.execute_reply.started": "2024-06-28T15:00:47.100467Z"
    }
   },
   "outputs": [],
   "source": [
    "community_flood_insurance_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the columns and entries within for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T15:00:49.559883Z",
     "iopub.status.busy": "2024-06-28T15:00:49.559169Z",
     "iopub.status.idle": "2024-06-28T15:00:49.596300Z",
     "shell.execute_reply": "2024-06-28T15:00:49.595624Z",
     "shell.execute_reply.started": "2024-06-28T15:00:49.559850Z"
    }
   },
   "outputs": [],
   "source": [
    "community_flood_insurance_data.columns = community_flood_insurance_data.columns.str.lower()\n",
    "community_flood_insurance_data = community_flood_insurance_data.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "community_flood_insurance_data['county'] = community_flood_insurance_data['county'].str.replace(' county', '', case=False)\n",
    "\n",
    "community_flood_insurance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = community_flood_insurance_data['communityname'].unique()\n",
    "unique_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilize the communityname column's astrisk within its entries, which indicate a total communities nfip involvement\n",
    "* look at just entries with the astrisk and identify counties with zero nfip participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions\n",
    "condition_1 = community_flood_insurance_data['communityname'].str.endswith('*')\n",
    "condition_2 = community_flood_insurance_data['communityname'].str.lower() == 'san francisco, city and county of'\n",
    "\n",
    "# Combine the conditions using the | (or) operator\n",
    "isolated_flood_insurance_counties = community_flood_insurance_data[condition_1 | condition_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T15:49:43.376640Z",
     "iopub.status.busy": "2024-06-28T15:49:43.375953Z",
     "iopub.status.idle": "2024-06-28T15:49:43.386621Z",
     "shell.execute_reply": "2024-06-28T15:49:43.385373Z",
     "shell.execute_reply.started": "2024-06-28T15:49:43.376607Z"
    }
   },
   "outputs": [],
   "source": [
    "len(isolated_flood_insurance_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify counties with no participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T15:40:17.624820Z",
     "iopub.status.busy": "2024-06-28T15:40:17.623700Z",
     "iopub.status.idle": "2024-06-28T15:40:17.645506Z",
     "shell.execute_reply": "2024-06-28T15:40:17.644759Z",
     "shell.execute_reply.started": "2024-06-28T15:40:17.624757Z"
    }
   },
   "outputs": [],
   "source": [
    "isolated_flood_insurance_counties.loc[isolated_flood_insurance_counties.participatinginnfip == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate relevant columns and adjust the entries within for increased transparency\n",
    "* remove astrisks\n",
    "* rename communityname column to county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T15:05:22.695701Z",
     "iopub.status.busy": "2024-06-28T15:05:22.694579Z",
     "iopub.status.idle": "2024-06-28T15:05:22.716612Z",
     "shell.execute_reply": "2024-06-28T15:05:22.715938Z",
     "shell.execute_reply.started": "2024-06-28T15:05:22.695638Z"
    }
   },
   "outputs": [],
   "source": [
    "flood_insurance_counties = isolated_flood_insurance_counties[['communityname', 'participatinginnfip']].copy()\n",
    "flood_insurance_counties['communityname'] = flood_insurance_counties['communityname'].str.replace(' county *', '')\n",
    "flood_insurance_counties['communityname'] = flood_insurance_counties['communityname'].str.replace(' county*', '')\n",
    "flood_insurance_counties['communityname'] = flood_insurance_counties['communityname'].str.replace(', city and county of', '')\n",
    "\n",
    "flood_insurance_counties = flood_insurance_counties.rename(columns={'communityname':'county', 'participatinginnfip':'nfip_participation'})\n",
    "\n",
    "flood_insurance_counties.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the original dataset to identify how many tribal participation entries there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_checking = community_flood_insurance_data[community_flood_insurance_data['tribal'] > 0]\n",
    "tribe_checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As there are only three separate counties with tribal nfip participation, we can manually add the flag for participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_flood_metric = flood_insurance_counties\n",
    "# Add new column with default value\n",
    "community_flood_metric['at_least_one_tribe_enrolled_within_county'] = 0\n",
    "\n",
    "# List of specified counties to set to 1\n",
    "specified_counties = ['lake', 'san bernardino', 'riverside']\n",
    "\n",
    "# Update the 'specified_county' column to 1 for specified counties\n",
    "community_flood_metric.loc[community_flood_metric['county'].isin(specified_counties), 'at_least_one_tribe_enrolled_within_county'] = 1\n",
    "community_flood_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dataset with California census tract data, assigning values to tracts within its respective county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "ca_tract_county = \"s3://ca-climate-index/0_map_data/ca_tracts_county.csv\"\n",
    "ca_tract_county = gpd.read_file(ca_tract_county)\n",
    "ca_tract_county = ca_tract_county.drop(columns={'field_1', 'geometry'})\n",
    "ca_tract_county.columns = ca_tract_county.columns.str.lower()\n",
    "ca_tract_county = ca_tract_county.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "ca_tract_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flood_community_metric = pd.merge(ca_tract_county, community_flood_metric, on='county', how='left')\n",
    "\n",
    "# Move column 'nfip_participation' to the end\n",
    "column_to_move = 'nfip_participation'\n",
    "ca_flood_community_metric = ca_flood_community_metric[[col for col in ca_flood_community_metric.columns if col != column_to_move] + [column_to_move]]\n",
    "\n",
    "# remove leading 0's from tract column\n",
    "ca_flood_community_metric['tract'] = ca_flood_community_metric['tract'].str.lstrip('0')\n",
    "\n",
    "print(len(ca_flood_community_metric))\n",
    "ca_flood_community_metric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a csv for upload to s3 bucket\n",
    "ca_flood_community_metric.to_csv('governance_community_flood_participation_metric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric two:\n",
    "* num. of NFIP participants -- personal preparedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:09:22.898185Z",
     "iopub.status.busy": "2024-06-28T16:09:22.896929Z",
     "iopub.status.idle": "2024-06-28T16:12:38.298392Z",
     "shell.execute_reply": "2024-06-28T16:12:38.297814Z",
     "shell.execute_reply.started": "2024-06-28T16:09:22.898117Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "# this dataset is quite large\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '1_pull_data/governance/personal_preparedness/fema/fema_fima_nfip_policies/fema_flood_redacted_policies.csv'\n",
    "\n",
    "pull_csv_from_directory(bucket_name, aws_dir, search_zipped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:12:38.299709Z",
     "iopub.status.busy": "2024-06-28T16:12:38.299535Z",
     "iopub.status.idle": "2024-06-28T16:13:00.548436Z",
     "shell.execute_reply": "2024-06-28T16:13:00.548081Z",
     "shell.execute_reply.started": "2024-06-28T16:12:38.299699Z"
    }
   },
   "outputs": [],
   "source": [
    "fema_flood_policy_data = pd.read_csv('fema_flood_redacted_policies.csv')\n",
    "print(len(fema_flood_policy_data))\n",
    "# os.remove('fema_flood_redacted_policies.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "fema_flood_policy_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:13:00.549004Z",
     "iopub.status.busy": "2024-06-28T16:13:00.548902Z",
     "iopub.status.idle": "2024-06-28T16:13:00.552041Z",
     "shell.execute_reply": "2024-06-28T16:13:00.551673Z",
     "shell.execute_reply.started": "2024-06-28T16:13:00.548995Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the datasets columns\n",
    "fema_flood_policy_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:13:00.553282Z",
     "iopub.status.busy": "2024-06-28T16:13:00.553147Z",
     "iopub.status.idle": "2024-06-28T16:13:03.072133Z",
     "shell.execute_reply": "2024-06-28T16:13:03.071762Z",
     "shell.execute_reply.started": "2024-06-28T16:13:00.553271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the number of non-NaN values in each column\n",
    "non_nan_counts = fema_flood_policy_data.count()\n",
    "\n",
    "# Set display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display the counts\n",
    "print(non_nan_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate the dataset to policies that expired past 2023 for recent indications of flood coverage\n",
    "* also get rid of a likely typo for year 2203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:14:47.659971Z",
     "iopub.status.busy": "2024-06-28T16:14:47.658908Z",
     "iopub.status.idle": "2024-06-28T16:14:47.992323Z",
     "shell.execute_reply": "2024-06-28T16:14:47.991951Z",
     "shell.execute_reply.started": "2024-06-28T16:14:47.659914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the 'policyTerminationDate' column to datetime\n",
    "fema_flood_policy_data['policyTerminationDate'] = pd.to_datetime(fema_flood_policy_data['policyTerminationDate'], errors='coerce')\n",
    "\n",
    "# Create a mask for dates after 2023\n",
    "mask = (fema_flood_policy_data['policyTerminationDate'].dt.year > 2023) & (fema_flood_policy_data['policyTerminationDate'].dt.year != 2203)\n",
    "\n",
    "# Apply the mask to filter the data\n",
    "current_flood_policy = fema_flood_policy_data[mask]\n",
    "\n",
    "print(len(current_flood_policy))\n",
    "current_flood_policy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T16:15:45.182880Z",
     "iopub.status.busy": "2024-06-28T16:15:45.182189Z",
     "iopub.status.idle": "2024-06-28T16:15:45.196547Z",
     "shell.execute_reply": "2024-06-28T16:15:45.195582Z",
     "shell.execute_reply.started": "2024-06-28T16:15:45.182848Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at how many unique census tracts are within the dataset\n",
    "len(current_flood_policy['censusTract'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant columns, adjust tract column entries to match Cal-CRAIs standardized tract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['censusTract', 'countyCode', 'policyTerminationDate', 'id']\n",
    "\n",
    "current_flood_policy_filter = current_flood_policy[column_list]\n",
    "current_flood_policy_filter['censusTract'] = current_flood_policy_filter['censusTract'].apply(lambda x: '0' + str(int(x)) if pd.notna(x) else x)\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "print(len(current_flood_policy_filter))\n",
    "current_flood_policy_filter.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates if applicable, based on location, flood policy ID, and policy termination date\n",
    "* no rows dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_flood_policy_filter = current_flood_policy_filter.drop_duplicates(subset=['id', 'policyTerminationDate', 'censusTract'])\n",
    "print(len(current_flood_policy_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_flood_policy_count = current_flood_policy_filter['censusTract'].value_counts().reset_index()\n",
    "tract_flood_policy_count = tract_flood_policy_count.rename(columns={'count':'num_flood_policies', 'censusTract':'tract'})\n",
    "\n",
    "print(len(tract_flood_policy_count))\n",
    "tract_flood_policy_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CA tract and county dataset and merge it with our flood policy data\n",
    "* merge based on county column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "ca_tract_county = \"s3://ca-climate-index/0_map_data/ca_tracts_county.csv\"\n",
    "ca_tract_county = gpd.read_file(ca_tract_county)\n",
    "ca_tract_county = ca_tract_county.drop(columns={'field_1', 'geometry'})\n",
    "ca_tract_county.columns = ca_tract_county.columns.str.lower()\n",
    "ca_tract_county = ca_tract_county.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "ca_tract_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_policy_merge = pd.merge(ca_tract_county, tract_flood_policy_count, on='tract', how='left')\n",
    "tract_policy_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trinity = tract_policy_merge[tract_policy_merge['county'] == 'trinity']\n",
    "trinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of policies when grouping the dataset by county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_flood_policy_count = tract_policy_merge.groupby('county', as_index=False)['num_flood_policies'].sum()\n",
    "county_flood_policy_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge back with the tract/county dataset, this time merging to the CA tract dataset to attribute the counts to each CA tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_flood_policy_county_metric = pd.merge(ca_tract_county, county_flood_policy_count, on='county', how='left')\n",
    "\n",
    "# remove leading 0's from tract column\n",
    "ca_flood_policy_county_metric['tract'] = ca_flood_policy_county_metric['tract'].str.lstrip('0')\n",
    "\n",
    "print(len(ca_flood_policy_county_metric))\n",
    "ca_flood_policy_county_metric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a csv for upload to s3 bucket\n",
    "ca_flood_policy_county_metric.to_csv('governance_flood_policy_metric.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@append_metadata\n",
    "def flood_metrics_upload(input_csv, export=False, varname=''):\n",
    "    '''\n",
    "    Uploads flood related metrics within the CAL-CRAI governance domain to S3 bucket. The metrics are:\n",
    "    \n",
    "    * whether a county is enrolled in the national flood insurance policy (NFIP)\n",
    "    * # of national flood insurance program participants per county\n",
    "    \n",
    "    Data for these metrics were sourced from the Federal Emergency Management Agency at:\n",
    "    https://www.fema.gov/about/openfema/data-sets#nfip\n",
    "\n",
    "    Note: For the number of participants per county, we were unable to distinguish policies\n",
    "    per resident/house/rental/business and get proportions of policies to county population.\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    Relevant data columns were isolated, some were renamed and adjusted.\n",
    "    Duplicate entries based on location were dropped.\n",
    "    Columns were created to count or flag desired metric output at the county level.\n",
    "    Data was then merged to California county and tract data to eventually extrapolate results to CA tracts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_csv: string\n",
    "        csv PSPS data \n",
    "    export: True/False boolean\n",
    "        False = will not upload resulting df containing CAL CRAI flood metric to AWS\n",
    "        True = will upload resulting df containing CAL CRAI flood metric to AWS\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    governance_flood_insurance.ipynb\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    '''\n",
    "    print('Data transformation: relevant columns were isolated and renamed')\n",
    "    print('Data transformation: duplicate entries by location were dropped.')\n",
    "    print('Data transformation: number of rows per county were totalled.')\n",
    "    print('Data transformation: data was merged with CA county and tract data to generate final metric data.') \n",
    " \n",
    "    if export == True:\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [input_csv]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{input_csv} uploaded to AWS.')\n",
    "    \n",
    "        #if os.path.exists(input_csv):\n",
    "    #   os.remove(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csvs = ['governance_community_flood_participation_metric.csv',\n",
    "            'governance_flood_policy_metric.csv']\n",
    "\n",
    "varnames = ['governance_fema_communitiy_flood',\n",
    "            'governance_fema_flood_policy_participants']\n",
    "\n",
    "# Process the data and export\n",
    "for input_csv, varname in zip(input_csvs, varnames):\n",
    "    flood_metrics_upload(input_csv, export=True, varname='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
