{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal-CRAI Metric Calculation\n",
    "Domain: Built Environment \\\n",
    "Indicator: Utilities\n",
    "\n",
    "This notebook calculates 1 metric,  sourced from the California energy commission:\n",
    "* Metric 1: number of power plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:04.416980Z",
     "iopub.status.busy": "2024-06-03T15:06:04.415884Z",
     "iopub.status.idle": "2024-06-03T15:06:06.800376Z",
     "shell.execute_reply": "2024-06-03T15:06:06.799751Z",
     "shell.execute_reply.started": "2024-06-03T15:06:04.416921Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import io\n",
    "import geopandas as gpd\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import pull_gpkg_from_directory, upload_csv_aws\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New function to pull .gpkg files\n",
    "* if good, will move to utils or can update existing pull function to handle different file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:14.111872Z",
     "iopub.status.busy": "2024-06-03T15:06:14.110342Z",
     "iopub.status.idle": "2024-06-03T15:06:16.479920Z",
     "shell.execute_reply": "2024-06-03T15:06:16.479017Z",
     "shell.execute_reply.started": "2024-06-03T15:06:14.111812Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '2b_reproject/built_environment/utilities/ca_energy_commission/'\n",
    "\n",
    "pull_gpkg_from_directory(bucket_name, aws_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:16.483017Z",
     "iopub.status.busy": "2024-06-03T15:06:16.482506Z",
     "iopub.status.idle": "2024-06-03T15:06:21.190629Z",
     "shell.execute_reply": "2024-06-03T15:06:21.190306Z",
     "shell.execute_reply.started": "2024-06-03T15:06:16.482979Z"
    }
   },
   "outputs": [],
   "source": [
    "power_plants = gpd.read_file('built_cec_power_plants.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:21.191407Z",
     "iopub.status.busy": "2024-06-03T15:06:21.191259Z",
     "iopub.status.idle": "2024-06-03T15:06:21.209774Z",
     "shell.execute_reply": "2024-06-03T15:06:21.209420Z",
     "shell.execute_reply.started": "2024-06-03T15:06:21.191391Z"
    }
   },
   "outputs": [],
   "source": [
    "power_plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering to relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:29.901742Z",
     "iopub.status.busy": "2024-06-03T15:06:29.901011Z",
     "iopub.status.idle": "2024-06-03T15:06:29.935537Z",
     "shell.execute_reply": "2024-06-03T15:06:29.935029Z",
     "shell.execute_reply.started": "2024-06-03T15:06:29.901703Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_power_plants = power_plants[['PlantName', 'CECPlantID', 'County','geometry']]\n",
    "\n",
    "# Establish columns to check for duplicates\n",
    "columns_to_check = ['CECPlantID']\n",
    "\n",
    "# Find duplicate rows based on specified columns\n",
    "duplicate_mask = filtered_power_plants.duplicated(subset=columns_to_check, keep='first')\n",
    "\n",
    "# Filter rows based on condition on the numeric column\n",
    "cleaned_power_plants = filtered_power_plants[~(duplicate_mask)]\n",
    "\n",
    "cleaned_power_plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below counts the number of entries per selected county. This is used to check that counties have the same number of power plants after the spatial join done next. The numbers should match as we have done all duplicate cleaning above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:42.385724Z",
     "iopub.status.busy": "2024-06-03T15:06:42.384977Z",
     "iopub.status.idle": "2024-06-03T15:06:42.406080Z",
     "shell.execute_reply": "2024-06-03T15:06:42.404969Z",
     "shell.execute_reply.started": "2024-06-03T15:06:42.385687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where 'CECPlantID' column exists\n",
    "checkin = cleaned_power_plants.dropna(subset=['CECPlantID'])\n",
    "county_count = checkin['County'] == 'Kern'\n",
    "print('Number of entries of designated county:',len(county_count[county_count]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull tract data and isolate relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:06:49.797389Z",
     "iopub.status.busy": "2024-06-03T15:06:49.796673Z",
     "iopub.status.idle": "2024-06-03T15:07:04.251204Z",
     "shell.execute_reply": "2024-06-03T15:07:04.250799Z",
     "shell.execute_reply.started": "2024-06-03T15:06:49.797351Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:07:04.252681Z",
     "iopub.status.busy": "2024-06-03T15:07:04.252557Z",
     "iopub.status.idle": "2024-06-03T15:07:04.269386Z",
     "shell.execute_reply": "2024-06-03T15:07:04.269032Z",
     "shell.execute_reply.started": "2024-06-03T15:07:04.252671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of the relevant columns from ca_boundaries\n",
    "filtered_ca_boundaries = ca_boundaries[['GEOID', 'geometry']].copy()\n",
    "\n",
    "# Rename the 'GEOID' column to 'tract'\n",
    "filtered_ca_boundaries.rename(columns={'GEOID': 'tract'}, inplace=True)\n",
    "\n",
    "# Remove the first character from the 'tract' column\n",
    "filtered_ca_boundaries['tract'] = filtered_ca_boundaries['tract'].str[1:]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "filtered_ca_boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial join the power plant data with the ca boundaries so we can attribute counties and tracts to power plants\n",
    "* the result has an extra thousand rows due to duplicate tract/geometries, this is addressed when grouping by tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:08:24.739722Z",
     "iopub.status.busy": "2024-06-03T15:08:24.738875Z",
     "iopub.status.idle": "2024-06-03T15:08:24.842328Z",
     "shell.execute_reply": "2024-06-03T15:08:24.841916Z",
     "shell.execute_reply.started": "2024-06-03T15:08:24.739681Z"
    }
   },
   "outputs": [],
   "source": [
    "ca_power_plants = gpd.sjoin(cleaned_power_plants, filtered_ca_boundaries, how='right', predicate='within')\n",
    "ca_power_plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another checker to count how many of a given tract show up in the dataset (that also have a CECPlantID) before we merge them and get the final counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:08:31.601647Z",
     "iopub.status.busy": "2024-06-03T15:08:31.600927Z",
     "iopub.status.idle": "2024-06-03T15:08:31.621383Z",
     "shell.execute_reply": "2024-06-03T15:08:31.620379Z",
     "shell.execute_reply.started": "2024-06-03T15:08:31.601609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where 'CECPlantID' column exists\n",
    "filtered_df = ca_power_plants.dropna(subset=['CECPlantID'])\n",
    "tract_check = filtered_df['tract'] == '6085505010'\n",
    "print('Number of entries of designated tract:',len(tract_check[tract_check]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by tract as long as CECPlantID is not NaN and summing those so we have number of plants per tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:08:39.601515Z",
     "iopub.status.busy": "2024-06-03T15:08:39.600747Z",
     "iopub.status.idle": "2024-06-03T15:08:40.201067Z",
     "shell.execute_reply": "2024-06-03T15:08:40.200696Z",
     "shell.execute_reply.started": "2024-06-03T15:08:39.601476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 'tract' and count the number of entries where 'CECPlantID' exists\n",
    "tract_power_counts = ca_power_plants.groupby('tract')['CECPlantID'].apply(lambda x: x.notnull().sum()).reset_index(name='Power_Plant_Count')\n",
    "\n",
    "# Output the result\n",
    "tract_power_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:20:31.702778Z",
     "iopub.status.busy": "2024-06-03T15:20:31.701977Z",
     "iopub.status.idle": "2024-06-03T15:20:31.712670Z",
     "shell.execute_reply": "2024-06-03T15:20:31.711534Z",
     "shell.execute_reply.started": "2024-06-03T15:20:31.702734Z"
    }
   },
   "outputs": [],
   "source": [
    "tract_power_counts['Power_Plant_Count'].min(), tract_power_counts['Power_Plant_Count'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have merged, we can check the df's counts per given tract and see if it matches with our checker above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:09:16.411240Z",
     "iopub.status.busy": "2024-06-03T15:09:16.410414Z",
     "iopub.status.idle": "2024-06-03T15:09:16.429117Z",
     "shell.execute_reply": "2024-06-03T15:09:16.427893Z",
     "shell.execute_reply.started": "2024-06-03T15:09:16.411197Z"
    }
   },
   "outputs": [],
   "source": [
    "tract_value = '6085505010'\n",
    "filtered_entries = tract_power_counts[tract_power_counts['tract'] == tract_value]\n",
    "print(filtered_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T15:09:19.515704Z",
     "iopub.status.busy": "2024-06-03T15:09:19.514854Z",
     "iopub.status.idle": "2024-06-03T15:09:19.550459Z",
     "shell.execute_reply": "2024-06-03T15:09:19.549640Z",
     "shell.execute_reply.started": "2024-06-03T15:09:19.515665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 'tract' and count the number of entries where 'CECPlantID' exists\n",
    "county_power_counts = ca_power_plants.groupby('County')['CECPlantID'].apply(lambda x: x.notnull().sum()).reset_index(name='Power_Plant_Count')\n",
    "county_power_counts = county_power_counts[1:]\n",
    "\n",
    "# Output the result\n",
    "county_power_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@append_metadata\n",
    "def calc_power_plant(df, export=False, export_filename=None, varname = ''):\n",
    "    '''\n",
    "    Calculates the number of power plants per California tract and county. \n",
    "    Data is sourced from the California Energy Commission (CEC): \n",
    "    https://cecgis-caenergy.opendata.arcgis.com/datasets/CAEnergy::california-power-plants/about\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    Geometry columns were merged between California 2021 tiger census tract data \n",
    "    and CEC power plant data to attribute power plants to census tracts. \n",
    "    Duplicate entries were removed based on matching CECPlantID. \n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    built_power_plant.ipynb\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: string\n",
    "        the dataframe containing the power plant data\n",
    "    export: True/False boolian\n",
    "        False = will not upload resulting df containing the power plant metric to AWS\n",
    "        True = will upload resulting df containing the power plant metric to AWS\n",
    "    export_filename: string\n",
    "        name of the csv file to be uploaded to AWS\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    '''   \n",
    "    print('Data transformation: isolate relevant columns for metric calculation.')\n",
    "    print('Data transformation: check for duplicate plant IDs using \"CECPlantID\" and retain single count for identical plants.')\n",
    "    filtered_power_plants = df[['PlantName', 'CECPlantID', 'County','geometry']]\n",
    "\n",
    "    # Establish columns to check for duplicates\n",
    "    columns_to_check = ['CECPlantID']\n",
    "\n",
    "    # Find duplicate rows based on specified columns\n",
    "    duplicate_mask = filtered_power_plants.duplicated(subset=columns_to_check, keep='first')\n",
    "\n",
    "    # Filter rows based on condition on the numeric column\n",
    "    cleaned_power_plants = filtered_power_plants[~(duplicate_mask)]\n",
    "    \n",
    "    # read in CA census tiger file\n",
    "    census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "    ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "\n",
    "    # Create a copy of the relevant columns from ca_boundaries\n",
    "    filtered_ca_boundaries = ca_boundaries[['GEOID', 'geometry']].copy()  # Added parentheses to the copy method\n",
    "\n",
    "    # Rename the 'GEOID' column to 'tract'\n",
    "    filtered_ca_boundaries = filtered_ca_boundaries.rename(columns={'GEOID': 'tract'})  # Corrected the rename method call\n",
    "\n",
    "    # Remove the first character from the 'tract' column\n",
    "    filtered_ca_boundaries['tract'] = filtered_ca_boundaries['tract'].str[1:]\n",
    "    print('Data transformation: merge geometries with California tiger census tract data (2021).')\n",
    "\n",
    "    ca_power_plants = gpd.sjoin(cleaned_power_plants, filtered_ca_boundaries, how='right', predicate='within')\n",
    "\n",
    "    print('Data transformation: make new dataframe by grouping data by census tracts and sum multiple entries')\n",
    "    # Group by 'tract' and count the number of entries where 'CECPlantID' exists\n",
    "    tract_power_counts = ca_power_plants.groupby('tract')['CECPlantID'].apply(lambda x: x.notnull().sum()).reset_index(name='power_plant_count')\n",
    "\n",
    "    # export to csv and upload to AWS\n",
    "    if export == True:\n",
    "        tract_power_counts.to_csv(export_filename)\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [export_filename]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "        os.remove('built_cec_power_plants.gpkg') # remove from local to clear up directory\n",
    "        os.remove(export_filename[0])\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{export_filename} uploaded to AWS.')\n",
    "\n",
    "\n",
    "    return tract_power_counts # returns df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '2b_reproject/built_environment/utilities/ca_energy_commission/'\n",
    "pull_gpkg_from_directory(bucket_name, aws_dir)\n",
    "\n",
    "power_plants = gpd.read_file('built_cec_power_plants.gpkg')\n",
    "\n",
    "calc_power_plant(power_plants, export=True, export_filename = 'built_power_plant_metric.csv',\n",
    "                 varname = 'built_cec_power_plants')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
