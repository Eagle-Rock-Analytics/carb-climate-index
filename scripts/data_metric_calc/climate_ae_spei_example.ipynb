{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a184be96-f61f-4546-8ff2-1cb43042623b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:15:17.898163Z",
     "iopub.status.busy": "2024-01-04T22:15:17.897747Z",
     "iopub.status.idle": "2024-01-04T22:15:17.902224Z",
     "shell.execute_reply": "2024-01-04T22:15:17.901452Z",
     "shell.execute_reply.started": "2024-01-04T22:15:17.898091Z"
    }
   },
   "source": [
    "## Cal-CRAI metric: SPEI\n",
    "This notebook briefly walks through how to calculate the `% change in probability that a water year is classified as having Moderate, Severe, or Extreme drought conditions via Standardized Precipitation Evapotranspiration Index (SPEI)` metric with FFWI data from the Cal-Adapt: Analytics Engine. This notebook may be expanded upon for inclusion in cae-notebooks in the future. **SPEI** will be added as an available data metric to climakitae as a part of this development. \n",
    "\n",
    "**Order of operations:**\n",
    "\n",
    "1. Read data in\n",
    "2. Calculate base function (FFWI, SPEI, warm nights, etc.)\n",
    "3. Calculate chronic\n",
    "4. Calculate delta signal\n",
    "5. Reprojection to census tracts\n",
    "6. Min-max standardization\n",
    "7. Export data\n",
    "8. Generate metadata (via Cal-CRAI environment, not AE)\n",
    "\n",
    "**Runtime**: This notebook takes approximately ~1 hours to run due to data size, warming levels, and reprojection steps.\n",
    "\n",
    "**References**: \n",
    "1. S. M. Vicente-Serrano, S. Beguería, and J. I. López-Moreno, “A Multiscalar Drought Index Sensitive to Global Warming: The Standardized Precipitation Evapotranspiration Index,” Journal of Climate, vol. 23, no. 7, pp. 1696–1718, Apr. 2010, doi: 10.1175/2009JCLI2909.1.\n",
    "2. George H. Hargreaves and Zohrab A. Samani. Reference Crop Evapotranspiration from Temperature. Applied engineering in agriculture, 1(2):96–99, 1985. PubAg AGID: 5662005. doi:10.13031/2013.26773\n",
    "3. https://xclim.readthedocs.io/en/stable/indices.html#xclim.indices.potential_evapotranspiration\n",
    "4. https://xclim.readthedocs.io/en/stable/indices.html#xclim.indices.standardized_precipitation_evapotranspiration_index\n",
    "\n",
    "Variables:\n",
    "1. Daily Water Budget, which is the difference between:\n",
    "    - Daily precipitation and\n",
    "    - Daily potential evapotranspiration, derived from some combo of the following, depending on method:\n",
    "       - Daily Min Temperature\n",
    "       - Daily Max Temperature\n",
    "       - Daily Mean Temperature\n",
    "       - Relative Humidity\n",
    "       - Surface Downwelling Shortwave Radiation\n",
    "       - Surface Upwelling Shortwave Radiation\n",
    "       - Surface Downwelling Longwave Radiation\n",
    "       - Surface Upwelling Longwave Radiation\n",
    "       - 10m Wind Speed\n",
    "       \n",
    "       *we will be using the Hargreaves and Samani (1985) version, so we use daily min and max temperatures*\n",
    "2. Calibration Daily Water Budget\n",
    "    - Can be computed from Daily Water Budget over a given \"calibration\" time period\n",
    "    \n",
    "### Step 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ffe7e6-5b3e-4e62-9ea2-7f8a39e3744f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "from climakitae.explore import warming_levels \n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.util.utils import read_ae_colormap\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from xclim.indices import (\n",
    "    potential_evapotranspiration, \n",
    "    standardized_precipitation_evapotranspiration_index,\n",
    "    standardized_precipitation_index\n",
    ")\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# import s3fs\n",
    "# import boto3\n",
    "# sys.path.append(os.path.expanduser('../../'))\n",
    "# from scripts.utils.file_helpers import upload_csv_aws\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "crs = ccrs.LambertConformal(\n",
    "    central_longitude=-70, \n",
    "    central_latitude=38, \n",
    "    false_easting=0.0, \n",
    "    false_northing=0.0,  \n",
    "    standard_parallels=[30, 60], \n",
    "    globe=None, \n",
    "    # cutoff=-30\n",
    ")\n",
    "div_cmap = read_ae_colormap(\n",
    "    cmap=\"ae_diverging\", cmap_hex=True\n",
    ")  \n",
    "cmap = read_ae_colormap(\n",
    "    cmap=\"ae_orange\", cmap_hex=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65eec21f-937c-43f5-b667-518a13dc42c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_wl = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_MIROC6_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_TaiESM1_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "]\n",
    "sims_hist = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1',\n",
    "    'WRF_MIROC6_r1i1p1f1', \n",
    "    'WRF_EC-Earth3_r1i1p1f1',\n",
    "    'WRF_TaiESM1_r1i1p1f1', \n",
    "]\n",
    "\n",
    "sim_name_dict = dict(zip(sims_wl,sims_hist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0aba666-bf6c-40cb-9556-56f05b478f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject_to_tracts(ds_delta, ca_boundaries):\n",
    "    # this step takes about 12 minutes with 3km data (~1 min with 9km data)\n",
    "    df = ds_delta.to_dataframe().reset_index()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.x,df.y))\n",
    "    gdf = gdf.set_crs(crs)\n",
    "    gdf = gdf.to_crs(ca_boundaries.crs)\n",
    "    \n",
    "    ca_boundaries = ca_boundaries.set_index(['GEOID'])    \n",
    "\n",
    "    clipped_gdf = gpd.sjoin_nearest(ca_boundaries, gdf, how='left')\n",
    "    clipped_gdf = clipped_gdf.drop(['index_right'], axis=1)\n",
    "    clipped_gdf = clipped_gdf.reset_index()[\n",
    "        [\"GEOID\",f\"{ds_delta.name}\",\"geometry\"]]\n",
    "    ### some coastal tracts do not contain any land grid cells ###\n",
    "    \n",
    "    # aggregate the gridded data to the tract level\n",
    "    clipped_gdf_diss = clipped_gdf.reset_index().dissolve(\n",
    "        by='GEOID', aggfunc='mean')\n",
    "    clipped_gdf_diss = clipped_gdf_diss.rename(\n",
    "        columns={f\"{ds_delta.name}_right\":\n",
    "                 ds_delta.name}\n",
    "    )\n",
    "    \n",
    "    # separate tracts with data from tracts without data\n",
    "    clipped_gdf_nan = clipped_gdf_diss[np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_nan = clipped_gdf_nan[[\"geometry\",ds_delta.name]]\n",
    "    clipped_gdf_valid = clipped_gdf_diss[~np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_valid = clipped_gdf_valid[[\"geometry\",ds_delta.name]]\n",
    "\n",
    "    # compute the centroid of each tract\n",
    "    clipped_gdf_nan[\"centroid\"] = clipped_gdf_nan.centroid\n",
    "    clipped_gdf_nan = clipped_gdf_nan.set_geometry(\"centroid\")\n",
    "    clipped_gdf_valid[\"centroid\"] = clipped_gdf_valid.centroid\n",
    "    clipped_gdf_valid = clipped_gdf_valid.set_geometry(\"centroid\")\n",
    "    \n",
    "    # fill in missing tracts with values from the closest tract\n",
    "    # in terms of distance between the tract centroids\n",
    "    clipped_gdf_filled = clipped_gdf_nan.sjoin_nearest(clipped_gdf_valid, how='left')\n",
    "    clipped_gdf_filled = clipped_gdf_filled[[\"geometry_left\",f\"{ds_delta.name}_right\"]]\n",
    "    clipped_gdf_filled = clipped_gdf_filled.rename(columns={\n",
    "        \"geometry_left\":\"geometry\", f\"{ds_delta.name}_right\":ds_delta.name\n",
    "    })\n",
    "    clipped_gdf_valid = clipped_gdf_valid.drop(columns=\"centroid\")\n",
    " \n",
    "    # concatenate filled-in tracts with the original tract which had data\n",
    "    gdf_all_tracts = pd.concat([clipped_gdf_valid,clipped_gdf_filled])\n",
    "\n",
    "    return gdf_all_tracts\n",
    "\n",
    "\n",
    "def min_max_standardize(df, col):\n",
    "    '''\n",
    "    Calculates min and max values for specified columns, then calculates\n",
    "    min-max standardized values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        Input dataframe   \n",
    "    cols_to_run_on: list\n",
    "        List of columns to calculate min, max, and standardize\n",
    "    '''\n",
    "    max_value = df[col].max()\n",
    "    min_value = df[col].min()\n",
    "\n",
    "    # Get min-max values, standardize, and add columns to df\n",
    "    prefix = col # Extracting the prefix from the column name\n",
    "    df[f'{prefix}_min'] = min_value\n",
    "    df[f'{prefix}_max'] = max_value\n",
    "    df[f'{prefix}_min_max_standardized'] = ((df[col] - min_value) / (max_value - min_value))\n",
    "\n",
    "    # note to add checker to make sure new min_max column values arent < 0 > 1\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] < 0] = 0\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] > 1] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010e57d-e270-407c-97f9-92b54c4079f8",
   "metadata": {},
   "source": [
    "### Step 1: Retrieve data\n",
    "We need to calculate:\n",
    "* 30 year centered around 2.0C warming level (SSP3-7.0)\n",
    "* Historical baseline 1981-2010 (Historical Climate)\n",
    "\n",
    "Note: the 3km data is too large to work with for all of CA for warming level conditions. Working with 45km for now.\n",
    "\n",
    "#### Step 1a) Chronic data (2.0°C WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6376c591-2f19-45e5-a56a-4bb543ed8394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wl = warming_levels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b872f5-664f-4828-a2f5-1d75446855ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max air temperature\n",
    "wl.wl_params.timescale = \"daily\"\n",
    "wl.wl_params.downscaling_method = \"Dynamical\"\n",
    "wl.wl_params.resolution = '3 km'\n",
    "wl.wl_params.variable = 'Maximum air temperature at 2m'\n",
    "wl.wl_params.area_subset = \"CA counties\" ## just for testing\n",
    "wl.wl_params.cached_area = [\"Sacramento County\"] ## just for testing\n",
    "wl.wl_params.warming_levels = [\"2.0\"]\n",
    "wl.wl_params.anom = \"No\"\n",
    "wl.calculate()\n",
    "ds_maxT = wl.sliced_data[\"2.0\"] # grab 2.0 degC data\n",
    "ds_maxT = ds_maxT.sel(all_sims = list(sim_name_dict.keys()))\n",
    "ds_maxT = add_dummy_time_to_wl(ds_maxT) # add time dimension back in, as this is removed by WL and is required for xclim functionality\n",
    "\n",
    "# min air temperature\n",
    "wl.wl_params.variable = 'Minimum air temperature at 2m'\n",
    "wl.calculate()\n",
    "ds_minT = wl.sliced_data[\"2.0\"] # grab 2.0 degC data\n",
    "ds_minT = ds_minT.sel(all_sims = list(sim_name_dict.keys()))\n",
    "ds_minT = add_dummy_time_to_wl(ds_minT) # add time dimension back in, as this is removed by WL and is required for xclim functionality\n",
    "\n",
    "# precip\n",
    "wl.wl_params.variable = 'Precipitation (total)'\n",
    "wl.calculate()\n",
    "\n",
    "ds_precip = wl.sliced_data[\"2.0\"]\n",
    "ds_precip = ds_precip.sel(all_sims = list(sim_name_dict.keys()))\n",
    "ds_precip = add_dummy_time_to_wl(ds_precip)\n",
    "ds_precip = ds_precip.clip(min=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f12ccf1-b03e-42ca-8604-6651e936f12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Retrieve historical baseline data (1981-2010)\n",
    "selections = ck.Select()\n",
    "selections.timescale = 'daily'\n",
    "selections.variable = 'Maximum air temperature at 2m'\n",
    "selections.area_subset = \"CA counties\" ## just for testing\n",
    "selections.cached_area = [\"Sacramento County\"] ## just for testing\n",
    "selections.scenario_historical=['Historical Climate']\n",
    "selections.area_average = 'No'\n",
    "selections.time_slice = (1981,2010) \n",
    "selections.resolution = '3 km'\n",
    "max_t_hist = selections.retrieve()\n",
    "max_t_hist = max_t_hist.sel(simulation=sims_hist)\n",
    "\n",
    "# now min temperature\n",
    "selections.variable = 'Minimum air temperature at 2m'\n",
    "min_t_hist = selections.retrieve()\n",
    "min_t_hist = min_t_hist.sel(simulation=sims_hist)\n",
    "\n",
    "# also need precip\n",
    "selections.variable = 'Precipitation (total)'\n",
    "precip_hist = selections.retrieve()\n",
    "precip_hist = precip_hist.clip(min=1.)\n",
    "precip_hist = precip_hist.sel(simulation=sims_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e2f30-99ab-4381-a1c1-aa087b0ae219",
   "metadata": {},
   "source": [
    "## Step 2: Calculate metric\n",
    "* % change in probability that a water year is classified as having Moderate, Severe, or Extreme drought conditions via SPEI\n",
    "* GWL model-mean # drought years/30 - historical model-mean # drought years/30)is GWL model-mean # drought years/30 - historical model-mean # drought years/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c16759a-e9b6-443d-8eea-a8222a9fb574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_wb(tasmin, tasmax, precip):\n",
    "    # first calculate PET\n",
    "    pet = potential_evapotranspiration(tasmin=tasmin, tasmax=tasmax, method='HG85')\n",
    "    pet = pet * (60*60*24) # convert from per second to per day\n",
    "    pet.attrs['units'] = 'mm'\n",
    "    \n",
    "    # calculate water budget\n",
    "    wb = precip - pet\n",
    "    wb.attrs['units'] = 'mm/day'\n",
    "    \n",
    "    # handing for simulation/all_sims dimension between historical and wl data\n",
    "    da_list = []\n",
    "    \n",
    "    if 'simulation' in wb.dims:\n",
    "        for sim in wb.simulation.values:\n",
    "            da = wb.sel(simulation=sim)\n",
    "            wb_min = da.min().values\n",
    "            da = da+abs(wb_min)\n",
    "            da_list.append(da)\n",
    "    \n",
    "    elif 'all_sims' in wb.dims:\n",
    "        for sim in wb.all_sims.values:\n",
    "            da = wb.sel(all_sims=sim)\n",
    "            wb_min = da.min().values\n",
    "            da = da+abs(wb_min)\n",
    "            da_list.append(da)\n",
    "            \n",
    "    wb = xr.concat(da_list, dim='simulation')\n",
    "    wb = wb.chunk(dict(time=-1)).compute()\n",
    "    \n",
    "    return wb\n",
    "\n",
    "def calculate_spei(wb, wb_cal):\n",
    "    \n",
    "    # finally calculate 3 month SPEI\n",
    "    spei = standardized_precipitation_evapotranspiration_index(\n",
    "        wb=wb, \n",
    "        wb_cal=wb_cal,\n",
    "        freq='MS',\n",
    "        window=3,\n",
    "        dist='gamma',\n",
    "        method='APP',\n",
    "    )\n",
    "    \n",
    "    # assign water year coordinate\n",
    "    water_year = (spei.time.dt.month >= 10) + spei.time.dt.year\n",
    "    spei.coords['water_year'] = water_year\n",
    "    \n",
    "    return spei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b41c1c5-14a4-4fe7-b1c9-3ef8b2c4a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate water budget for historical data.\n",
    "# This will also serve as our calibration water budget for the warming levels data.\n",
    "wb_hist = calculate_wb(\n",
    "    tasmin = min_t_hist,\n",
    "    tasmax = max_t_hist,\n",
    "    precip = precip_hist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b570e8d-954b-4d80-8ac8-d468149608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate water budget for warming levels data.\n",
    "wb_wl = calculate_wb(\n",
    "    tasmin = ds_minT,\n",
    "    tasmax = ds_maxT,\n",
    "    precip = ds_precip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc578db-060d-4939-b28a-a776a49e2e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate historical SPEI using itself as the calibration water budget\n",
    "spei_hist = calculate_spei(\n",
    "    wb = wb_hist,\n",
    "    wb_cal = wb_hist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb35f6d-c639-404d-9195-a1cd9684a7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate warming levels SPEI using the historical water budget for the calibration water budget\n",
    "spei_wl = calculate_spei(\n",
    "    wb = wb_wl,\n",
    "    wb_cal = wb_hist\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2497c-eed1-42be-a3d7-b22d8fb23daf",
   "metadata": {},
   "source": [
    "Count number of water years featuring 6 or more months with SPEI < -1 (ie, 6 or more dry months in a year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c968152-195c-4591-8654-c857ccf71e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now calculate number of drought years from SPEI\n",
    "def drought_yrs(spei):   \n",
    "    mod_dry_thresh = -1.0\n",
    "    drought_duration_thresh = 6 # 3 months = short-term drought; 6+ = long-term\n",
    "    num_dry_months = (spei <= mod_dry_thresh).groupby('water_year').sum('time')\n",
    "    num_dry_years = (num_dry_months >= drought_duration_thresh).sum('water_year')\n",
    "    # take model average\n",
    "    num_dry_years_avg = num_dry_years.mean(dim=['simulation']).squeeze() \n",
    "    \n",
    "    # make a nan mask\n",
    "    nan_mask = spei.isel(simulation=0, time=-1).squeeze()\n",
    "    # nan out grid points outside of the domain\n",
    "    num_dry_years_avg = xr.where(np.isnan(nan_mask), x=np.nan, y=num_dry_years_avg)\n",
    "    \n",
    "    return num_dry_years_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76cb1d3f-ec85-49c1-b8d3-e1f3e2405ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of drought years for historical and warming level periods\n",
    "drought_yrs_hist = drought_yrs(spei_hist)\n",
    "drought_yrs_wl = drought_yrs(spei_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e39a7-183f-426b-bf2e-6cd7ae326d1a",
   "metadata": {},
   "source": [
    "### Step 2: Calculate delta signal\n",
    "Difference between chronic (at 2.0°C warming level) and historical baseline (1981-2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c44eb4-f59a-4106-9c0d-da45fd4fdd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_delta = drought_yrs_wl - drought_yrs_hist\n",
    "ds_delta.name = \"change_in_drought_years\" # assign name so it can convert to pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b1589-aa78-40e8-811f-428d6e537372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_delta.min().values, ds_delta.max().values # change over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442eb7c-798b-4e75-b800-b32ae232aada",
   "metadata": {},
   "source": [
    "### Step 3: Reproject and aggregate to tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f6c4cb8-b164-4c73-ac50-6fae532783aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_shp_dir = \"tl_2021_06_tract.shp\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "ca_boundaries = ca_boundaries[[\"COUNTYFP\",\"GEOID\",\"geometry\"]]\n",
    "# isolate sacramento county\n",
    "ca_boundaries = ca_boundaries[ca_boundaries[\"COUNTYFP\"]=='067']\n",
    "ca_boundaries = ca_boundaries.to_crs(crs=3310) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47def9-0709-40f6-85c8-350d989f1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_df = reproject_to_tracts(ds_delta, ca_boundaries) \n",
    "drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44788e5-0117-418b-8f8d-a3e2848c10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_df.plot(column=\"change_in_drought_years\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e89b3-fcff-452e-bcc0-e89326561cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_data_std = min_max_standardize(drought_df, col=ds_delta.name)\n",
    "drought_data_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
