{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a184be96-f61f-4546-8ff2-1cb43042623b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T22:15:17.898163Z",
     "iopub.status.busy": "2024-01-04T22:15:17.897747Z",
     "iopub.status.idle": "2024-01-04T22:15:17.902224Z",
     "shell.execute_reply": "2024-01-04T22:15:17.901452Z",
     "shell.execute_reply.started": "2024-01-04T22:15:17.898091Z"
    }
   },
   "source": [
    "## Cal-CRAI metric: cold spell freqency\n",
    "\n",
    "This notebook walks through how to calculate the extreme heat loss metric: `# of cold days` using Cal-Adapt: Analytics Engine data. This notebook may be expanded or modified for inclusion in cae-notebooks in the future. \n",
    "\n",
    "**Order of operations**:\n",
    "1. Read data in\n",
    "2. Calculate base function (FFWI, SPEI, warm nights, etc.)\n",
    "3. Calculate chronic\n",
    "4. Calculate delta signal\n",
    "5. Reprojection to census tracts\n",
    "6. Min-max standardization\n",
    "7. Export data\n",
    "\n",
    "**Runtime**: This notebook will take approximately 1 hour to run due to data size, warming levels, and reprojection steps. \n",
    "\n",
    "### Step 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ffe7e6-5b3e-4e62-9ea2-7f8a39e3744f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:57:03.012169Z",
     "iopub.status.busy": "2024-09-12T14:57:03.011606Z",
     "iopub.status.idle": "2024-09-12T14:57:17.547370Z",
     "shell.execute_reply": "2024-09-12T14:57:17.546632Z",
     "shell.execute_reply.started": "2024-09-12T14:57:03.012104Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "from climakitae.explore import warming_levels \n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.core.data_interface import DataParameters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import pyproj\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "\n",
    "# projection information\n",
    "import cartopy.crs as ccrs\n",
    "crs = ccrs.LambertConformal(\n",
    "    central_longitude=-70, \n",
    "    central_latitude=38, \n",
    "    false_easting=0.0, \n",
    "    false_northing=0.0,  \n",
    "    standard_parallels=[30, 60], \n",
    "    globe=None, \n",
    "    # cutoff=-30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190e304f-0cba-49ea-b961-e27bc8f4ae0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:57:17.550166Z",
     "iopub.status.busy": "2024-09-12T14:57:17.549001Z",
     "iopub.status.idle": "2024-09-12T14:57:17.566011Z",
     "shell.execute_reply": "2024-09-12T14:57:17.565368Z",
     "shell.execute_reply.started": "2024-09-12T14:57:17.550135Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_wl = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_MIROC6_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_TaiESM1_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "]\n",
    "sims_hist = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1',\n",
    "    'WRF_MIROC6_r1i1p1f1', \n",
    "    'WRF_EC-Earth3_r1i1p1f1',\n",
    "    'WRF_TaiESM1_r1i1p1f1', \n",
    "]\n",
    "\n",
    "sim_name_dict = dict(zip(sims_wl,sims_hist)) \n",
    "\n",
    "def count_delta_extreme_cold_events(ds_hist, ds_wl):    \n",
    "  \n",
    "    # define the months over which we are going to \n",
    "    # determine the 2nd percentile temperature threshold\n",
    "    # to define a cold spell\n",
    "    months_to_measure = [m for m in np.arange(1,13,1)]\n",
    "    \n",
    "    sim_coord_dict = dict(zip(sims_wl,sims_hist))\n",
    "    \n",
    "    ds_hist = ds_hist.squeeze()\n",
    "    ds_wl = ds_wl.squeeze()\n",
    "    ds_template = ds_hist.isel(time=0, simulation=0).squeeze()\n",
    "    # first set consistent coordinates\n",
    "    ds_hist = ds_hist.sortby(\"simulation\")\n",
    "    ds_wl = ds_wl.rename({\"all_sims\" : \"simulation\"})\n",
    "    ds_wl = ds_wl.sortby(\"simulation\")\n",
    "    ds_wl = ds_wl.assign_coords({'simulation': list(sim_coord_dict.values())})\n",
    "    ds_wl = ds_wl.transpose(\"simulation\",\"time\",\"y\",\"x\")\n",
    "\n",
    "    # compute 2nd percentile historical temperature\n",
    "    thresh_ds = ds_hist.sel(\n",
    "        time=ds_hist.time.dt.month.isin(months_to_measure)).chunk(\n",
    "            dict(time=-1)).quantile(0.02, dim=\"time\")\n",
    "    \n",
    "    # count total days < 2nd percentile in historical data and take annual average\n",
    "    hist_count = xr.where(ds_hist < thresh_ds, x=1, y=0).groupby(\n",
    "        \"time.year\").sum().mean(dim=\"year\").mean(dim=\"simulation\")\n",
    "    \n",
    "    # count total days < 2nd percentile in warming levels data and take annual average\n",
    "    chronic_count = xr.where(ds_wl < thresh_ds, x=1, y=0).groupby(\n",
    "        \"time.year\").sum().mean(dim=\"year\").mean(dim=\"simulation\")\n",
    "    \n",
    "    # get the delta signal\n",
    "    delta_count = chronic_count - hist_count\n",
    "    \n",
    "    # nan out non-CA grid points\n",
    "    delta_count = xr.where(np.isnan(ds_template), x=np.nan, y=delta_count)\n",
    "    return delta_count\n",
    "\n",
    "def reproject_to_tracts(ds_delta, ca_boundaries):\n",
    "    # this step takes about 12 minutes with 3km data (~1 min with 9km data)\n",
    "    df = ds_delta.to_dataframe().reset_index()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.x,df.y))\n",
    "    gdf = gdf.set_crs(crs)\n",
    "    gdf = gdf.to_crs(ca_boundaries.crs)\n",
    "    \n",
    "    ca_boundaries = ca_boundaries.set_index(['GEOID'])    \n",
    "\n",
    "    clipped_gdf = gpd.sjoin_nearest(ca_boundaries, gdf, how='left')\n",
    "    clipped_gdf = clipped_gdf.drop(['index_right'], axis=1)\n",
    "    clipped_gdf = clipped_gdf.reset_index()[\n",
    "        [\"GEOID\",f\"{ds_delta.name}\",\"geometry\"]]\n",
    "    ### some coastal tracts do not contain any land grid cells ###\n",
    "    \n",
    "    # aggregate the gridded data to the tract level\n",
    "    clipped_gdf_diss = clipped_gdf.reset_index().dissolve(\n",
    "        by='GEOID', aggfunc='mean')\n",
    "    clipped_gdf_diss = clipped_gdf_diss.rename(\n",
    "        columns={f\"{ds_delta.name}_right\":\n",
    "                 ds_delta.name}\n",
    "    )\n",
    "    \n",
    "    # separate tracts with data from tracts without data\n",
    "    clipped_gdf_nan = clipped_gdf_diss[np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_nan = clipped_gdf_nan[[\"geometry\",ds_delta.name]]\n",
    "    clipped_gdf_valid = clipped_gdf_diss[~np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_valid = clipped_gdf_valid[[\"geometry\",ds_delta.name]]\n",
    "\n",
    "    # compute the centroid of each tract\n",
    "    clipped_gdf_nan[\"centroid\"] = clipped_gdf_nan.centroid\n",
    "    clipped_gdf_nan = clipped_gdf_nan.set_geometry(\"centroid\")\n",
    "    clipped_gdf_valid[\"centroid\"] = clipped_gdf_valid.centroid\n",
    "    clipped_gdf_valid = clipped_gdf_valid.set_geometry(\"centroid\")\n",
    "    \n",
    "    # fill in missing tracts with values from the closest tract\n",
    "    # in terms of distance between the tract centroids\n",
    "    clipped_gdf_filled = clipped_gdf_nan.sjoin_nearest(clipped_gdf_valid, how='left')\n",
    "    clipped_gdf_filled = clipped_gdf_filled[[\"geometry_left\",f\"{ds_delta.name}_right\"]]\n",
    "    clipped_gdf_filled = clipped_gdf_filled.rename(columns={\n",
    "        \"geometry_left\":\"geometry\", f\"{ds_delta.name}_right\":ds_delta.name\n",
    "    })\n",
    "    clipped_gdf_valid = clipped_gdf_valid.drop(columns=\"centroid\")\n",
    " \n",
    "    # concatenate filled-in tracts with the original tract which had data\n",
    "    gdf_all_tracts = pd.concat([clipped_gdf_valid,clipped_gdf_filled])\n",
    "\n",
    "    return gdf_all_tracts\n",
    "\n",
    "\n",
    "def min_max_standardize(df, col):\n",
    "    '''\n",
    "    Calculates min and max values for specified columns, then calculates\n",
    "    min-max standardized values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        Input dataframe   \n",
    "    cols_to_run_on: list\n",
    "        List of columns to calculate min, max, and standardize\n",
    "    '''\n",
    "    max_value = df[col].max()\n",
    "    min_value = df[col].min()\n",
    "\n",
    "    # Get min-max values, standardize, and add columns to df\n",
    "    prefix = col # Extracting the prefix from the column name\n",
    "    df[f'{prefix}_min'] = min_value\n",
    "    df[f'{prefix}_max'] = max_value\n",
    "    df[f'{prefix}_min_max_standardized'] = ((df[col] - min_value) / (max_value - min_value))\n",
    "\n",
    "    # note to add checker to make sure new min_max column values arent < 0 > 1\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] < 0] = 0\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] > 1] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87675a-a882-4bd1-8484-ec655b52b742",
   "metadata": {},
   "source": [
    "### Step 1: Retrieve data\n",
    "We need to calculate:\n",
    "* 30 year centered around 2.0C warming level (SSP3-7.0)\n",
    "* Historical baseline 1981-2010 (Historical Climate)\n",
    "\n",
    "Note: the 3km data is too large to work with for all of CA for warming level conditions. Working with 9km for now.\n",
    "\n",
    "#### Step 1a) Chronic data (2.0°C WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724a65e-137c-4fc3-8114-53e2298d53fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:57:17.567195Z",
     "iopub.status.busy": "2024-09-12T14:57:17.566907Z",
     "iopub.status.idle": "2024-09-12T15:00:06.061846Z",
     "shell.execute_reply": "2024-09-12T15:00:06.061150Z",
     "shell.execute_reply.started": "2024-09-12T14:57:17.567173Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Step 1a) Chronic data (2.0degC WL)\n",
    "wl = warming_levels()\n",
    "wl.wl_params.timescale = \"daily\"\n",
    "wl.wl_params.downscaling_method = \"Dynamical\"\n",
    "wl.wl_params.variable = \"Air Temperature at 2m\"\n",
    "wl.wl_params.area_subset = \"states\"\n",
    "wl.wl_params.cached_area = [\"CA\"]\n",
    "wl.wl_params.warming_levels = [\"2.0\"]\n",
    "wl.wl_params.units = \"degF\"\n",
    "wl.wl_params.resolution = \"9 km\"\n",
    "wl.wl_params.anom = \"No\"\n",
    "wl.calculate()\n",
    "ds = wl.sliced_data['2.0']\n",
    "ds = ds.sel(all_sims = sims_wl)\n",
    "ds = add_dummy_time_to_wl(ds) # add time dimension back in, as this is removed by WL and is required for xclim functionality\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff21a13-5666-42ab-b259-0186a9315e51",
   "metadata": {},
   "source": [
    "#### Step 1b) Historical baseline data (1981-2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a2a8c-e264-4d0a-832c-14ce064ef11b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:00:06.063148Z",
     "iopub.status.busy": "2024-09-12T15:00:06.062813Z",
     "iopub.status.idle": "2024-09-12T15:00:14.876924Z",
     "shell.execute_reply": "2024-09-12T15:00:14.876226Z",
     "shell.execute_reply.started": "2024-09-12T15:00:06.063125Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selections = DataParameters()\n",
    "selections.area_average = 'No'\n",
    "selections.timescale = 'daily'\n",
    "selections.variable = 'Air Temperature at 2m'\n",
    "selections.area_subset = 'states'\n",
    "selections.cached_area = ['CA']\n",
    "selections.scenario_historical = ['Historical Climate']\n",
    "selections.time_slice = (1981, 2010)\n",
    "selections.resolution = '9 km'\n",
    "selections.units = 'degF'\n",
    "ds_hist = selections.retrieve().squeeze()\n",
    "ds_hist = ds_hist.sel(simulation=sims_hist)\n",
    "ds_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b6a51-12be-46dd-a768-87fb1bcea490",
   "metadata": {},
   "source": [
    "### Step 2: Calculate delta signal\n",
    "Difference between chronic (at 2.0°C warming level) and historical baseline (1981-2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e83d0c-bb6e-4572-a9e5-16e5006243a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:00:14.879379Z",
     "iopub.status.busy": "2024-09-12T15:00:14.879052Z",
     "iopub.status.idle": "2024-09-12T15:00:57.945785Z",
     "shell.execute_reply": "2024-09-12T15:00:57.944993Z",
     "shell.execute_reply.started": "2024-09-12T15:00:14.879357Z"
    }
   },
   "outputs": [],
   "source": [
    "cold_delta_ds = count_delta_extreme_cold_events(\n",
    "    ds_hist, ds\n",
    ")\n",
    "cold_delta_ds = ck.load(cold_delta_ds)\n",
    "cold_delta_ds.name = \"mean_change_cold_days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ed814-9bd7-4967-8fd6-571bc7af56f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:00:57.947643Z",
     "iopub.status.busy": "2024-09-12T15:00:57.946997Z",
     "iopub.status.idle": "2024-09-12T15:00:57.954761Z",
     "shell.execute_reply": "2024-09-12T15:00:57.954097Z",
     "shell.execute_reply.started": "2024-09-12T15:00:57.947609Z"
    }
   },
   "outputs": [],
   "source": [
    "cold_delta_ds.min(), cold_delta_ds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7325f27-3270-4789-8735-f3fdce16f9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:00:57.957531Z",
     "iopub.status.busy": "2024-09-12T15:00:57.957249Z",
     "iopub.status.idle": "2024-09-12T15:00:58.336330Z",
     "shell.execute_reply": "2024-09-12T15:00:58.335667Z",
     "shell.execute_reply.started": "2024-09-12T15:00:57.957509Z"
    }
   },
   "outputs": [],
   "source": [
    "cold_delta_ds.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1505b19e-5833-4d12-9e26-946a19b24e03",
   "metadata": {},
   "source": [
    "### Step 3: Reproject data to census tract projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdbed49-dc69-41fc-983d-7e16763924f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:00:58.337659Z",
     "iopub.status.busy": "2024-09-12T15:00:58.337335Z",
     "iopub.status.idle": "2024-09-12T15:02:11.748534Z",
     "shell.execute_reply": "2024-09-12T15:02:11.747907Z",
     "shell.execute_reply.started": "2024-09-12T15:00:58.337636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in census tract shapefile\n",
    "# census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\" # pcluster run\n",
    "census_shp_dir = \"2021_ca_tract/tl_2021_06_tract.shp\" # local run, requires having census tracts loaded in file tree\n",
    "\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "\n",
    "# convert to area-preserving CRS\n",
    "ca_boundaries = ca_boundaries.to_crs(crs=3310)\n",
    "cold_day_df = reproject_to_tracts(cold_delta_ds, ca_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63df68-02c0-4cc7-9a59-88022b0d5810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:02:11.749812Z",
     "iopub.status.busy": "2024-09-12T15:02:11.749504Z",
     "iopub.status.idle": "2024-09-12T15:02:11.779962Z",
     "shell.execute_reply": "2024-09-12T15:02:11.779269Z",
     "shell.execute_reply.started": "2024-09-12T15:02:11.749789Z"
    }
   },
   "outputs": [],
   "source": [
    "cold_day_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f87593-4c0e-4c74-8f8a-72880005de0b",
   "metadata": {},
   "source": [
    "### Step 4: Min-max standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e8b2c8-8feb-47ce-92b5-a5ba26fe0f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:02:11.781668Z",
     "iopub.status.busy": "2024-09-12T15:02:11.781035Z",
     "iopub.status.idle": "2024-09-12T15:02:11.787800Z",
     "shell.execute_reply": "2024-09-12T15:02:11.787209Z",
     "shell.execute_reply.started": "2024-09-12T15:02:11.781635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Cal-CRAI min-max standardization function, available in `utils.calculate_index.py`\n",
    "cold_day_std = min_max_standardize(cold_day_df, col=cold_delta_ds.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b025ad-7d26-405f-be02-53e1f2be40b9",
   "metadata": {},
   "source": [
    "### Step 5: Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "007ac333-2d99-4380-9f06-203b7695e8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:02:11.788916Z",
     "iopub.status.busy": "2024-09-12T15:02:11.788627Z",
     "iopub.status.idle": "2024-09-12T15:02:11.838739Z",
     "shell.execute_reply": "2024-09-12T15:02:11.838123Z",
     "shell.execute_reply.started": "2024-09-12T15:02:11.788895Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean up dataframes prior to export\n",
    "cold_day_std = cold_day_std.drop(columns=['geometry'])\n",
    "\n",
    "# export\n",
    "cold_day_std.to_csv('climate_heat_cold_days_metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2898e-e35d-4dfd-aea5-284df9897b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T15:02:11.839949Z",
     "iopub.status.busy": "2024-09-12T15:02:11.839644Z",
     "iopub.status.idle": "2024-09-12T15:02:11.851603Z",
     "shell.execute_reply": "2024-09-12T15:02:11.850884Z",
     "shell.execute_reply.started": "2024-09-12T15:02:11.839925Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cold_day_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
