{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2aa917a-2085-43d9-8c6b-aabfbc167d4f",
   "metadata": {},
   "source": [
    "## Absolute change in 99th percentile 1-day accumulated precipitation\n",
    "This notebook generates the text metadata files for the in-land flooding exposure metric `absolute change in 99th percentile 1-day accumulated precipitation`, using data from Cal-Adapt: Analytics Engine data. \n",
    "Please see the processing notebook `climate_ae_precipitation_accumulation_metrics.ipynb` for full methodological process. Note this notebook can only be on the AE Jupyter Hub, or a computing environment with a large enough memory capacity (e.g., at least 30 GB).\n",
    "\n",
    "### Step 1: Generate metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "166cf3f4-de4a-4edb-9c0b-6577997f679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import upload_csv_aws, pull_csv_from_directory\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1949db95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame as 'csv_folder\\climate_flood_exposure_precipitation_metric.csv'\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '3_fair_data/index_data/climate_flood_exposure_precipitation_metric.csv'\n",
    "folder = 'csv_folder'\n",
    "\n",
    "pull_csv_from_directory(bucket_name, aws_dir, folder, search_zipped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2149e67e-d33b-4a6e-9ad3-a522158fe310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>precip_99percentile</th>\n",
       "      <th>precip_99percentile_min</th>\n",
       "      <th>precip_99percentile_max</th>\n",
       "      <th>precip_99percentile_min_max_standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6001401700</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.190519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6001401800</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.190519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6001402200</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.190519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6001402500</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.190519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6001402600</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.190519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9124</th>\n",
       "      <td>6111008900</td>\n",
       "      <td>1.700077</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.237236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>6111009100</td>\n",
       "      <td>1.700077</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.237236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9126</th>\n",
       "      <td>6111009200</td>\n",
       "      <td>1.700077</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.237236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9127</th>\n",
       "      <td>6111009600</td>\n",
       "      <td>1.373455</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.215146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>6111980000</td>\n",
       "      <td>1.391396</td>\n",
       "      <td>-1.807552</td>\n",
       "      <td>12.977818</td>\n",
       "      <td>0.216359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9129 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GEOID  precip_99percentile  precip_99percentile_min  \\\n",
       "0     6001401700             1.009346                -1.807552   \n",
       "1     6001401800             1.009346                -1.807552   \n",
       "2     6001402200             1.009346                -1.807552   \n",
       "3     6001402500             1.009346                -1.807552   \n",
       "4     6001402600             1.009346                -1.807552   \n",
       "...          ...                  ...                      ...   \n",
       "9124  6111008900             1.700077                -1.807552   \n",
       "9125  6111009100             1.700077                -1.807552   \n",
       "9126  6111009200             1.700077                -1.807552   \n",
       "9127  6111009600             1.373455                -1.807552   \n",
       "9128  6111980000             1.391396                -1.807552   \n",
       "\n",
       "      precip_99percentile_max  precip_99percentile_min_max_standardized  \n",
       "0                   12.977818                                  0.190519  \n",
       "1                   12.977818                                  0.190519  \n",
       "2                   12.977818                                  0.190519  \n",
       "3                   12.977818                                  0.190519  \n",
       "4                   12.977818                                  0.190519  \n",
       "...                       ...                                       ...  \n",
       "9124                12.977818                                  0.237236  \n",
       "9125                12.977818                                  0.237236  \n",
       "9126                12.977818                                  0.237236  \n",
       "9127                12.977818                                  0.215146  \n",
       "9128                12.977818                                  0.216359  \n",
       "\n",
       "[9129 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# options here: climate_extreme_heat_hot_day_metric, climate_extreme_heat_warm_night_metric\n",
    "df_in = pd.read_csv(r'csv_folder/climate_flood_exposure_precipitation_metric.csv') # make sure this is in the same folder!\n",
    "df_in # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad66c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move a specific column to the end of the DataFrame\n",
    "column_to_move = 'precip_99percentile'  # Replace with the actual column name\n",
    "columns = [col for col in df_in.columns if col != column_to_move]  # Keep all other columns\n",
    "columns.append(column_to_move)  # Add the column to move to the end\n",
    "\n",
    "# Reassign the DataFrame with the new column order\n",
    "df_in = df_in[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf9ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.to_csv('climate_flood_exposure_precipitation_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03699578-d4e7-48f4-be44-ac5799f63738",
   "metadata": {},
   "outputs": [],
   "source": [
    "@append_metadata\n",
    "def precip_ae_data_process(df, export=False, export_filename=None, varname=''):\n",
    "    '''\n",
    "    Reduces the size of the initial daily raw precipitation data in order to streamline compute time.\n",
    "    Transforms the raw data into the following baseline metrics:\n",
    "    * Absolute change in 99th percentile 1-day accumulated precipitation\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    Metric is calculated by pooling data across models and calculating the 99th percentile. \n",
    "    See https://github.com/cal-adapt/cae-notebooks/blob/main/exploratory/internal_variability.ipynb\n",
    "    for reasoning behind data pooling for precipitation model data. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        Input data.\n",
    "    export: True/False boolean\n",
    "        False = will not upload resulting df containing CAL CRAI flooding metric to AWS\n",
    "        True = will upload resulting df containing CAL CRAI flooding metric to AWS\n",
    "    export_filename: string\n",
    "        name of csv file to be uploaded to AWS\n",
    "    varname: string\n",
    "        Final metric name, for metadata generation\n",
    "        \n",
    "    Script\n",
    "    ------\n",
    "    Metric calculation: climate_ae_precipitation_accumulation_metric.py via pcluster run\n",
    "    Example metric calculation for Alameda county: climate_ae_precipitation_accumulation_metric_example.ipynb\n",
    "    Metadata generation: climate_ae_precipitation_accumulation_metadata.ipynb\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    Because the climate projections data is on the order of 2.4 TB in size, intermediary\n",
    "    processed files are not produced for each stage of the metric calculation. All processing\n",
    "    occurs in a single complete run in the notebook listed above.\n",
    "    '''\n",
    "        \n",
    "    # calculate with 2°C WL\n",
    "    print('Data transformation: raw projections data retrieved for warming level of 2.0°C, by manually subsetting based on GWL for parent GCM and calculating 30 year average.')\n",
    "    print(\"Data transformation: dynamically-downscaled climate data subsetted for a-priori bias-corrected models.\")\n",
    "\n",
    "    # historical baseline\n",
    "    print(\"Data transformation: historical baseline data retrieved for 1981-2010, averaging across models.\")\n",
    "    print(\"Data transformation: dynamically-downscaled climate data subsetted for a-priori bias-corrected models.\")\n",
    "\n",
    "    # calculate delta signal\n",
    "    print(\"Data transformation: snowfall sigal removed from precipitation data to isolate liquid precipitation from total precipitation.\")\n",
    "    print(\"Data transformation: data clipped to remove 0.1mm to remove trace precipitation.\")\n",
    "    print(\"Data transformation: leap days removed from historical data to match time periods.\")\n",
    "    print(\"Data transformation: data pooled across models to increase sample size and drop all singleton dimensions (scenario).\")\n",
    "    print(\"Data transformation: calculate 99th percentile from pooled data.\")\n",
    "    print(\"Data transformation: delta signal calculated by taking difference between chronic (2.0°C) and historical baseline.\")\n",
    "    print(\"Data transformation: non-CA grid points removed from data.\")\n",
    "\n",
    "    # reprojection to census tracts\n",
    "    print(\"Data transformation: data transformed from xarray dataset into pandas dataframe.\")\n",
    "    print(\"Data transformation: data reprojected from Lambert Conformal Conic CRS to CRS 3310.\")\n",
    "        \n",
    "    # min-max standardization\n",
    "    print(\"Data transformation: data min-max standardized with min_max_standardize function.\")\n",
    "    \n",
    "    if export == True:\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [df]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{df} uplaoded to AWS.')\n",
    "\n",
    "    if os.path.exists(df):\n",
    "        os.remove(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb61bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'climate_caladapt_flood_exposure_precipitation'\n",
    "filename = 'climate_flood_exposure_precipitation_metric.csv'\n",
    "precip_ae_data_process(filename, export=True, export_filename=None, varname='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
