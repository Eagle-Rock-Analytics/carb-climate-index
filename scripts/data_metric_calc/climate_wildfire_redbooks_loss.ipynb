{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal-CRAI Metric Calculation\n",
    "Domain: Climate Risks \\\n",
    "Indicator: Wildfire Loss\n",
    "\n",
    "This notebook calculates two metrics, sourced from CalFire's historical redbooks:\n",
    "* Metric 1: Number of damaged/destroyed buildings per county per year from wildfire\n",
    "* Metric 2: Number of fatalities per county per year from wildfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:55:03.014001Z",
     "iopub.status.busy": "2024-04-23T16:55:03.013191Z",
     "iopub.status.idle": "2024-04-23T16:55:03.748706Z",
     "shell.execute_reply": "2024-04-23T16:55:03.748046Z",
     "shell.execute_reply.started": "2024-04-23T16:55:03.013960Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import geopandas as gpd\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import pull_csv_from_directory, upload_csv_aws, filter_counties\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:55:31.665261Z",
     "iopub.status.busy": "2024-04-23T16:55:31.663857Z",
     "iopub.status.idle": "2024-04-23T16:55:33.068051Z",
     "shell.execute_reply": "2024-04-23T16:55:33.067283Z",
     "shell.execute_reply.started": "2024-04-23T16:55:31.665210Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '1_pull_data/climate_risk/wildfire/loss/historical/calfire_redbooks/cleaned_stitched_calfire_redbook_data/'\n",
    "folder = 'csv_folder'\n",
    "\n",
    "pull_csv_from_directory(bucket_name, aws_dir, folder, search_zipped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:55:33.070312Z",
     "iopub.status.busy": "2024-04-23T16:55:33.069968Z",
     "iopub.status.idle": "2024-04-23T16:55:33.081842Z",
     "shell.execute_reply": "2024-04-23T16:55:33.081335Z",
     "shell.execute_reply.started": "2024-04-23T16:55:33.070284Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in air quality data (already for state of CA)\n",
    "wildfire_loss = pd.read_csv(r'csv_folder/calfire_redbooks_cleaned.csv')\n",
    "print(len(wildfire_loss))\n",
    "wildfire_loss.head(5)\n",
    "#os.remove('calfire_redbooks_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset has inconsistent date formats and capitalization\n",
    "* we adjust the dating formats and create a new year column\n",
    "* we bring all entries to lower case\n",
    "* all nan's are treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:56:08.128702Z",
     "iopub.status.busy": "2024-04-23T16:56:08.127743Z",
     "iopub.status.idle": "2024-04-23T16:56:08.201618Z",
     "shell.execute_reply": "2024-04-23T16:56:08.201127Z",
     "shell.execute_reply.started": "2024-04-23T16:56:08.128643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace NaN values with 0\n",
    "wildfire_loss.fillna(0, inplace=True)\n",
    "\n",
    "# Convert 'date_start' column to datetime\n",
    "wildfire_loss['date_start'] = pd.to_datetime(wildfire_loss['date_start'], format='mixed', dayfirst=True)\n",
    "\n",
    "# Format datetime to mm/dd/yyyy\n",
    "wildfire_loss['date_start'] = wildfire_loss['date_start'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# Assuming wildfire_loss is your DataFrame\n",
    "wildfire_loss['date_start'] = pd.to_datetime(wildfire_loss['date_start'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Extract year from the 'date_start' column and create a new 'year' column\n",
    "wildfire_loss['year'] = wildfire_loss['date_start'].dt.year.astype(int)\n",
    "\n",
    "# Ensure all entries within county column are lower case\n",
    "wildfire_loss['county/unit'] = wildfire_loss['county/unit'].str.lower()\n",
    "\n",
    "wildfire_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are multiple entries that contain two or more counties\n",
    "\n",
    "The code below duplicates rows that have a '-' OR ',' within the county column and assigns the original row the county preceeding the '-' or ',' while the duplicate takes on the second or third county name. \n",
    "The method below equally splits the destroyed/damaged structures and fatality values between the rows that had shared counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:56:46.400795Z",
     "iopub.status.busy": "2024-04-23T16:56:46.399929Z",
     "iopub.status.idle": "2024-04-23T16:56:46.716257Z",
     "shell.execute_reply": "2024-04-23T16:56:46.715933Z",
     "shell.execute_reply.started": "2024-04-23T16:56:46.400749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the modified rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in wildfire_loss.iterrows():\n",
    "    county_unit = row['county/unit']\n",
    "    \n",
    "    # Check if the county/unit is a string\n",
    "    if isinstance(county_unit, str):\n",
    "        county_unit = county_unit.replace('\\n', '')\n",
    "\n",
    "        # Split the county/unit string by '-' or ',' or '/'\n",
    "        if '-' in county_unit:\n",
    "            county_units = county_unit.split('-')\n",
    "        elif ',' in county_unit:\n",
    "            county_units = county_unit.split(',')\n",
    "        elif '/' in county_unit:\n",
    "            county_units = county_unit.split('/')\n",
    "            # Strip any whitespace around the county names\n",
    "            county_units = [county.strip() for county in county_units]\n",
    "        else:\n",
    "            county_units = [county_unit]\n",
    "        \n",
    "        # Count the number of counties\n",
    "        num_counties = len(county_units)\n",
    "        \n",
    "        # Convert values in the specified columns to integers or floats\n",
    "        destroyed_structures = row['destroyed_structures']\n",
    "        damaged_structures = row['damaged_structures']\n",
    "        firefighter_fatalities = row['firefighter_fatalities']\n",
    "        civil_fatalities = row['civil_fatalities']\n",
    "        \n",
    "        if isinstance(destroyed_structures, str):\n",
    "            destroyed_structures = destroyed_structures.replace(',', '')\n",
    "            if destroyed_structures.isdigit():\n",
    "                destroyed_structures = int(destroyed_structures)\n",
    "            else:\n",
    "                destroyed_structures = 0\n",
    "        \n",
    "        if isinstance(damaged_structures, str):\n",
    "            damaged_structures = damaged_structures.replace(',', '')\n",
    "            if damaged_structures.isdigit():\n",
    "                damaged_structures = int(damaged_structures)\n",
    "            else:\n",
    "                damaged_structures = 0\n",
    "        \n",
    "        if isinstance(firefighter_fatalities, str):\n",
    "            firefighter_fatalities = firefighter_fatalities.replace(',', '')\n",
    "            if firefighter_fatalities.isdigit():\n",
    "                firefighter_fatalities = float(firefighter_fatalities)\n",
    "            else:\n",
    "                firefighter_fatalities = 0\n",
    "        \n",
    "        if isinstance(civil_fatalities, str):\n",
    "            civil_fatalities = civil_fatalities.replace(',', '')\n",
    "            if civil_fatalities.isdigit():\n",
    "                civil_fatalities = float(civil_fatalities)\n",
    "            else:\n",
    "                civil_fatalities = 0\n",
    "        \n",
    "        if num_counties > 1:\n",
    "            destroyed_structures = math.ceil(destroyed_structures / num_counties)\n",
    "            damaged_structures = math.ceil(damaged_structures / num_counties)\n",
    "            firefighter_fatalities = math.ceil(firefighter_fatalities / num_counties)\n",
    "            civil_fatalities = math.ceil(civil_fatalities / num_counties)\n",
    "        \n",
    "        # Iterate through each county/unit part\n",
    "        for county in county_units:\n",
    "            # Create a new row for each county/unit part\n",
    "            new_row = row.copy()\n",
    "            new_row['county'] = county.strip()\n",
    "            new_row['destroyed_structures'] = destroyed_structures\n",
    "            new_row['damaged_structures'] = damaged_structures\n",
    "            new_row['firefighter_fatalities'] = firefighter_fatalities\n",
    "            new_row['civil_fatalities'] = civil_fatalities\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        # If the county/unit is not a string (e.g., NaN), handle it accordingly\n",
    "        # For now, just append the original row to the new_rows list\n",
    "        new_rows.append(row)\n",
    "\n",
    "# Create a new DataFrame from the modified rows\n",
    "cleaned_wildfire_loss = pd.DataFrame(new_rows)\n",
    "\n",
    "# Define a dictionary mapping old values to new values\n",
    "rename_map = {\n",
    "    'mardera': 'madera',\n",
    "    'tahema': 'tehama',\n",
    "    'toulumne' : 'tuolumne',\n",
    "     'tehema' : 'tehama',\n",
    "     'tuolomne' : 'tuolumne'\n",
    "    }\n",
    "# deleting problematic row that will not split, only had one data field with a value of 1\n",
    "cleaned_wildfire_loss = cleaned_wildfire_loss.drop(index=122)\n",
    "\n",
    "# Use the replace method to rename the entries\n",
    "cleaned_wildfire_loss['county'] = cleaned_wildfire_loss['county'].replace(rename_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating CRI metric columns by summing structure and fatality related data respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:56:54.097287Z",
     "iopub.status.busy": "2024-04-23T16:56:54.096541Z",
     "iopub.status.idle": "2024-04-23T16:56:54.124090Z",
     "shell.execute_reply": "2024-04-23T16:56:54.123492Z",
     "shell.execute_reply.started": "2024-04-23T16:56:54.097249Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_wildfire_loss['damaged_destroyed_structures'] = cleaned_wildfire_loss['damaged_structures'] + cleaned_wildfire_loss['destroyed_structures']\n",
    "cleaned_wildfire_loss['total_fatalities'] = cleaned_wildfire_loss['firefighter_fatalities'] + cleaned_wildfire_loss['civil_fatalities']\n",
    "cleaned_wildfire_loss.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolating relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:57:04.927970Z",
     "iopub.status.busy": "2024-04-23T16:57:04.927255Z",
     "iopub.status.idle": "2024-04-23T16:57:04.942954Z",
     "shell.execute_reply": "2024-04-23T16:57:04.942096Z",
     "shell.execute_reply.started": "2024-04-23T16:57:04.927933Z"
    }
   },
   "outputs": [],
   "source": [
    "isolated_cleaned_wildfire_loss = cleaned_wildfire_loss[['county', 'year', 'damaged_destroyed_structures', 'total_fatalities']]\n",
    "isolated_cleaned_wildfire_loss, omitted_rows = filter_counties(isolated_cleaned_wildfire_loss, 'county', county_list=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:57:06.760942Z",
     "iopub.status.busy": "2024-04-23T16:57:06.759597Z",
     "iopub.status.idle": "2024-04-23T16:57:06.775391Z",
     "shell.execute_reply": "2024-04-23T16:57:06.774452Z",
     "shell.execute_reply.started": "2024-04-23T16:57:06.760864Z"
    }
   },
   "outputs": [],
   "source": [
    "omitted_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_cleaned_wildfire_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping data by county and aggregate the structure and fatality data so we get total damaged structures and total fatalities per county from 2008-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:57:17.214447Z",
     "iopub.status.busy": "2024-04-23T16:57:17.213687Z",
     "iopub.status.idle": "2024-04-23T16:57:17.240537Z",
     "shell.execute_reply": "2024-04-23T16:57:17.239823Z",
     "shell.execute_reply.started": "2024-04-23T16:57:17.214407Z"
    }
   },
   "outputs": [],
   "source": [
    "cri_wildfire_loss = isolated_cleaned_wildfire_loss.groupby('county').agg({'damaged_destroyed_structures': 'sum', 'total_fatalities': 'sum'}).reset_index()\n",
    "print(len(cri_wildfire_loss))\n",
    "cri_wildfire_loss.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:57:25.418316Z",
     "iopub.status.busy": "2024-04-23T16:57:25.417515Z",
     "iopub.status.idle": "2024-04-23T16:57:25.438556Z",
     "shell.execute_reply": "2024-04-23T16:57:25.437692Z",
     "shell.execute_reply.started": "2024-04-23T16:57:25.418271Z"
    }
   },
   "outputs": [],
   "source": [
    "cri_wildfire_loss['average_damaged_destroyed_structures'] = cri_wildfire_loss['damaged_destroyed_structures'] // 13\n",
    "cri_wildfire_loss['average_fatalities'] = cri_wildfire_loss['total_fatalities'] // 13\n",
    "cri_wildfire_loss.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:57:33.361565Z",
     "iopub.status.busy": "2024-04-23T16:57:33.361074Z",
     "iopub.status.idle": "2024-04-23T16:57:33.377375Z",
     "shell.execute_reply": "2024-04-23T16:57:33.376563Z",
     "shell.execute_reply.started": "2024-04-23T16:57:33.361535Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking the total county results by isolated to one county per year\n",
    "fact_checking = isolated_cleaned_wildfire_loss.groupby(['county', 'year']).agg({'damaged_destroyed_structures': 'sum', 'total_fatalities': 'sum'}).reset_index()\n",
    "desired_county_data = fact_checking[fact_checking['county'] == 'butte']\n",
    "print(desired_county_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "ca_tract_county = \"s3://ca-climate-index/0_map_data/ca_tracts_county.csv\"\n",
    "ca_tract_county = gpd.read_file(ca_tract_county)\n",
    "ca_tract_county = ca_tract_county.drop(columns={'field_1', 'geometry', 'COUNTYFP'})\n",
    "ca_tract_county = ca_tract_county.rename(columns={'TRACT':'USCB_GEOID', 'County':'county'})\n",
    "ca_tract_county['county'] = ca_tract_county['county'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_tract_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri_wildfire_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri_wildfire_loss_metric = pd.merge(ca_tract_county, cri_wildfire_loss, on='county', how='left')\n",
    "cri_wildfire_loss_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri_wildfire_structure_loss_metric = cri_wildfire_loss_metric[['USCB_GEOID', 'county', 'average_damaged_destroyed_structures']]\n",
    "cri_wildfire_structure_loss_metric = cri_wildfire_structure_loss_metric.rename(columns={'average_damaged_destroyed_structures':'average_damaged_destroyed_structures_wildfire'})\n",
    "\n",
    "cri_wildfire_fatality_loss_metric = cri_wildfire_loss_metric[['USCB_GEOID', 'county', 'average_fatalities']]\n",
    "cri_wildfire_fatality_loss_metric = cri_wildfire_fatality_loss_metric.rename(columns={'average_fatalities':'average_annual_fatalities_wildfire'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T20:00:39.990713Z",
     "iopub.status.busy": "2024-04-22T20:00:39.990272Z",
     "iopub.status.idle": "2024-04-22T20:00:39.994344Z",
     "shell.execute_reply": "2024-04-22T20:00:39.993743Z",
     "shell.execute_reply.started": "2024-04-22T20:00:39.990697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving metric df to .csv file\n",
    "cri_wildfire_structure_loss_metric.to_csv('climate_wildfire_redbooks_loss_buildings_metric.csv', index=False)\n",
    "cri_wildfire_fatality_loss_metric.to_csv('climate_wildfire_redbooks_loss_fatalities_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function call for this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T17:00:02.186187Z",
     "iopub.status.busy": "2024-04-23T17:00:02.185219Z",
     "iopub.status.idle": "2024-04-23T17:00:02.220111Z",
     "shell.execute_reply": "2024-04-23T17:00:02.219449Z",
     "shell.execute_reply.started": "2024-04-23T17:00:02.186144Z"
    }
   },
   "outputs": [],
   "source": [
    "@append_metadata\n",
    "def wildfire_loss_calc(input_csv, export=False, varname=''):\n",
    "    '''\n",
    "    Calculates the total number of damaged/destroyed structures and fatalities \n",
    "    resulting from wildfires per California county between 2008-2020. The data \n",
    "    used to calculate these metrics are sourced from CALFIRE's Redbook data: \n",
    "    https://www.fire.ca.gov/our-impact/statistics\n",
    "  \n",
    "    Methods\n",
    "    --------\n",
    "    Data was stitched together and cleaned by utilizing a California county filter function. \n",
    "    Often, entries contained multiple counties where a single fire occured. \n",
    "    In these cases, the number of fatalities and affected structures were equally split between the number of\n",
    "    counties. \n",
    "    The number of fatalities and affected structures were summed within each county across the 13 year dataset. \n",
    "    Averages were also calculated using the total temporal range of the dataset (13).\n",
    "    Data were then merged to California tract data, so each tract had the metric values from the county it resides in.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    df: string\n",
    "        the dataframe containing the wildfire losses data\n",
    "    export: True/False boolean\n",
    "        False = will not upload resulting df containing CAL CRAI wildfire loss metric to AWS\n",
    "        True = will upload resulting df containing CAL CRAI wildfire loss metric to AWS\n",
    "    export_filename: string\n",
    "        name of the csv file to be uploaded to AWS\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    climate_wildfire_redbooks_loss.ipynb\n",
    "\n",
    "    Note\n",
    "    ------\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are\n",
    "    stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    '''\n",
    "    print('Data transformation: convert fire ignition date to year.')\n",
    "    print('Data transformation: nan values within the data are treated as 0.')\n",
    "    print('Data transformation: rows that contained multiple counties had their data split equally between each county.')\n",
    "    print('Data transformation: convert fire ignition date to year.')\n",
    "    print('Data transformation: misspelled counties were adjusted to correct spelling.')\n",
    "    print('Data transformation: data were merged to California tracts.')\n",
    "\n",
    "    if export == True:\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [input_csv]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{input_csv} uploaded to AWS.')\n",
    " \n",
    "    '''if os.path.exists(input_csv):\n",
    "        os.remove(input_csv)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csvs = ['climate_wildfire_redbooks_loss_fatalities_metric.csv',\n",
    "               'climate_wildfire_redbooks_loss_buildings_metric.csv']\n",
    "\n",
    "varnames = ['climate_calfire_wildfire_fatalities','climate_calfire_wildfire_building_loss']\n",
    "\n",
    "# Process the data and export\n",
    "for input_csv, varname in zip(input_csvs, varnames):\n",
    "    print(f'Processing {input_csv} with varname {varname}')\n",
    "    wildfire_loss_calc(input_csv, export=True, varname='test') #varname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
