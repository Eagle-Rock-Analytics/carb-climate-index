{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:04:58.122472Z",
     "iopub.status.busy": "2024-09-12T14:04:58.122056Z",
     "iopub.status.idle": "2024-09-12T14:05:12.673174Z",
     "shell.execute_reply": "2024-09-12T14:05:12.672358Z",
     "shell.execute_reply.started": "2024-09-12T14:04:58.122402Z"
    },
    "tags": []
   },
   "source": [
    "## Absolute change in 99th percentile 1-day accumulated precipitation\n",
    "This notebook generates the text metadata files for the in-land flooding exposure metric `absolute change in 99th percentile 1-day accumulated precipitation`, using data from Cal-Adapt: Analytics Engine data. Because the AE data represents 200+ GB of data, metrics were calculated on the AE Jupyter Hub. \n",
    "Please see the processing script `climate_ae_precipitation_accumulation_metrics.py` for full methodological process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:22:13.013730Z",
     "iopub.status.busy": "2024-09-12T14:22:13.013506Z",
     "iopub.status.idle": "2024-09-12T14:22:27.719845Z",
     "shell.execute_reply": "2024-09-12T14:22:27.719113Z",
     "shell.execute_reply.started": "2024-09-12T14:22:13.013674Z"
    }
   },
   "outputs": [],
   "source": [
    "import climakitae as ck\n",
    "from climakitae.explore import warming_levels \n",
    "from climakitae.util.utils import add_dummy_time_to_wl\n",
    "from climakitae.core.data_interface import DataParameters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import pyproj\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "\n",
    "# projection information\n",
    "import cartopy.crs as ccrs\n",
    "crs = ccrs.LambertConformal(\n",
    "    central_longitude=-70, \n",
    "    central_latitude=38, \n",
    "    false_easting=0.0, \n",
    "    false_northing=0.0,  \n",
    "    standard_parallels=[30, 60], \n",
    "    globe=None, \n",
    "    # cutoff=-30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:22:27.722843Z",
     "iopub.status.busy": "2024-09-12T14:22:27.721690Z",
     "iopub.status.idle": "2024-09-12T14:22:27.726989Z",
     "shell.execute_reply": "2024-09-12T14:22:27.726373Z",
     "shell.execute_reply.started": "2024-09-12T14:22:27.722812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_wl = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_MIROC6_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_EC-Earth3_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "    'WRF_TaiESM1_r1i1p1f1_Historical + SSP 3-7.0 -- Business as Usual',\n",
    "]\n",
    "sims_hist = [\n",
    "    'WRF_MPI-ESM1-2-HR_r3i1p1f1',\n",
    "    'WRF_MIROC6_r1i1p1f1', \n",
    "    'WRF_EC-Earth3_r1i1p1f1',\n",
    "    'WRF_TaiESM1_r1i1p1f1', \n",
    "]\n",
    "\n",
    "sim_name_dict = dict(zip(sims_wl,sims_hist)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:22:27.728290Z",
     "iopub.status.busy": "2024-09-12T14:22:27.727976Z",
     "iopub.status.idle": "2024-09-12T14:22:27.739251Z",
     "shell.execute_reply": "2024-09-12T14:22:27.738509Z",
     "shell.execute_reply.started": "2024-09-12T14:22:27.728268Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject_to_tracts(ds_delta, ca_boundaries):\n",
    "    # this step takes about 12 minutes with 3km data (~1 min with 9km data)\n",
    "    df = ds_delta.to_dataframe().reset_index()\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.x,df.y))\n",
    "    gdf = gdf.set_crs(crs)\n",
    "    gdf = gdf.to_crs(ca_boundaries.crs)\n",
    "    \n",
    "    ca_boundaries = ca_boundaries.set_index(['GEOID'])    \n",
    "\n",
    "    clipped_gdf = gpd.sjoin_nearest(ca_boundaries, gdf, how='left')\n",
    "    clipped_gdf = clipped_gdf.drop(['index_right'], axis=1)\n",
    "    clipped_gdf = clipped_gdf.reset_index()[\n",
    "        [\"GEOID\",f\"{ds_delta.name}\",\"geometry\"]]\n",
    "    ### some coastal tracts do not contain any land grid cells ###\n",
    "    \n",
    "    # aggregate the gridded data to the tract level\n",
    "    clipped_gdf_diss = clipped_gdf.reset_index().dissolve(\n",
    "        by='GEOID', aggfunc='mean')\n",
    "    clipped_gdf_diss = clipped_gdf_diss.rename(\n",
    "        columns={f\"{ds_delta.name}_right\":\n",
    "                 ds_delta.name}\n",
    "    )\n",
    "    \n",
    "    # separate tracts with data from tracts without data\n",
    "    clipped_gdf_nan = clipped_gdf_diss[np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_nan = clipped_gdf_nan[[\"geometry\",ds_delta.name]]\n",
    "    clipped_gdf_valid = clipped_gdf_diss[~np.isnan(\n",
    "        clipped_gdf_diss[ds_delta.name]\n",
    "    )]\n",
    "    clipped_gdf_valid = clipped_gdf_valid[[\"geometry\",ds_delta.name]]\n",
    "\n",
    "    # compute the centroid of each tract\n",
    "    clipped_gdf_nan[\"centroid\"] = clipped_gdf_nan.centroid\n",
    "    clipped_gdf_nan = clipped_gdf_nan.set_geometry(\"centroid\")\n",
    "    clipped_gdf_valid[\"centroid\"] = clipped_gdf_valid.centroid\n",
    "    clipped_gdf_valid = clipped_gdf_valid.set_geometry(\"centroid\")\n",
    "    \n",
    "    # fill in missing tracts with values from the closest tract\n",
    "    # in terms of distance between the tract centroids\n",
    "    clipped_gdf_filled = clipped_gdf_nan.sjoin_nearest(clipped_gdf_valid, how='left')\n",
    "    clipped_gdf_filled = clipped_gdf_filled[[\"geometry_left\",f\"{ds_delta.name}_right\"]]\n",
    "    clipped_gdf_filled = clipped_gdf_filled.rename(columns={\n",
    "        \"geometry_left\":\"geometry\", f\"{ds_delta.name}_right\":ds_delta.name\n",
    "    })\n",
    "    clipped_gdf_valid = clipped_gdf_valid.drop(columns=\"centroid\")\n",
    " \n",
    "    # concatenate filled-in tracts with the original tract which had data\n",
    "    gdf_all_tracts = pd.concat([clipped_gdf_valid,clipped_gdf_filled])\n",
    "\n",
    "    return gdf_all_tracts\n",
    "\n",
    "\n",
    "def min_max_standardize(df, col):\n",
    "    '''\n",
    "    Calculates min and max values for specified columns, then calculates\n",
    "    min-max standardized values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        Input dataframe   \n",
    "    cols_to_run_on: list\n",
    "        List of columns to calculate min, max, and standardize\n",
    "    '''\n",
    "    max_value = df[col].max()\n",
    "    min_value = df[col].min()\n",
    "\n",
    "    # Get min-max values, standardize, and add columns to df\n",
    "    prefix = col # Extracting the prefix from the column name\n",
    "    df[f'{prefix}_min'] = min_value\n",
    "    df[f'{prefix}_max'] = max_value\n",
    "    df[f'{prefix}_min_max_standardized'] = ((df[col] - min_value) / (max_value - min_value))\n",
    "\n",
    "    # note to add checker to make sure new min_max column values arent < 0 > 1\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] < 0] = 0\n",
    "    df[f'{prefix}_min_max_standardized'].loc[df[f'{prefix}_min_max_standardized'] > 1] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Retrieve data\n",
    "We need to calculate:\n",
    "- 30 year centered around 2.0degC warming level (SSP3-7.0)\n",
    "- Historical baseline 1981-2010 (Historical Climate)\n",
    "\n",
    "Because \"total precipitation\" includes snow, we will also retrieve snowfall data so we can remove the snow signal and calculate rain. \n",
    "\n",
    "#### 1a) Chronic data (2.0degC WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:22:27.741002Z",
     "iopub.status.busy": "2024-09-12T14:22:27.740408Z",
     "iopub.status.idle": "2024-09-12T14:25:15.802646Z",
     "shell.execute_reply": "2024-09-12T14:25:15.801856Z",
     "shell.execute_reply.started": "2024-09-12T14:22:27.740969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve 2 deg C precipitation total data\n",
    "wl = warming_levels()\n",
    "wl.wl_params.timescale = \"daily\"\n",
    "wl.wl_params.downscaling_method = \"Dynamical\"\n",
    "wl.wl_params.variable = \"Precipitation (total)\"\n",
    "wl.wl_params.area_subset = \"states\"\n",
    "wl.wl_params.cached_area = [\"CA\"]\n",
    "wl.wl_params.warming_levels = [\"2.0\"]\n",
    "wl.wl_params.units = \"mm\"\n",
    "wl.wl_params.resolution = \"9 km\"\n",
    "wl.wl_params.anom = \"No\"\n",
    "wl.calculate()\n",
    "ds = wl.sliced_data[\"2.0\"] # grab 2.0 degC data\n",
    "ds = ds.sel(all_sims = list(sim_name_dict.keys()))\n",
    "total_precip = add_dummy_time_to_wl(ds)\n",
    "total_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:25:15.804395Z",
     "iopub.status.busy": "2024-09-12T14:25:15.803956Z",
     "iopub.status.idle": "2024-09-12T14:27:09.785260Z",
     "shell.execute_reply": "2024-09-12T14:27:09.784483Z",
     "shell.execute_reply.started": "2024-09-12T14:25:15.804361Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve 2 deg C snowfall (snow and ice) data\n",
    "wl.wl_params.timescale = \"daily\"\n",
    "wl.wl_params.downscaling_method = \"Dynamical\"\n",
    "wl.wl_params.variable = \"Snowfall\"\n",
    "wl.wl_params.area_subset = \"states\"\n",
    "wl.wl_params.cached_area = [\"CA\"]\n",
    "wl.wl_params.warming_levels = [\"2.0\"]\n",
    "wl.wl_params.units = \"mm\"\n",
    "wl.wl_params.resolution = \"9 km\"\n",
    "wl.calculate()\n",
    "ds = wl.sliced_data[\"2.0\"] # grab 2.0 degC data\n",
    "ds = ds.sel(all_sims = list(sim_name_dict.keys()))\n",
    "total_snowfall = add_dummy_time_to_wl(ds)\n",
    "total_snowfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Retrieve historical baseline data (1981-2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:27:09.786930Z",
     "iopub.status.busy": "2024-09-12T14:27:09.786519Z",
     "iopub.status.idle": "2024-09-12T14:27:24.255237Z",
     "shell.execute_reply": "2024-09-12T14:27:24.254498Z",
     "shell.execute_reply.started": "2024-09-12T14:27:09.786897Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Step 1b: Retrieve historical baseline data (1981-2010)\n",
    "# precip\n",
    "selections = DataParameters()\n",
    "selections.area_average = 'No'\n",
    "selections.timescale = 'daily'\n",
    "selections.variable = 'Precipitation (total)'\n",
    "selections.area_subset = 'states'\n",
    "selections.cached_area = ['CA']\n",
    "selections.scenario_historical = ['Historical Climate']\n",
    "selections.time_slice = (1981, 2010)\n",
    "selections.resolution = '9 km'\n",
    "selections.units = 'mm'\n",
    "hist_precip_ds = selections.retrieve()\n",
    "hist_precip_ds = hist_precip_ds.sel(simulation=sims_hist)\n",
    "hist_precip_ds\n",
    "\n",
    "# Snowfall (snow and ice)\n",
    "selections.variable = 'Snowfall'\n",
    "hist_snow_ds = selections.retrieve()\n",
    "hist_snow_ds = hist_snow_ds.sel(simulation=sims_hist)\n",
    "hist_snow_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate delta signal\n",
    "* remove snow from precip\n",
    "* remove leap days from historical data\n",
    "* pool the precipitation data together -- we do this becuase precipitation is better captured by collapsing the simulation dimension. Please see [internal_variability.ipynb](https://github.com/cal-adapt/cae-notebooks/blob/main/exploratory/internal_variability.ipynb) for a full explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:27:24.260644Z",
     "iopub.status.busy": "2024-09-12T14:27:24.260357Z",
     "iopub.status.idle": "2024-09-12T14:27:25.296146Z",
     "shell.execute_reply": "2024-09-12T14:27:25.295474Z",
     "shell.execute_reply.started": "2024-09-12T14:27:24.260623Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove snow from precip\n",
    "rain_wl = total_precip - total_snowfall\n",
    "rain_wl = rain_wl.clip(min=0.1)\n",
    "rain_hist = hist_precip_ds - hist_snow_ds\n",
    "rain_hist = rain_hist.clip(min=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:27:25.297899Z",
     "iopub.status.busy": "2024-09-12T14:27:25.297183Z",
     "iopub.status.idle": "2024-09-12T14:27:25.309919Z",
     "shell.execute_reply": "2024-09-12T14:27:25.309361Z",
     "shell.execute_reply.started": "2024-09-12T14:27:25.297865Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove leap days from historical data\n",
    "rain_hist = rain_hist.sel(time=~((rain_hist.time.dt.month == 2) & (rain_hist.time.dt.day == 29)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:27:25.311531Z",
     "iopub.status.busy": "2024-09-12T14:27:25.310903Z",
     "iopub.status.idle": "2024-09-12T14:27:25.329727Z",
     "shell.execute_reply": "2024-09-12T14:27:25.329015Z",
     "shell.execute_reply.started": "2024-09-12T14:27:25.311496Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pool the data first\n",
    "hist_pool = rain_hist.stack(index=['simulation', 'time']).squeeze()\n",
    "wl_pool = rain_wl.stack(index=['all_sims', 'time']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:27:25.331442Z",
     "iopub.status.busy": "2024-09-12T14:27:25.330856Z",
     "iopub.status.idle": "2024-09-12T14:28:12.581304Z",
     "shell.execute_reply": "2024-09-12T14:28:12.580496Z",
     "shell.execute_reply.started": "2024-09-12T14:27:25.331408Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_wrf_pool_perc = hist_pool.chunk(\n",
    "    dict(index=-1)).quantile([.99],\n",
    "    dim='index').compute().squeeze()\n",
    "\n",
    "wl_wrf_pool_perc = wl_pool.chunk(\n",
    "    dict(index=-1)).quantile([.99],\n",
    "    dim='index').compute().squeeze()\n",
    "\n",
    "delta_wrf_pool_perc = (wl_wrf_pool_perc - hist_wrf_pool_perc)\n",
    "# absolute change in 99th percentile, data pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:28:12.582584Z",
     "iopub.status.busy": "2024-09-12T14:28:12.582251Z",
     "iopub.status.idle": "2024-09-12T14:28:12.917079Z",
     "shell.execute_reply": "2024-09-12T14:28:12.916269Z",
     "shell.execute_reply.started": "2024-09-12T14:28:12.582549Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta_wrf_pool_perc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:28:12.918939Z",
     "iopub.status.busy": "2024-09-12T14:28:12.918322Z",
     "iopub.status.idle": "2024-09-12T14:28:12.922406Z",
     "shell.execute_reply": "2024-09-12T14:28:12.921807Z",
     "shell.execute_reply.started": "2024-09-12T14:28:12.918904Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename metric to be friendly for our remaining process\n",
    "delta_wrf_pool_perc.name = \"precip_99percentile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reproject data to census tract projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:28:57.473275Z",
     "iopub.status.busy": "2024-09-12T14:28:57.472858Z",
     "iopub.status.idle": "2024-09-12T14:30:10.985704Z",
     "shell.execute_reply": "2024-09-12T14:30:10.984967Z",
     "shell.execute_reply.started": "2024-09-12T14:28:57.473244Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in census tract shapefile\n",
    "# census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\" # pcluster run\n",
    "census_shp_dir = \"2021_ca_tract/tl_2021_06_tract.shp\" # local run, requires having census tracts loaded in file tree\n",
    "\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "\n",
    "# convert to area-preserving CRS\n",
    "ca_boundaries = ca_boundaries.to_crs(crs=3310)\n",
    "rain_df = reproject_to_tracts(delta_wrf_pool_perc, ca_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Min-max standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:31:39.502949Z",
     "iopub.status.busy": "2024-09-12T14:31:39.502558Z",
     "iopub.status.idle": "2024-09-12T14:31:39.510344Z",
     "shell.execute_reply": "2024-09-12T14:31:39.509765Z",
     "shell.execute_reply.started": "2024-09-12T14:31:39.502926Z"
    }
   },
   "outputs": [],
   "source": [
    "## Step 4: Min-max standardization\n",
    "# Using Cal-CRAI min-max standardization function, available in `utils.calculate_index.py`\n",
    "rain_std = min_max_standardize(rain_df, col=delta_wrf_pool_perc.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:31:41.091341Z",
     "iopub.status.busy": "2024-09-12T14:31:41.090946Z",
     "iopub.status.idle": "2024-09-12T14:31:41.143100Z",
     "shell.execute_reply": "2024-09-12T14:31:41.142466Z",
     "shell.execute_reply.started": "2024-09-12T14:31:41.091316Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean up dataframes prior to export\n",
    "rain_std = rain_std.drop(columns=['geometry'])\n",
    "\n",
    "# export\n",
    "rain_std.to_csv('climate_flood_exposure_precipitation_metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-12T14:31:45.746725Z",
     "iopub.status.busy": "2024-09-12T14:31:45.746351Z",
     "iopub.status.idle": "2024-09-12T14:31:45.765453Z",
     "shell.execute_reply": "2024-09-12T14:31:45.764578Z",
     "shell.execute_reply.started": "2024-09-12T14:31:45.746699Z"
    }
   },
   "outputs": [],
   "source": [
    "rain_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
