{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb715ee-e004-405e-b2de-86bb36685ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import dask_geopandas\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48351f2-ea37-49db-8133-4e4c58cd8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqt_list = [\n",
    "    'climate_risk/flood/exposure/koordinates/climate_koordinates_floodplain.parquet.gzip',\n",
    "    'climate_risk/wildfire/exposure/historical/iowa_state_environmental_mesonet/climate_iowa_mesonet_wildfire_warnings.parquet.gzip',\n",
    "    'governance/community_preparedness/usda_forest_service/governance_usda_fuel_reduction.parquet.gzip',\n",
    "    'governance/natural_resource_conservation/usda/forest_to_faucets/F2F2_Assessment/governance_usda_watershed_risk.parquet.gzip'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ba1ce-cafa-4b64-a8b8-2e438c547a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "bucket = 'ca-climate-index'\n",
    "path = '2b_reproject/' \n",
    "\n",
    "for pqt in pqt_list:\n",
    "    ppath = path+pqt\n",
    "    bucket_uri = f's3://{bucket}/{ppath}'\n",
    "    print(pqt)\n",
    "    df = gpd.read_parquet(bucket_uri)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891835f8-faa6-400d-85ad-a7ed9c7e30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### whatever metric calculation(s) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d81604-3dee-48c4-8825-7ac7964295bd",
   "metadata": {},
   "source": [
    "# The biggest dataset: ISU Mesonet's flood warning database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb64c14-6267-45c4-825e-84c73973e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of paths, since this is actually 10 files\n",
    "def build_isu_mesonet_file_list(\n",
    "    path='2b_reproject/climate_risk/flood/exposure/isu_environmental_mesonet'\n",
    "):\n",
    "    \"\"\" Build a list of shapefile URIs contained in S3 folder \"\"\"\n",
    "    # initiate empty list for s3 URIs\n",
    "    all_shapefiles = []\n",
    "    bucket_name = 'ca-climate-index' \n",
    "    # initiate s3 session\n",
    "    session = boto3.Session()\n",
    "    # use the session to get the resource\n",
    "    s3 = session.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket_name)\n",
    "    # iterate through directory\n",
    "    for obj in my_bucket.objects.filter(\n",
    "        Prefix=path):\n",
    "        all_shapefiles.append(obj.key)\n",
    "    return all_shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb61db-52b3-41b2-8566-5d52048fdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pqt_list = build_isu_mesonet_file_list()\n",
    "path = '2b_reproject/climate_risk/flood/exposure/isu_environmental_mesonet' \n",
    "to_drop = ['hilbert_distance', 'WFO', 'EXPIRED', 'INIT_ISS', 'INIT_EXP',\n",
    "       'PHENOM', 'GTYPE', 'SIG', 'ETN', 'STATUS', 'NWS_UGC',\n",
    "       'UPDATED', 'HV_NWSLI', 'HV_SEV', 'HV_CAUSE', 'HV_REC', \n",
    "       'POLY_BEG', 'POLY_END', 'WINDTAG', 'HAILTAG', 'TORNTAG', \n",
    "        'DAMAGTAG', 'index_right', 'USCB_NAME','AREA_KM2','EMERGENC',\n",
    "          'geometry']\n",
    "\n",
    "df_list = []\n",
    "for f in pqt_list:\n",
    "    bucket_uri = f's3://{bucket}/{f}'\n",
    "    # read in as dask geopandas dataframe\n",
    "    df = dask_geopandas.read_parquet(bucket_uri)\n",
    "    # reduce memory use by dropping unneeded columns\n",
    "    df = df.drop(columns=to_drop)\n",
    "    # reduce by counting the # of events per tract:\n",
    "    df_out = df.groupby(['USCB_GEOID']).count(\n",
    "    ).compute().reset_index().rename(\n",
    "        columns={'ISSUED':'number_warnings'})\n",
    "    # append df_out to the list of dfs\n",
    "    df_list.append(df_out)\n",
    "    # clear memory\n",
    "    df_out = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d424a05-1b9d-40a7-bb4c-a8847f1681be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# initiate merged dataframe\n",
    "merged_df = df_list[0]\n",
    "# loop and merge one by one in list\n",
    "for df_i in df_list[1:]:\n",
    "    # merge on GEOID\n",
    "    merged_df = dd.merge(merged_df, df_i, left_on=[\"USCB_GEOID\"],\n",
    "        right_on=[\"USCB_GEOID\"], how=\"outer\")\n",
    "    # add up flood warning counts from both the dataframes\n",
    "    merged_df['number_warnings'] = merged_df['number_warnings_x'].add(\n",
    "        merged_df['number_warnings_y'], fill_value=0)\n",
    "    display(merged_df)\n",
    "    # display(merged_df.loc[merged_df['USCB_GEOID'] == '06065046900'])\n",
    "    # only keep the total\n",
    "    merged_df = merged_df.drop(columns=['number_warnings_x','number_warnings_y'])\n",
    "    # clear df_i to start on the next df in the list\n",
    "    # and avoid double-counting\n",
    "    df_i = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a4584-217b-4a32-ac41-49025e96ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca06d9-2779-4eaf-ada7-fb30e9d067a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={'USCB_GEOID':'GEOID'})\n",
    "flood_warning_df = pd.merge(merged_df,ca_boundaries,on=\"GEOID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db454f3-d3d8-4f53-a786-5bccd70de7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_gdf = gpd.GeoDataFrame(\n",
    "    flood_warning_df, geometry=flood_warning_df[\"geometry\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9edf55-b5f3-4deb-9a95-237afc26a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_gdf.plot(column=\"number_warnings\",legend=True,scheme=\"quantiles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
