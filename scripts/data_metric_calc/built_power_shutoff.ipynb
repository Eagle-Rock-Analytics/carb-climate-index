{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal-CRAI Metric Calculation for: Built Environment / PSPS event frequency\n",
    "* Public Safety Power Shutoff (PSPS) event frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import pull_csv_from_directory, upload_csv_aws\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '1_pull_data/built_environment/utilities/pse_health_energy/'\n",
    "\n",
    "pull_csv_from_directory(bucket_name, aws_dir, search_zipped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in food access data (already subsetted for CA)\n",
    "power_shutoff_data = pd.read_csv('public_safety_power_shutoff_frequency.csv')\n",
    "print(len(power_shutoff_data))\n",
    "power_shutoff_data = power_shutoff_data.rename(columns={'Fips':'GEOID'})\n",
    "# os.remove('public_safety_power_shutoff_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_shutoff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is using older tract data, so we will join it with 2017 Tract data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "old_census_path = \"s3://ca-climate-index/0_map_data/tl_2017_06_tract/\"\n",
    "ca_old = gpd.read_file(old_census_path)\n",
    "ca_old['GEOID'] = pd.to_numeric(ca_old.GEOID)\n",
    "ca_old = ca_old[[\"GEOID\",\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tract_power_shutoff_data = pd.merge(ca_old, power_shutoff_data, on=\"GEOID\")\n",
    "old_tract_power_shutoff_data = gpd.GeoDataFrame(old_tract_power_shutoff_data, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "# need to rename columns so we don't have any duplicates in the final geodatabase\n",
    "column_names = ca_boundaries.columns\n",
    "new_column_names = [\"USCB_\"+column for column in column_names if column != \"geometry\"]\n",
    "ca_boundaries = ca_boundaries.rename(columns=dict(zip(column_names, new_column_names)))\n",
    "# drop unnecessary columns\n",
    "ca_boundaries = ca_boundaries[[\"geometry\",\"USCB_GEOID\"]]\n",
    "ca_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert to an area-preserving CRS for distance calculations\n",
    "old_tract_power_shutoff_data = old_tract_power_shutoff_data.to_crs(crs=3857) \n",
    "ca_boundaries = ca_boundaries.to_crs(crs=3857) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first find the tracts which have not changed from 2010 to 2017\n",
    "# find the indices which correspond to the new boundaries\n",
    "unchanged_tracts_ca = pd.to_numeric(ca_boundaries['USCB_GEOID']).isin(pd.to_numeric(old_tract_power_shutoff_data['GEOID']))\n",
    "ca_boundaries[unchanged_tracts_ca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find the indices which correspond to the original data\n",
    "unchanged_tracts_old = pd.to_numeric(old_tract_power_shutoff_data['GEOID']).isin(pd.to_numeric(ca_boundaries['USCB_GEOID']))\n",
    "original_df = old_tract_power_shutoff_data[unchanged_tracts_old]\n",
    "original_df[\"USCB_GEOID\"] = original_df[\"GEOID\"].apply(lambda x: '{0:0>11}'.format(x))\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now we only have to join the remaining tracts\n",
    "mapped_df = gpd.sjoin_nearest(\n",
    "    ca_boundaries[~unchanged_tracts_ca], \n",
    "    old_tract_power_shutoff_data[~unchanged_tracts_old], \n",
    "    how=\"inner\", distance_col=\"distances\", \n",
    "    max_distance=5000\n",
    ")\n",
    "mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then concatenate the sjoined tracts with the unchanged ones\n",
    "joined_df = pd.concat([original_df,mapped_df])\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars = ['out_freq_s']\n",
    "for col in data_vars:\n",
    "    non_numeric = joined_df[~joined_df[col].apply(lambda x: pd.to_numeric(x, errors='coerce')).notnull()]\n",
    "    if not non_numeric.empty:\n",
    "        print(f\"Non-numeric values found in column '{col}':\")\n",
    "        display(non_numeric)\n",
    "for col in data_vars:\n",
    "    joined_df[col] = pd.to_numeric(joined_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars = ['out_freq_s']\n",
    "# now take the average of the tracts which now exist in the new tract\n",
    "joined_avg_df = joined_df.groupby(['USCB_GEOID','geometry'])[data_vars].mean().reset_index()\n",
    "power_shutoff_new_tracts = gpd.GeoDataFrame(joined_avg_df, geometry='geometry')\n",
    "power_shutoff_new_tracts = power_shutoff_new_tracts.drop(columns={'geometry'})\n",
    "power_shutoff_new_tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_checking = pd.isna(power_shutoff_new_tracts['out_freq_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = power_shutoff_new_tracts[nan_checking]\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_shutoff_new_tracts.to_csv('built_power_shutoffs_metric.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@append_metadata\n",
    "def power_shutoff_upload(input_csv, export=False, varname=''):\n",
    "    '''\n",
    "    Uploads the calculated Public Safety Power Shutoff (PSPS) metric to S3 bucket. The metrics is:\n",
    "    Frequency of PSPS events per California census tract.\n",
    "\n",
    "    Data for this metric was sourced from PSE Healthy Energy at:\n",
    "    https://www.psehealthyenergy.org/work/california-public-safety-power-shutoff-interactive-map/ from the \n",
    "    PSPS Duration by Census Tract section\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    The data was from older census tracts, so we merged it with 2017 California Tiger shape files first.\n",
    "    The data was then set to Cal-CRAI standardized coordinate reference system (CRS) 4269.\n",
    "    Data was then spatially joined to the nearest 2021 census tract data.\n",
    "    Data were then grouped spatially and had the PSPS frequency data averaged per census tracts.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_csv: string\n",
    "        csv PSPS data \n",
    "    export: True/False boolean\n",
    "        False = will not upload resulting df containing CAL CRAI PSPS metric to AWS\n",
    "        True = will upload resulting df containing CAL CRAI PSPS metric to AWS\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    built_power_shutoff.ipynb\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    '''\n",
    "    print('Data transformation: source data and destination tracts both reprojected to CRS 3857.')\n",
    "    print('Data transformation: unchanged tracts isolated to preserve original data.')\n",
    "    print('Data transformation: new tracts filled by averaging the adjacent original tracts.')\n",
    "    print('Data transformation: original data merged with spatially averaged (\"new\") data.')\n",
    " \n",
    "    if export == True:\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [input_csv]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{input_csv} uploaded to AWS.')\n",
    " \n",
    "    if os.path.exists(input_csv):\n",
    "        os.remove(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = 'built_power_shutoffs_metric.csv'\n",
    "varname = 'built_pse_power_shutoff'\n",
    "\n",
    "power_shutoff_upload(input_csv, export=True, varname='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
