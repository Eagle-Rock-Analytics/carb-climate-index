{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal-CRAI Metric Calculation for: Natural systems / impervious surfaces\n",
    "* % of tract with an impervious surface (eg, pavement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import dask_geopandas\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import upload_csv_aws\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_usgs_pqt_file_list(\n",
    "    path='2b_reproject/natural_systems/ecosystem_condition/usgs'\n",
    "):\n",
    "    \"\"\" Build a list of USGS parquet URIs contained in S3 folder \"\"\"\n",
    "    # initiate empty list for s3 URIs\n",
    "    all_pqt = []\n",
    "    bucket = 'ca-climate-index' \n",
    "    # initiate s3 session\n",
    "    session = boto3.Session()\n",
    "    # use the session to get the resource\n",
    "    s3 = session.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    # iterate through directory\n",
    "    for obj in my_bucket.objects.filter(\n",
    "        Prefix=path):\n",
    "        if obj.key.endswith('.parquet.gzip'):\n",
    "            all_pqt.append( f's3://{bucket}/{obj.key}')\n",
    "    return all_pqt\n",
    "\n",
    "def natural_sort(l): \n",
    "    \"\"\" Sort list numerically while accounting for missing leading 0s \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l: list\n",
    "        list of strings containing numbers to naturally sort\n",
    "        \n",
    "    Acknowledgment\n",
    "    ----------\n",
    "    Special thanks to Mark Byers on stackoverflow.\n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)\n",
    "\n",
    "@append_metadata\n",
    "def percent_tract_impervious(pqt_list, ca_boundaries, run_code=True, varname=''):\n",
    "    \"\"\"\n",
    "    Calculates the percent area of a tract which is developed and impervious as defined by USGS.\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in\n",
    "    ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "     \n",
    "    Methods\n",
    "    -------\n",
    "    Uses percent of each 30 x 30 m pixel in the USGS data to calculate the impervious area per pixel,\n",
    "    then sums these pixel areas over each tract and calculates the percentage of the total \n",
    "    tract area with with an impervious surface.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pqt_list: string\n",
    "        filename of the large geodataframe shapefile\n",
    "    ca_boundaries: \n",
    "        read-in gpd file of California Census Tracts, converted to California Albers projection\n",
    "    run_code: bool\n",
    "        if True, code will run. If false, just metadata file will be updated.\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    natural_impervious_lands.ipynb\n",
    "    \"\"\"\n",
    "    \n",
    "    out_fname = 'natural_usgs_impervious_land_metric.csv'\n",
    "\n",
    "    if run_code == False:\n",
    "        # Metadata-only section\n",
    "        print('Data transformation: previously reprojected data parquets were read in one by one.')\n",
    "        print('Data transformation: total impervious area of each 30 x 30 m pixel calculated.')\n",
    "        print('Data transformation: total impervious area summed for each tract.')\n",
    "        print('Data transformation: percent impervious area calculated for each tract.')\n",
    "        print('Data transformation: adjust one tract with 101% impervious area to 100%.')\n",
    "        print(f'{out_fname} would be uploaded to AWS.')\n",
    "        return None  # Return early if run_code is False\n",
    "\n",
    "    else:\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '3_fair_data/index_data'\n",
    "        export_filename = [out_fname]\n",
    "        \n",
    "        gdf_list = []\n",
    "        for pqt in pqt_list:\n",
    "            gdf = gpd.read_parquet(pqt)\n",
    "            gdf[\"impervious_surface\"] = gdf[\"impervious_surface\"]*1e-2\n",
    "            # percent area of 30 x 30 m pixel which is impervious\n",
    "            gdf[\"pixel_area_impervious\"] = 900 * gdf[\"impervious_surface\"] \n",
    "            agg_gdf = pd.DataFrame(data=gdf[\"pixel_area_impervious\"].groupby(gdf[\"GEOID\"]).sum(),\n",
    "                            ).rename(columns={\"pixel_area_impervious\":\"tract_area_impervious\"})\n",
    "            gdf_list.append(agg_gdf)\n",
    "        \n",
    "        # concatenate list of dataframes into one\n",
    "        interim_df = pd.concat(gdf_list).reset_index()\n",
    "        \n",
    "        # Some tracts were split between multiple parquet partitions,\n",
    "        # resulting in some GEOIDs having more than one entry, where\n",
    "        # each entry is only a partial result. \n",
    "        # We sum over each GEOID one more time to get one total for each tract.\n",
    "        summed_df = pd.DataFrame(data=interim_df[\"tract_area_impervious\"].groupby(\n",
    "            interim_df[\"GEOID\"]).sum()).rename(\n",
    "            columns={\"tract_area_impervious\":\"total_tract_area_impervious\"}\n",
    "        )\n",
    "        summed_gdf = pd.merge(ca_boundaries, summed_df, on=\"GEOID\")\n",
    "        summed_gdf[\"tract_percent_impervious\"] = ( summed_gdf[\"total_tract_area_impervious\"] \n",
    "                                                    / summed_gdf[\"tract_area\"] ) * 100\n",
    "        # one tract has a value of ~101%, likely some error propagation\n",
    "        # related to the original measurements and area calculations here.\n",
    "        # We replace this value with 100%.\n",
    "        summed_gdf['tract_percent_impervious'] = summed_gdf['tract_percent_impervious'].apply(\n",
    "            lambda x: 100 if x > 100 else x)\n",
    "        # subset to the data columns we want to save\n",
    "        metric_gdf = summed_gdf[[\"GEOID\",\"tract_percent_impervious\"]]\n",
    "        metric_gdf.to_csv(out_fname)\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "        return summed_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sorted list of the 45 parquets in the bucket\n",
    "pqt_list = natural_sort(build_usgs_pqt_file_list())\n",
    "\n",
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "# keep the columns we need\n",
    "ca_boundaries = ca_boundaries[[\"GEOID\",\"geometry\"]]\n",
    "# change to area-preserving CRS\n",
    "ca_boundaries = ca_boundaries.to_crs(\"epsg:3310\") # CA Albers\n",
    "# calculate area of each tract\n",
    "ca_boundaries[\"tract_area\"] = ca_boundaries.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "impervious_gdf = percent_tract_impervious(pqt_list, ca_boundaries, run_code=False, varname='natural_usgs_impervious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impervious_gdf.plot(column=\"tract_percent_impervious\", legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
