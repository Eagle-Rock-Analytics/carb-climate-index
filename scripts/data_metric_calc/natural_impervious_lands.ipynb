{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:03:59.709116Z",
     "iopub.status.busy": "2024-08-09T23:03:59.708540Z",
     "iopub.status.idle": "2024-08-09T23:04:02.223445Z",
     "shell.execute_reply": "2024-08-09T23:04:02.222878Z",
     "shell.execute_reply.started": "2024-08-09T23:03:59.709099Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import dask_geopandas\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import pull_gpkg_from_directory, upload_csv_aws\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:04:02.224866Z",
     "iopub.status.busy": "2024-08-09T23:04:02.224364Z",
     "iopub.status.idle": "2024-08-09T23:04:02.302591Z",
     "shell.execute_reply": "2024-08-09T23:04:02.301807Z",
     "shell.execute_reply.started": "2024-08-09T23:04:02.224835Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_usgs_pqt_file_list(\n",
    "    path='2b_reproject/natural_systems/ecosystem_condition/usgs'\n",
    "):\n",
    "    \"\"\" Build a list of parquet URIs contained in S3 folder \"\"\"\n",
    "    # initiate empty list for s3 URIs\n",
    "    all_pqt = []\n",
    "    bucket = 'ca-climate-index' \n",
    "    # initiate s3 session\n",
    "    session = boto3.Session()\n",
    "    # use the session to get the resource\n",
    "    s3 = session.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    # iterate through directory\n",
    "    for obj in my_bucket.objects.filter(\n",
    "        Prefix=path):\n",
    "        if obj.key.endswith('.parquet.gzip'):\n",
    "            all_pqt.append( f's3://{bucket}/{obj.key}')\n",
    "    return all_pqt\n",
    "\n",
    "def natural_sort(l): \n",
    "    \"\"\" Sort list numerically despite missing leading 0s \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l: list\n",
    "        list of strings containing numbers to naturally sort\n",
    "        \n",
    "    Acknowledgement\n",
    "    ----------\n",
    "    Special thanks to Mark Byers on stackoverflow.\n",
    "    \"\"\"\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:04:02.303812Z",
     "iopub.status.busy": "2024-08-09T23:04:02.303613Z",
     "iopub.status.idle": "2024-08-09T23:04:13.870400Z",
     "shell.execute_reply": "2024-08-09T23:04:13.869775Z",
     "shell.execute_reply.started": "2024-08-09T23:04:02.303799Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sorted list of the 45 parquets in the bucket\n",
    "pqt_list = natural_sort(build_usgs_pqt_file_list())\n",
    "\n",
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "# keep the columns we need\n",
    "ca_boundaries = ca_boundaries[[\"GEOID\",\"geometry\"]]\n",
    "# change to area-preserving CRS\n",
    "ca_boundaries = ca_boundaries.to_crs(\"epsg:3310\") # CA Albers\n",
    "# calculate area of each tract\n",
    "ca_boundaries[\"tract_area\"] = ca_boundaries.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:21:05.353946Z",
     "iopub.status.busy": "2024-08-09T23:21:05.353392Z",
     "iopub.status.idle": "2024-08-09T23:21:07.840568Z",
     "shell.execute_reply": "2024-08-09T23:21:07.839777Z",
     "shell.execute_reply.started": "2024-08-09T23:21:05.353929Z"
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gdf_list = []\n",
    "for pqt in pqt_list:\n",
    "    gdf = gpd.read_parquet(pqt)\n",
    "    gdf[\"pixel_area\"] = 900 # 30x30 m pixel\n",
    "    gdf[\"impervious_surface\"] = gdf[\"impervious_surface\"]*1e-2\n",
    "    gdf[\"pixel_area_impervious\"] = gdf[\"pixel_area\"] * gdf[\"impervious_surface\"]\n",
    "    agg_gdf = pd.Series(gdf[\"pixel_area_impervious\"].groupby(gdf[\"GEOID\"]).sum())\n",
    "    # gdf = gdf[[\"GEOID\",\"area_impervious\"]]\n",
    "    gdf_list.append(gdf)\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:24:47.881739Z",
     "iopub.status.busy": "2024-08-09T23:24:47.881322Z",
     "iopub.status.idle": "2024-08-09T23:24:47.924545Z",
     "shell.execute_reply": "2024-08-09T23:24:47.923987Z",
     "shell.execute_reply.started": "2024-08-09T23:24:47.881725Z"
    }
   },
   "outputs": [],
   "source": [
    "aa = pd.Series(gdf[\"pixel_area_impervious\"].groupby(gdf[\"GEOID\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[\"percent_impervious\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:20:55.976589Z",
     "iopub.status.busy": "2024-08-09T23:20:55.976065Z",
     "iopub.status.idle": "2024-08-09T23:20:55.984938Z",
     "shell.execute_reply": "2024-08-09T23:20:55.984359Z",
     "shell.execute_reply.started": "2024-08-09T23:20:55.976574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.area_impervious.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T23:18:15.610531Z",
     "iopub.status.busy": "2024-08-09T23:18:15.610095Z",
     "iopub.status.idle": "2024-08-09T23:18:17.870281Z",
     "shell.execute_reply": "2024-08-09T23:18:17.869534Z",
     "shell.execute_reply.started": "2024-08-09T23:18:15.610516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_impervious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963632076</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963632077</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963672507</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963672508</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963672509</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470975112 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           area_impervious\n",
       "6154                   NaN\n",
       "6155                   NaN\n",
       "6156                   NaN\n",
       "6157                   NaN\n",
       "6158                   NaN\n",
       "...                    ...\n",
       "963632076              NaN\n",
       "963632077              NaN\n",
       "963672507              NaN\n",
       "963672508              NaN\n",
       "963672509              NaN\n",
       "\n",
       "[470975112 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_agg = pd.concat(gdf_list)\n",
    "gdf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to partitioning, many GEOIDs have more than one entry\n",
    "# so we sum over each GEOID one more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to loop through the parquets, store them, then stitch together into one df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couple of print statements to see how many unique entries we have for the impervious surface and census tract columns\n",
    "* counts seem low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming and reading census data in for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CA census tiger file\n",
    "ca_tract_county = \"s3://ca-climate-index/0_map_data/ca_tracts_county.csv\"\n",
    "ca_tract_county = gpd.read_file(ca_tract_county)\n",
    "ca_tract_county = ca_tract_county.drop(columns={'field_1', 'geometry', 'COUNTYFP'})\n",
    "ca_tract_county.columns = ca_tract_county.columns.str.lower()\n",
    "ca_tract_county = ca_tract_county.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\n",
    "ca_tract_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impervious_surfaces_columns = impervious_surfaces_data[['GEOID', 'geometry', 'impervious_surface']]\n",
    "impervious_surfaces_columns = impervious_surfaces_columns.rename(columns={'GEOID':'tract'})\n",
    "impervious_surfaces_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_impervious_surfaces = impervious_surfaces_columns.groupby('tract')['impervious_surface'].mean().reset_index()\n",
    "grouped_impervious_surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impervious_surface_merge = pd.merge(ca_tract_county, impervious_surfaces_columns, on='tract', how='left')\n",
    "impervious_surface_merge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
