{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal-CRAI Reprojection -- Koordinates Floodplain Data\n",
    "This notebook processes floodplain data sourced from Koordinates: \\\n",
    "https://koordinates.com/\n",
    "\n",
    "Data reprojecting includes:\n",
    "* Isolating for 100 year floodplain data exclusively\n",
    "* Clipping data to California boundaries\n",
    "* Reprojecting data to standardized coordinate reference system (EPSG:4269)\n",
    "\n",
    "Output is uploaded to 2b_reproject directory within AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import sys\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from functools import wraps\n",
    "import dask_geopandas\n",
    "import re\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.write_metadata import (\n",
    "    append_metadata\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @append_metadata\n",
    "def reproject_floodplain(shp_fname, ca_boundaries, varname='', export=False, additional_comments='N/A'):\n",
    "    \"\"\" \n",
    "    Given S3 URI which corresponds to a data shapefile and a shapefile with California Census Tract: \n",
    "    (1) reproject the data shapefile to the CRS of the California Census Tracts, \n",
    "    (2) clip to California, and \n",
    "    (3) send it off to S3.\n",
    "\n",
    "    This function differs from the one in geospatial_reproject.ipynb since it handles the overlapping\n",
    "    polygons which make up different flood zones. \n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in\n",
    "    ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    shp_fname: string\n",
    "        Local main folder where the pulled files will be saved.\n",
    "    ca_boundaries: string\n",
    "        Name of the CA census tract shape file.\n",
    "    export: bool\n",
    "        If True, exports resulting file to S3.\n",
    "        If False, will return the metadata.\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    koordinates_reproject.ipynb\n",
    "    \"\"\"    \n",
    "    s3_client = boto3.client('s3')  \n",
    "    bucket_name = 'ca-climate-index' \n",
    "    # read in shapefile of interest from S3 and take a look at it\n",
    "    gdf = gpd.read_file(shp_fname)\n",
    "    print(\"Dropping entries which do not correspond to 100-year flood.\")\n",
    "    # remove entries of unknown flood risk\n",
    "    gdf = gdf.dropna()\n",
    "    # keep only 100-year flood entries\n",
    "    gdf = gdf[gdf.FloodZone.str.contains(\"100\")]  \n",
    "    # drop unnecessary columns\n",
    "    gdf = gdf[[\"geometry\",\"FLD_ZONE\",\"FloodZone\"]]\n",
    "    \n",
    "    print(f\"Original CRS of {varname}: {gdf.crs}\")\n",
    "    fig, ax = plt.subplots()\n",
    "    gdf.plot(ax=ax, markersize=1)\n",
    "    plt.title(f\"{varname} on original projection\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # reproject the data to the census tract CRS and clip to California\n",
    "    gdf_reprojected = gdf.to_crs(ca_boundaries.crs)\n",
    "    print(f\"{varname} reprojected from {gdf.crs} to {gdf_reprojected.crs} with geopandas to_crs() function.\")\n",
    "\n",
    "    clipped_gdf = gpd.overlay(gdf_reprojected, ca_boundaries, how='intersection')\n",
    "    print(f\"{varname} clipped to California boundaries via geopandas overlay using the 'intersection' method.\")\n",
    "    clipped_gdf = clipped_gdf.dissolve(by='USCB_GEOID')\n",
    "    print(\"All polygons in a given tract have been aggregated to a single entry.\")\n",
    "    display(clipped_gdf)\n",
    "    \n",
    "    # visualize results\n",
    "    fig, ax = plt.subplots()\n",
    "    ca_boundaries.plot(ax=ax, color='white', edgecolor='black')\n",
    "    clipped_gdf.plot(ax=ax, marker='o', color='red', markersize=1)\n",
    "    plt.title(f\"{varname} on new projection\")\n",
    "    plt.show()\n",
    "  \n",
    "    # write the reprojected file to disk - still looking for a way around this\n",
    "    # if not os.path.exists(f\"{varname}.gpkg\"):\n",
    "    clipped_gdf.to_file(f\"{varname}.gpkg\", driver=\"GPKG\")\n",
    "    print(f\"{varname}.gpkg has been made\")\n",
    "    \n",
    "    if shp_fname.endswith('.zip'):\n",
    "        shp_fname = shp_fname.replace(\n",
    "            'zip+',\n",
    "            '')\n",
    "        \n",
    "    dest_path = shp_fname.replace(\n",
    "        's3://ca-climate-index/',\n",
    "        '')\n",
    "    dest_path = re.sub(r'1_pull_data|2a_subset', '2b_reproject', dest_path)\n",
    "    dest_path = dest_path.replace(dest_path.split('/')[-1],f\"{varname}.gpkg\")\n",
    "    print(f\"Reprojected data called {varname}.gpkg sent to S3 bucket: {dest_path}\")\n",
    "    \n",
    "    if export == True:\n",
    "        # upload it to S3\n",
    "        s3_client.upload_file(f\"{varname}.gpkg\", f'{bucket_name}', f'{dest_path}'\n",
    "        )\n",
    "        \n",
    "    os.remove(f\"{varname}.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to floodplain shapefile\n",
    "shp_fname = 'zip+s3://ca-climate-index/1_pull_data/climate_risk/flood/exposure/koordinates/california-fema-100-year-floodplains.gdb.zip'\n",
    "varname = 'climate_koordinates_floodplain'\n",
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "# need to rename columns so we don't have any duplicates in the final geodatabase\n",
    "column_names = ca_boundaries.columns\n",
    "new_column_names = [\"USCB_\"+column for column in column_names if column != \"geometry\"]\n",
    "ca_boundaries = ca_boundaries.rename(columns=dict(zip(column_names, new_column_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_floodplain(shp_fname, ca_boundaries, varname=varname, export=True, additional_comments='N/A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
