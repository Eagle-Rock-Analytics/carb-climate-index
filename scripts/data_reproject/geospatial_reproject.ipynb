{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T00:29:26.377259Z",
     "iopub.status.busy": "2024-02-15T00:29:26.377059Z",
     "iopub.status.idle": "2024-02-15T00:29:27.733530Z",
     "shell.execute_reply": "2024-02-15T00:29:27.732856Z",
     "shell.execute_reply.started": "2024-02-15T00:29:26.377245Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from geopandas.tools import overlay\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import zipfile\n",
    "import sys\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "import re\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.write_metadata import (\n",
    "    append_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T00:29:27.742106Z",
     "iopub.status.busy": "2024-02-15T00:29:27.741616Z",
     "iopub.status.idle": "2024-02-15T00:29:27.753374Z",
     "shell.execute_reply": "2024-02-15T00:29:27.752739Z",
     "shell.execute_reply.started": "2024-02-15T00:29:27.742087Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "def list_geospatial_files(path):\n",
    "    \"\"\" Build a list of shapefile URIs contained in S3 folder \"\"\"\n",
    "    # initiate empty list for s3 URIs\n",
    "    all_shapefiles = []\n",
    "    bucket_name = 'ca-climate-index' \n",
    "    # initiate s3 session\n",
    "    session = boto3.Session()\n",
    "    # use the session to get the resource\n",
    "    s3 = session.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket_name)\n",
    "    # iterate through directory\n",
    "    for obj in my_bucket.objects.filter(\n",
    "        Prefix=path):\n",
    "        # build list of shapefile URIs\n",
    "        if obj.key.endswith('.zip'):\n",
    "            # preceding the URI with 'zip' lets you read in the file without downloading, unzipping, etc\n",
    "            s3_uri = f\"zip+s3://ca-climate-index/\"+obj.key\n",
    "            all_shapefiles.append(s3_uri)\n",
    "        elif obj.key.endswith('.shp'):\n",
    "            s3_uri = \"s3://ca-climate-index/\"+obj.key\n",
    "            all_shapefiles.append(s3_uri)\n",
    "    return all_shapefiles\n",
    "\n",
    "# @append_metadata\n",
    "def reproject_shapefile(shp_fname, ca_boundaries, varname='', additional_comments='N/A'):\n",
    "    \"\"\" Given S3 URI which corresponds to a data shapefile and a shapefile\n",
    "    with California Census Tract, (1) reproject the data shapefile to the CRS of the California Census Tracts, \n",
    "    (2) clip to California, and (3) send it off to S3. \"\"\"    \n",
    "\n",
    "    # read in shapefile of interest from S3 and take a look at it\n",
    "    gdf = gpd.read_file(shp_fname)\n",
    "    print(f\"Reading in shapefile: {shp_fname}\")\n",
    "    print(f\"Original CRS of {varname}: {gdf.crs}\")\n",
    "    fig, ax = plt.subplots()\n",
    "    gdf.plot(ax=ax, markersize=1)\n",
    "    plt.title(f\"{varname} on original projection\")\n",
    "    plt.show()\n",
    "\n",
    "    # check the current coordinate system of the census tracts data\n",
    "    print(f\"CRS of Census Tracts Shapefile: {ca_boundaries.crs}\")\n",
    "\n",
    "    # reproject the data to the census tract CRS and clip to California\n",
    "    gdf_reprojected = gdf.to_crs(ca_boundaries.crs)\n",
    "    print(f\"{varname} reprojected from {gdf.crs} to {gdf_reprojected.crs} with geopandas to_crs() function.\")\n",
    "\n",
    "    clipped_gdf = overlay(gdf_reprojected, ca_boundaries, how='intersection')\n",
    "    print(f\"{varname} clipped to California boundaries via geopandas overlay using the 'intersection' method.\")\n",
    "    print(f\"Additional comments: {additional_comments}.\") # eg, code rerun, bug fix, etc\n",
    "\n",
    "    # visualize results\n",
    "    fig, ax = plt.subplots()\n",
    "    ca_boundaries.plot(ax=ax, color='white', edgecolor='black')\n",
    "    clipped_gdf.plot(ax=ax, marker='o', color='red', markersize=1)\n",
    "    plt.title(f\"{varname} on new projection\")\n",
    "    plt.show()\n",
    "  \n",
    "    # write the reprojected file to disk - still looking for a way around this\n",
    "    # if not os.path.exists(f\"{varname}.gpkg\"):\n",
    "    clipped_gdf.to_file(f\"{varname}.gpkg\", driver=\"GPKG\")\n",
    "    print(f\"{varname}.gpkg has been made\")\n",
    "    print(f'Uploading file {varname}.gpkg to AWS')\n",
    "    \n",
    "    # upload it to S3\n",
    "    s3_client = boto3.client('s3')  \n",
    "    bucket_name = 'ca-climate-index' \n",
    "\n",
    "    if shp_fname.endswith('.zip'):\n",
    "        shp_fname = shp_fname.replace(\n",
    "            'zip+',\n",
    "            '')\n",
    "    dest_path = shp_fname.replace(\n",
    "        's3://ca-climate-index/',\n",
    "        '')\n",
    "    dest_path = re.sub(r'1_pull_data|2a_subset', '2b_reproject', dest_path)\n",
    "    dest_path = dest_path.replace(dest_path.split('/')[-1],f\"{varname}.gpkg\")\n",
    "\n",
    "    s3_client.upload_file(f\"{varname}.gpkg\", f'{bucket_name}', f'{dest_path}'\n",
    "    )\n",
    "    print(f\"Reprojected data called {varname}.gpkg sent to S3 bucket: {dest_path}\")\n",
    "    print('')\n",
    "    os.remove(f\"{varname}.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T00:29:27.754410Z",
     "iopub.status.busy": "2024-02-15T00:29:27.754047Z",
     "iopub.status.idle": "2024-02-15T00:29:48.232642Z",
     "shell.execute_reply": "2024-02-15T00:29:48.232102Z",
     "shell.execute_reply.started": "2024-02-15T00:29:27.754396Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in the CSV with the data details\n",
    "ref_file = sys.path[-1]+'/metadata/Full Data Pipeline Notes - 1_ Pull.csv'\n",
    "df = pd.read_csv(ref_file)\n",
    "\n",
    "# subset for shapefiles\n",
    "ref_df = df.fillna('N/A')\n",
    "# comment out for now as 'Pulled Format' column not updated\n",
    "# ref_df = ref_df[ref_df[\"Pulled Format\"].str.contains(\"shp\")]\n",
    "\n",
    "### Define the path\n",
    "path1 = \"1_pull_data\"\n",
    "path2 = \"2a_subset\"\n",
    "#  build a list of shapefiles in the above s3 paths\n",
    "my_list = list_geospatial_files(path1) \n",
    "my_list += list_geospatial_files(path2)\n",
    "\n",
    "# read in CA census tiger file\n",
    "census_shp_dir = \"s3://ca-climate-index/0_map_data/2021_tiger_census_tract/2021_ca_tract/\"\n",
    "ca_boundaries = gpd.read_file(census_shp_dir)\n",
    "# need to rename columns so we don't have any duplicates in the final geodatabase\n",
    "column_names = ca_boundaries.columns\n",
    "new_column_names = [\"USCB_\"+column for column in column_names if column != \"geometry\"]\n",
    "ca_boundaries = ca_boundaries.rename(columns=dict(zip(column_names, new_column_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshooting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T00:30:00.840674Z",
     "iopub.status.busy": "2024-02-15T00:30:00.840448Z",
     "iopub.status.idle": "2024-02-15T00:30:01.140447Z",
     "shell.execute_reply": "2024-02-15T00:30:01.139907Z",
     "shell.execute_reply.started": "2024-02-15T00:30:00.840660Z"
    }
   },
   "outputs": [],
   "source": [
    "def troubleshoot_reproject(shp_fname, ca_boundaries, varname='', additional_comments='N/A'):\n",
    "    \"\"\" Given S3 URI which corresponds to a shapefile, (1) reproject it\n",
    "    to the CRS of the California Census Tracts, (2) clip to California, \n",
    "    and (3) send it off to S3. \"\"\"    \n",
    "\n",
    "    # check the current coordinate system of the census tracts data\n",
    "    print(f\"CRS of Census Tracts Shapefile: {ca_boundaries.crs}\")\n",
    "    # reproject the data to the census tract CRS and clip to California\n",
    "    gdf_reprojected = gdf.to_crs(ca_boundaries.crs)\n",
    "    print(f\"{varname} reprojected from {gdf.crs} to {gdf_reprojected.crs} with geopandas to_crs() function.\")\n",
    "    clipped_gdf = overlay(gdf_reprojected, ca_boundaries, how='intersection')\n",
    "    return gdf_reprojected, clipped_gdf\n",
    "\n",
    "fpath = \"zip+s3://ca-climate-index/1_pull_data/built_environment/transportation/cdot/Bottlenecks.zip\"\n",
    "gdf = gpd.read_file(fpath)\n",
    "reproj, clipped_gdf = troubleshoot_reproject(fpath, ca_boundaries, varname='bottlenecks_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'Bottlenecks.zip',\n",
    "    'California_Rail_Network.zip',\n",
    "    'Local_Bridges.zip',\n",
    "    'National_Highway_System.zip',\n",
    "    'Public_Airport.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"TV_Broadcast_Contours.zip\":\n",
    "            continue\n",
    "        if fname =='sta_tv_contours.zip':\n",
    "            varname = \"built_hifld_tv_contour\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'broadband_internet.gdb.zip'\n",
    "    ]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        print(varname)\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'FM_Transmission_Towers.zip',\n",
    "    'Cellular_Towers.zip',\n",
    "    'Microwave_Service_Towers.zip',\n",
    "    'Paging_Transmission_Towers.zip',\n",
    "    'Land_Mobile_Broadcast_Towers.zip'\n",
    "    ]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"TV_Broadcast_Contours.zip\":\n",
    "            continue\n",
    "        if fname =='sta_tv_contours.zip':\n",
    "            varname = \"built_hifld_tv_contour\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing tv contours separately, doesnt work when grouped with other communication file names\n",
    "file_names = [ \n",
    "    'sta_tv_contours.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"TV_Broadcast_Contours.zip\":\n",
    "            continue\n",
    "        if fname =='sta_tv_contours.zip':\n",
    "            varname = \"built_hifld_tv_contour\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    #else:\n",
    "        #print(f\"Skipping file {fname} as it is not in the list of files to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'California_Electric_Transmission_Lines.zip',\n",
    "    'California_Power_Plants.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"TV_Broadcast_Contours.zip\":\n",
    "            continue\n",
    "        if fname =='sta_tv_contours.zip':\n",
    "            varname = \"built_hifld_tv_contour\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'extreme_heat_warnings_1986_2024.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"TV_Broadcast_Contours.zip\":\n",
    "            continue\n",
    "        if fname =='sta_tv_contours.zip':\n",
    "            varname = \"built_hifld_tv_contour\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    'vulnerable_fire_stations_2000.gdb.zip',\n",
    "    'vulnerable_fire_stations_2100.gdb.zip',\n",
    "    'vulnerable_hospitals_2000.gdb.zip',\n",
    "    'vulnerable_hospitals_2100.gdb.zip',\n",
    "    'vulnerable_police_stations_2000.gdb.zip',\n",
    "    'vulnerable_police_stations_2100.gdb.zip',\n",
    "    'vulnerable_schools_2000.gdb.zip',\n",
    "    'vulnerable_schools_2100.gdb.zip',\n",
    "    'vulnerable_slr_superfund_sites.gdb.zip',\n",
    "    'vulnerable_wastewater_treatment_facilities.gdb.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"flash_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fl_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fa_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname =='merged_flood.zip':\n",
    "            varname = \"climate_iowa_mesonet_flash_flood_warnings\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'merged_flood.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"flash_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fl_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fa_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname =='merged_flood.zip':\n",
    "            varname = \"climate_iowa_mesonet_flash_flood_warnings\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'california-fema-100-year-floodplains.gdb.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"flash_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fl_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fa_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname =='merged_flood.zip':\n",
    "            varname = \"climate_iowa_mesonet_flash_flood_warnings\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wildfire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'red_flag_warnings_1986_2024.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "         # want the subsetted TV contours data in 2a_subset folder\n",
    "        if fname==\"flash_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fl_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname==\"fa_flood_warnings_1986_2024.zip\":\n",
    "            continue\n",
    "        if fname =='merged_flood.zip':\n",
    "            varname = \"climate_iowa_mesonet_flash_flood_warnings\"\n",
    "        else:\n",
    "            # match up file name to variable name\n",
    "            varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n",
    "    else:\n",
    "        print(f\"Skipping file {fname} as it is not in the list of files to process.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Preparedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'usda_fuel_treatment.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# full list of file names here - still need to do some tweaking\n",
    "# file_names = [name for name in ref_df['File Name'].values if name != 'N/A']\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergency Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'usgs_fire_stations.zip'\n",
    "]\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Resources Conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample for testing\n",
    "file_names = [ \n",
    "    'cpad_2023_holdings.zip',\n",
    "    'calfire_timber_management.zip'\n",
    "]\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big, running separately\n",
    "file_names = [ \n",
    "    'f2f2_assessment.gdb.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosystem Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too big, running separately\n",
    "file_names = [ \n",
    "    'ca_fish_wildlife_species_biodiversity.gdb.zip'\n",
    "]\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosystem Conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [ \n",
    "    'cpad_2023_holdings_conservation.zip'\n",
    "]\n",
    "\n",
    "# test additional comments for fun\n",
    "additional_comments = \"N/A\"\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecosystem Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [ \n",
    "    'ca_dept_forestry_ecosystem_veg.gdb.zip'\n",
    "]\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"zip+s3://ca-climate-index/1_pull_data/natural_systems/ecosystem_type/ca_dept_forestry_fire/ca_dept_forestry_ecosystem_veg.gdb.zip\"\n",
    "gdf = gpd.read_file(fpath)\n",
    "reproj, clipped_gdf = troubleshoot_reproject(fpath, ca_boundaries, varname='bottlenecks_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [ \n",
    "    'hpsa_mental_health.zip',\n",
    "    'hpsa_primary_care.zip',\n",
    "    'hpsa_narcotic_treatment_programs.zip'\n",
    "]\n",
    "\n",
    "# iterate through the list \n",
    "for fpath in my_list:\n",
    "    # get the file name by itself (no subdirectories)\n",
    "    fname = fpath.split('/')[-1]\n",
    "    if fname in file_names:\n",
    "            # match up file name to variable name\n",
    "        varname = ref_df.loc[ref_df[\"File Name\"] == fname][\"Variable\"].values[0]\n",
    "        reproject_shapefile(fpath, ca_boundaries, varname=varname, additional_comments=additional_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
