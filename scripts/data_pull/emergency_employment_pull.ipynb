{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "#import xlrd\n",
    "import boto3\n",
    "import io\n",
    "import zipfile\n",
    "import glob\n",
    "import shutil\n",
    "import boto3\n",
    "\n",
    "# suppress pandas purely educational warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.file_helpers import pull_gpkg_from_directory, upload_csv_aws, filter_counties\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_to_county = {\n",
    "    'processed_alameDetOcc.csv': 'Alameda',\n",
    "    'processed_alpinDetOcc.csv': 'Alpine',\n",
    "    'processed_amadoDetOcc.csv': 'Amador',\n",
    "    'processed_calavDetOcc.csv': 'Calaveras',\n",
    "    'processed_colusDetOcc.csv': 'Colusa',\n",
    "    'processed_contrDetOcc.csv': 'Contra Costa',\n",
    "    'processed_delnoDetOcc.csv': 'Del Norte',\n",
    "    'processed_eldorDetOcc.csv': 'El Dorado',\n",
    "    'processed_fresnDetOcc.csv': 'Fresno',\n",
    "    'processed_glennDetOcc.csv': 'Glenn',\n",
    "    'processed_humboDetOcc.csv': 'Humboldt',\n",
    "    'processed_imperDetOcc.csv': 'Imperial',\n",
    "    'processed_inyoDetOcc.csv': 'Inyo',\n",
    "    'processed_kernDetOcc.csv': 'Kern',\n",
    "    'processed_kingsDetOcc.csv': 'Kings',\n",
    "    'processed_laDetOcc.csv': 'Los Angeles',\n",
    "    'processed_lakeDetOcc.csv': 'Lake',\n",
    "    'processed_lassenDetOcc.csv': 'Lassen',\n",
    "    'processed_maderDetOcc.csv': 'Madera',\n",
    "    'processed_marinDetOcc.csv': 'Marin',\n",
    "    'processed_maripDetOcc.csv': 'Mariposa',\n",
    "    'processed_mendoDetOcc.csv': 'Mendocino',\n",
    "    'processed_merceDetOcc.csv': 'Merced',\n",
    "    'processed_modocDetOcc.csv': 'Modoc',\n",
    "    'processed_monoDetOcc.csv': 'Mono',\n",
    "    'processed_monteDetOcc.csv': 'Monterey',\n",
    "    'processed_napaDetOcc.csv': 'Napa',\n",
    "    'processed_nevadDetOcc.csv': 'Nevada',\n",
    "    'processed_oranDetOcc.csv': 'Orange',\n",
    "    'processed_placeDetOcc.csv': 'Placer',\n",
    "    'processed_plumaDetOcc.csv': 'Plumas',\n",
    "    'processed_riveDetOcc.csv': 'Riverside',\n",
    "    'processed_sacDetOcc.csv': 'Sacramento',\n",
    "    'processed_sanbeDetOcc.csv': 'San Benito',\n",
    "    'processed_sanbrDetOcc.csv': 'San Bernardino',\n",
    "    'processed_sandiDetOcc.csv': 'San Diego',\n",
    "    'processed_sanfrDetOcc.csv': 'San Francisco',\n",
    "    'processed_sanjoDetOcc.csv': 'San Joaquin',\n",
    "    'processed_sanluDetOcc.csv': 'San Luis Obispo',\n",
    "    'processed_sanmaDetOcc.csv': 'San Mateo',\n",
    "    'processed_santbDetOcc.csv': 'Santa Barbara',\n",
    "    'processed_santcDetOcc.csv': 'Santa Clara',\n",
    "    'processed_scruzDetOcc.csv': 'Santa Cruz',\n",
    "    'processed_shastDetOcc.csv': 'Shasta',\n",
    "    'processed_sierrDetOcc.csv': 'Sierra',\n",
    "    'processed_siskiDetOcc.csv': 'Siskiyou',\n",
    "    'processed_solanDetOcc.csv': 'Solano',\n",
    "    'processed_sonomDetOcc.csv': 'Sonoma',\n",
    "    'processed_staniDetOcc.csv': 'Stanislaus',\n",
    "    'processed_sutteDetOcc.csv': 'Sutter',\n",
    "    'processed_tehamDetOcc.csv': 'Tehama',\n",
    "    'processed_triniDetOcc.csv': 'Trinity',\n",
    "    'processed_tularDetOcc.csv': 'Tulare',\n",
    "    'processed_tuoluDetOcc.csv': 'Tuolumne',\n",
    "    'processed_ventuDetOcc.csv': 'Ventura',\n",
    "    'processed_yoloDetOcc.csv': 'Yolo',\n",
    "    'processed_yubaDetOcc.csv': 'Yuba'\n",
    "}\n",
    "def pull_csv_or_xls_from_directory(bucket_name, directory, search_zipped=True):\n",
    "    \"\"\"\n",
    "    Pulls CSV or XLS files from a specified directory in an S3 bucket.\n",
    "    \n",
    "    Parameters:\n",
    "    - bucket_name (str): The name of the S3 bucket.\n",
    "    - directory (str): The directory within the bucket to search for CSV or XLS files.\n",
    "    - search_zipped (bool): If True, search for CSV or XLS files within zip files. If False, search for CSV or XLS files directly.\n",
    "    \"\"\"\n",
    "    # Create an S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # List objects in the specified directory\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=directory)\n",
    "\n",
    "    # Check if objects were found\n",
    "    if 'Contents' in response:\n",
    "        # Iterate through each object found\n",
    "        for obj in response['Contents']:\n",
    "            # Get the key (filename) of the object\n",
    "            key = obj['Key']\n",
    "            \n",
    "            # Check if the object is a .zip file\n",
    "            if search_zipped and key.endswith('.zip'):\n",
    "                # Download the zip file into memory\n",
    "                zip_object = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "                zip_data = io.BytesIO(zip_object['Body'].read())\n",
    "                \n",
    "                # Open the zip file\n",
    "                with zipfile.ZipFile(zip_data, 'r') as zip_ref:\n",
    "                    # Iterate through each file in the zip\n",
    "                    for file_name in zip_ref.namelist():\n",
    "                        # Check if the file is a .csv or .xls file\n",
    "                        if file_name.endswith('.csv') or file_name.endswith('.xls'):\n",
    "                            # Read the file\n",
    "                            with zip_ref.open(file_name) as file:\n",
    "                                # Convert the file content to pandas DataFrame\n",
    "                                if file_name.endswith('.csv'):\n",
    "                                    df = pd.read_csv(file)\n",
    "                                elif file_name.endswith('.xls'):\n",
    "                                    df = pd.read_excel(file)\n",
    "                                \n",
    "                                # Save the DataFrame with a similar name as the file\n",
    "                                df_name = file_name.split('.')[0]  # Remove extension\n",
    "                                df.to_csv(f\"{df_name}.csv\", index=False)\n",
    "                                print(f\"Saved DataFrame as '{df_name}.csv'\")\n",
    "                                # You can now manipulate df as needed\n",
    "            elif not search_zipped and (key.endswith('.csv') or key.endswith('.xls')):\n",
    "                # Directly download the CSV or XLS file\n",
    "                file_object = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "                file_data = io.BytesIO(file_object['Body'].read())\n",
    "                # Convert the file content to pandas DataFrame\n",
    "                if key.endswith('.csv'):\n",
    "                    df = pd.read_csv(file_data)\n",
    "                elif key.endswith('.xls'):\n",
    "                    df = pd.read_excel(file_data)\n",
    "                # Save the DataFrame with a similar name as the file\n",
    "                df_name = key.split('/')[-1].split('.')[0]  # Extract filename without extension\n",
    "                df.to_csv(f\"{df_name}.csv\", index=False)\n",
    "                print(f\"Saved DataFrame as '{df_name}.csv'\")\n",
    "                # You can now manipulate df as needed\n",
    "\n",
    "    else:\n",
    "        print(\"No objects found in the specified directory.\")\n",
    "\n",
    "@append_metadata\n",
    "def combined_function(input_folder, temp_folder, final_output_folder, final_combined_csv, export=False, varname=''):\n",
    "    '''\n",
    "    Pulls emergency responder employment data from our AWS bucket, cleans the data, and reuploads to AWS\n",
    "    for future analysis and data handling. Data is sourced from: \n",
    "    https://labormarketinfo.edd.ca.gov/geography/demoaa.html\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    Data was pulled into a folder and iteratively cleaned by converting data types, removing unwanted rows,\n",
    "    and isolating for emergency responder positions and values.\n",
    "    Files were then merged into one single resulting csv file containing emergency employment data for each California\n",
    "    county.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_folder: string\n",
    "        folder containing the csv employment files\n",
    "    temp_folder: string\n",
    "        folder to hold cleaned files before final processing\n",
    "    final_output_folder: string\n",
    "        folder to hold the final csv file\n",
    "    final_combined_csv: string\n",
    "        name of the final csv file containing the employment data  \n",
    "    export: True/False boolean\n",
    "        False = will not upload resulting df containing CAL CRAI emergency management grant metric to AWS\n",
    "        True = will upload resulting df containing CAL CRAI emergency management grant metric to AWS\n",
    "\n",
    "    Script\n",
    "    ------\n",
    "    emergency_employment_pull.ipynb\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    '''\n",
    "    print('Data transformation: convert every xls file to csv file.')\n",
    "    print('Data transformation: isolate relevant columns and remove unwanted rows.')\n",
    "    print('Data transformation: assign each data file its corresponding county name.')\n",
    "    print('Data transformation: merge all separate files together into one csv.')\n",
    "\n",
    "    # Ensure the temp and final output folders exist\n",
    "    if not os.path.exists(temp_folder):\n",
    "        os.makedirs(temp_folder)\n",
    "    if not os.path.exists(final_output_folder):\n",
    "        os.makedirs(final_output_folder)\n",
    "\n",
    "    # Step 1: xls_to_csv equivalent\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_filename = os.path.splitext(filename)[0] + \".csv\"\n",
    "            output_path = os.path.join(temp_folder, output_filename)\n",
    "\n",
    "            df = pd.read_csv(input_path)\n",
    "\n",
    "            occupation_code_index = df[df.apply(lambda row: 'Occupation Code' in str(row), axis=1)].index\n",
    "            if not occupation_code_index.empty:\n",
    "                df = df.iloc[occupation_code_index[0]:]\n",
    "                df.columns = df.iloc[0]\n",
    "                df = df.iloc[1:]\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                strings_to_isolate = [\n",
    "                    'Police officers 3870',\n",
    "                    'Firefighting and prevention workers 3740',\n",
    "                    'Registered nurses 3255',\n",
    "                    'Emergency medical technicians and paramedics 3401'\n",
    "                ]\n",
    "                df = df[df.iloc[:, 0].astype(str).str.strip().isin(strings_to_isolate)]\n",
    "            else:\n",
    "                print(f\"Warning: 'Occupation Code' not found in {filename}. No conversion performed.\")\n",
    "                continue\n",
    "            \n",
    "            df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Step 2: process_csv_files equivalent\n",
    "    for filename in os.listdir(temp_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(temp_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            if 'Subject' in df.columns:\n",
    "                for index, row in df.iterrows():\n",
    "                    if 'Total, both sexes' in str(row['Subject']):\n",
    "                        df.at[index + 1, 'Subject'] = 'Occupation Total'\n",
    "\n",
    "                df.columns.values[2] = 'Value'\n",
    "                df = df.iloc[:, :3]\n",
    "                df = df[~df['Subject'].str.contains('Percent')]\n",
    "                df = df[~df['Subject'].str.contains('Number')]\n",
    "                df = df[~df['Subject'].str.contains('Male')]\n",
    "                df = df[~df['Subject'].str.contains('Female')]\n",
    "                df = df[~df['Subject'].str.contains('Total, both sexes')]\n",
    "\n",
    "                output_file_path = os.path.join(final_output_folder, f\"processed_{filename}\")\n",
    "                df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # Step 3: merge_data_single_csv equivalent\n",
    "    combined_data = pd.DataFrame()\n",
    "    for filename in os.listdir(final_output_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(final_output_folder, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            county_value = filename_to_county.get(filename)\n",
    "            if county_value:\n",
    "                df['County'] = county_value\n",
    "                combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "    combined_data.to_csv(final_combined_csv, index=False)\n",
    "\n",
    "        # export to csv and upload to AWS\n",
    "    if export == True:\n",
    "        combined_data.to_csv(final_combined_csv)\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = '1_pull_data/governance/emergency_response/ca_employment_development_dept'\n",
    "        export_filename = [final_combined_csv]\n",
    "        upload_csv_aws(export_filename, bucket_name, directory)\n",
    "\n",
    "    if export == False:\n",
    "        print(f'{final_combined_csv} uploaded to AWS.')\n",
    "\n",
    "    if os.path.exists(final_combined_csv[0]):\n",
    "        os.remove(final_combined_csv[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame as 'alameDetOcc.csv'\n",
      "Saved DataFrame as 'alpinDetOcc.csv'\n",
      "Saved DataFrame as 'amadoDetOcc.csv'\n",
      "Saved DataFrame as 'calavDetOcc.csv'\n",
      "Saved DataFrame as 'colusDetOcc.csv'\n",
      "Saved DataFrame as 'contrDetOcc.csv'\n",
      "Saved DataFrame as 'delnoDetOcc.csv'\n",
      "Saved DataFrame as 'eldorDetOcc.csv'\n",
      "Saved DataFrame as 'fresnDetOcc.csv'\n",
      "Saved DataFrame as 'glennDetOcc.csv'\n",
      "Saved DataFrame as 'humboDetOcc.csv'\n",
      "Saved DataFrame as 'imperDetOcc.csv'\n",
      "Saved DataFrame as 'inyoDetOcc.csv'\n",
      "Saved DataFrame as 'kernDetOcc.csv'\n",
      "Saved DataFrame as 'kingsDetOcc.csv'\n",
      "Saved DataFrame as 'laDetOcc.csv'\n",
      "Saved DataFrame as 'lakeDetOcc.csv'\n",
      "Saved DataFrame as 'lasseDetOcc.csv'\n",
      "Saved DataFrame as 'maderDetOcc.csv'\n",
      "Saved DataFrame as 'marinDetOcc.csv'\n",
      "Saved DataFrame as 'maripDetOcc.csv'\n",
      "Saved DataFrame as 'mendoDetOcc.csv'\n",
      "Saved DataFrame as 'merceDetOcc.csv'\n",
      "Saved DataFrame as 'modocDetOcc.csv'\n",
      "Saved DataFrame as 'monoDetOcc.csv'\n",
      "Saved DataFrame as 'monteDetOcc.csv'\n",
      "Saved DataFrame as 'napaDetOcc.csv'\n",
      "Saved DataFrame as 'nevadDetOcc.csv'\n",
      "Saved DataFrame as 'oranDetOcc.csv'\n",
      "Saved DataFrame as 'placeDetOcc.csv'\n",
      "Saved DataFrame as 'plumaDetOcc.csv'\n",
      "Saved DataFrame as 'riveDetOcc.csv'\n",
      "Saved DataFrame as 'sacDetOcc.csv'\n",
      "Saved DataFrame as 'sanbeDetOcc.csv'\n",
      "Saved DataFrame as 'sanbrDetOcc.csv'\n",
      "Saved DataFrame as 'sandiDetOcc.csv'\n",
      "Saved DataFrame as 'sanfrDetOcc.csv'\n",
      "Saved DataFrame as 'sanjoDetOcc.csv'\n",
      "Saved DataFrame as 'sanluDetOcc.csv'\n",
      "Saved DataFrame as 'sanmaDetOcc.csv'\n",
      "Saved DataFrame as 'santbDetOcc.csv'\n",
      "Saved DataFrame as 'santcDetOcc.csv'\n",
      "Saved DataFrame as 'scruzDetOcc.csv'\n",
      "Saved DataFrame as 'shastDetOcc.csv'\n",
      "Saved DataFrame as 'sierrDetOcc.csv'\n",
      "Saved DataFrame as 'siskiDetOcc.csv'\n",
      "Saved DataFrame as 'solanDetOcc.csv'\n",
      "Saved DataFrame as 'sonomDetOcc.csv'\n",
      "Saved DataFrame as 'staniDetOcc.csv'\n",
      "Saved DataFrame as 'sutteDetOcc.csv'\n",
      "Saved DataFrame as 'tehamDetOcc.csv'\n",
      "Saved DataFrame as 'triniDetOcc.csv'\n",
      "Saved DataFrame as 'tularDetOcc.csv'\n",
      "Saved DataFrame as 'tuoluDetOcc.csv'\n",
      "Saved DataFrame as 'ventuDetOcc.csv'\n",
      "Saved DataFrame as 'yoloDetOcc.csv'\n",
      "Saved DataFrame as 'yubaDetOcc.csv'\n",
      "Copied and removed 57 CSV files.\n",
      "Removed folder: output_folder\n",
      "Removed folder: cleaned_csv_files\n",
      "Removed folder: final_cleaned_data\n"
     ]
    }
   ],
   "source": [
    "# pull csv from aws\n",
    "bucket_name = 'ca-climate-index'\n",
    "aws_dir = '1_pull_data/governance/emergency_response/ca_employment_development_dept/edd_detailed_occupations_county/'\n",
    "\n",
    "pull_csv_or_xls_from_directory(bucket_name, aws_dir, search_zipped=False)\n",
    "\n",
    "# Define the output folder path\n",
    "output_folder = 'output_folder'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Find all CSV files in the current directory\n",
    "source_files = glob.glob('*.csv')\n",
    "\n",
    "# Iterate through the source files and copy only CSV files to the output folder\n",
    "for file in source_files:\n",
    "    # Construct the destination file path\n",
    "    destination_path = os.path.join(output_folder, os.path.basename(file))\n",
    "    \n",
    "    # Copy the file to the output folder\n",
    "    shutil.copyfile(file, destination_path)\n",
    "    \n",
    "    # Remove the original file\n",
    "    os.remove(file)\n",
    "\n",
    "print(f\"Copied and removed {len(source_files)} CSV files.\")\n",
    "\n",
    "# Define the list of variable names\n",
    "var_list = [\n",
    "    'governance_edd_responder_firefighter',\n",
    "    'governance_edd_responder_nurse',\n",
    "    'governance_edd_responder_parametics',\n",
    "    'governance_edd_responder_police'\n",
    "]\n",
    "\n",
    "# Iterate through each variable name in the list and call the combined function\n",
    "for varname in var_list:\n",
    "    combined_function('output_folder', 'cleaned_csv_files', 'final_cleaned_data', 'ca_emergency_employment.csv', export=False, varname='test')\n",
    "\n",
    "# Define the folders you want to remove\n",
    "folders_to_remove = ['output_folder', 'cleaned_csv_files', 'final_cleaned_data']\n",
    "\n",
    "# Remove each folder\n",
    "for folder in folders_to_remove:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        print(f\"Removed folder: {folder}\")\n",
    "    else:\n",
    "        print(f\"Folder not found: {folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
