{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script uploads manually downloaded data to AWS bucket for the California Climate Risk Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T22:03:42.520296Z",
     "iopub.status.busy": "2024-06-20T22:03:42.519105Z",
     "iopub.status.idle": "2024-06-20T22:03:43.116562Z",
     "shell.execute_reply": "2024-06-20T22:03:43.116094Z",
     "shell.execute_reply.started": "2024-06-20T22:03:42.520214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.expanduser('../../'))\n",
    "from scripts.utils.write_metadata import append_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T22:03:43.117700Z",
     "iopub.status.busy": "2024-06-20T22:03:43.117525Z",
     "iopub.status.idle": "2024-06-20T22:03:43.138669Z",
     "shell.execute_reply": "2024-06-20T22:03:43.138359Z",
     "shell.execute_reply.started": "2024-06-20T22:03:43.117684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set AWS credentials\n",
    "s3 = boto3.resource('s3')\n",
    "s3_cl = boto3.client('s3') # for lower-level processes\n",
    "bucket_name = 'ca-climate-index'\n",
    "raw_path = '1_pull_data/' # path to raw datafiles in AWS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T22:05:44.465570Z",
     "iopub.status.busy": "2024-06-20T22:05:44.464367Z",
     "iopub.status.idle": "2024-06-20T22:05:44.482916Z",
     "shell.execute_reply": "2024-06-20T22:05:44.481924Z",
     "shell.execute_reply.started": "2024-06-20T22:05:44.465503Z"
    }
   },
   "outputs": [],
   "source": [
    "def aws_datasource_dirs(domain, datasource):\n",
    "    \"\"\"Creates a dir in the respective domain dir, if not already available\"\"\"\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "    # path to folder in aws\n",
    "    datasource_dir = '{0}{1}/{2}/'.format(raw_path, domain, datasource)\n",
    "\n",
    "    # # check if folder already exists\n",
    "    dirs = []\n",
    "    for item in bucket.objects.filter(Prefix=raw_path+domain+'/'):\n",
    "        d = str(item.key)\n",
    "        dirs += [d]\n",
    "\n",
    "    if datasource_dir not in dirs:\n",
    "        print('Creating folder for {}'.format(datasource_dir))\n",
    "    #     bucket.put_object(Key=datasource_dir)\n",
    "\n",
    "    return datasource_dir\n",
    "\n",
    "@append_metadata\n",
    "def manual_to_aws(domain, datasource, loc, filename, export=False, varname=''):\n",
    "    \"\"\"\n",
    "    Uploads data that was manually downloaded to AWS bucket.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    domain: string\n",
    "        built_environment, governance, natural_systems, society_economy, climate_risk\n",
    "    datasource: string\n",
    "        Organization of datasource\n",
    "    loc: string\n",
    "        Local path to filename to upload\n",
    "    export: bool\n",
    "        If True, exports file to specified AWS bucket\n",
    "    \n",
    "    Script\n",
    "    ------\n",
    "    manual_pull_upload.ipynb\n",
    "\n",
    "    Note:\n",
    "    This function assumes users have configured the AWS CLI such that their access key / secret key pair are\n",
    "    stored in ~/.aws/credentials.\n",
    "    See https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html for guidance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract the filename from path\n",
    "    loc = loc.replace('\\\\', '/')\n",
    "    fname = loc.split('/')[-1]\n",
    "    path_to_save = aws_datasource_dirs(domain, datasource)\n",
    "    \n",
    "    if export == True:\n",
    "        # point to location of file(s) locally and upload to aws\n",
    "        try:\n",
    "            s3_cl.upload_file(\n",
    "                loc,\n",
    "                bucket_name,\n",
    "                aws_datasource_dirs(domain, datasource)+fname\n",
    "            )\n",
    "            print('{0} saved to {1}'.format(fname, path_to_save))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if export == False:\n",
    "        # Metadata update optionality\n",
    "        print(f'{filename} uploaded to AWS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling data pipeline file to obtain all variable names for metadata generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T22:05:48.086304Z",
     "iopub.status.busy": "2024-06-20T22:05:48.085565Z",
     "iopub.status.idle": "2024-06-20T22:05:48.111941Z",
     "shell.execute_reply": "2024-06-20T22:05:48.111301Z",
     "shell.execute_reply.started": "2024-06-20T22:05:48.086228Z"
    }
   },
   "outputs": [],
   "source": [
    "#ref_file = sys.path[-1]+'/metadata/Full Data Pipeline Notes - 1_ Pull.csv'\n",
    "ref_file = f'C:/Users/jespi/eagle/carb-climate-index-7/metadata/Full Data Pipeline Notes - 1_ Pull.csv'\n",
    "df = pd.read_csv(ref_file)\n",
    "# drop empty columns\n",
    "df = df.loc[:, df.columns.notna()]\n",
    "\n",
    "df = df.drop(columns=['Link','Unnamed: 15'])\n",
    "ref_df = df.fillna('N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate for variable and file name column entries\n",
    "* enter variables that used other pulling/uploading methods and exclude\n",
    "* return the isolated list with manual pulled files and variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>File Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>built_cpuc_internet</td>\n",
       "      <td>broadband_internet.gdb.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>built_hifld_radio_towers</td>\n",
       "      <td>FM_Transmission_Towers.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>built_hifld_cellular_towers</td>\n",
       "      <td>Cellular_Towers.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>built_hifld_microwave_towers</td>\n",
       "      <td>Microwave_Service_Towers.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>built_hifld_paging_towers</td>\n",
       "      <td>Paging_Transmission_Towers.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>society_acs_demographic_over_65</td>\n",
       "      <td>demographic_DP05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>society_acs_demographic_under_5</td>\n",
       "      <td>demographic_DP05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>society_acs_demographic_american_indian</td>\n",
       "      <td>demographic_DP05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>society_acs_health_insurance</td>\n",
       "      <td>health_insurance_B27010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>society_usda_food_accessibility</td>\n",
       "      <td>foodaccess2019.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Variable                       File Name\n",
       "0                        built_cpuc_internet      broadband_internet.gdb.zip\n",
       "1                   built_hifld_radio_towers      FM_Transmission_Towers.zip\n",
       "2                built_hifld_cellular_towers             Cellular_Towers.zip\n",
       "3               built_hifld_microwave_towers    Microwave_Service_Towers.zip\n",
       "4                  built_hifld_paging_towers  Paging_Transmission_Towers.zip\n",
       "..                                       ...                             ...\n",
       "97           society_acs_demographic_over_65            demographic_DP05.csv\n",
       "98           society_acs_demographic_under_5            demographic_DP05.csv\n",
       "99   society_acs_demographic_american_indian            demographic_DP05.csv\n",
       "100             society_acs_health_insurance     health_insurance_B27010.csv\n",
       "101          society_usda_food_accessibility              foodaccess2019.csv\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build list of variable names excluding 'N/A'\n",
    "# Include variable and file name columns\n",
    "variable_names = [(row['Variable'], row['File Name']) for _, row in df.iterrows() if row['Variable'] != 'N/A']\n",
    "\n",
    "# Define files that used other methods for pulling/uploading to be excluded\n",
    "skip_vars = ['natural_epa_air_quality',\n",
    "             'governance_edd_responder_firefighter',\n",
    "             'governance_edd_responder_nurse',\n",
    "             'governance_edd_responder_parametics',\n",
    "             'governance_edd_responder_police',\n",
    "             'climate_noaa_flood_fatalities',\n",
    "             'climate_usda_heat_crop_loss',\n",
    "             'climate_usda_heat_crop_cost']\n",
    "\n",
    "# Exclude variables from the list along with their corresponding file names\n",
    "included_vars = [(var, fname) for var, fname in variable_names if var not in skip_vars]\n",
    "\n",
    "# Store the remaining variable and corresponding file names to be run through the manual pull function\n",
    "included_vars_df = pd.DataFrame(included_vars, columns=['Variable', 'File Name'])\n",
    "\n",
    "included_vars_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating metadata for all metrics that were manually downloaded and uploaded to AWS\n",
    "* loop through each variable name not excluded and generate metadata, including filename\n",
    "* use var[1] for filenames and var[0] for varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T22:06:02.980936Z",
     "iopub.status.busy": "2024-06-20T22:06:02.980121Z",
     "iopub.status.idle": "2024-06-20T22:06:03.807247Z",
     "shell.execute_reply": "2024-06-20T22:06:03.806664Z",
     "shell.execute_reply.started": "2024-06-20T22:06:02.980872Z"
    }
   },
   "outputs": [],
   "source": [
    "for var in included_vars:\n",
    "    manual_to_aws(domain='all', datasource='all', loc='any', filename=var[1], export=False, varname=var[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
