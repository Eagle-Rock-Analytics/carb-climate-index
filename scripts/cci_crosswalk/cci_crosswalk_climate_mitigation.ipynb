{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T20:32:51.450966Z",
     "iopub.status.busy": "2024-03-12T20:32:51.450235Z",
     "iopub.status.idle": "2024-03-12T20:32:51.957914Z",
     "shell.execute_reply": "2024-03-12T20:32:51.957424Z",
     "shell.execute_reply.started": "2024-03-12T20:32:51.450931Z"
    }
   },
   "source": [
    "## California Climate Investment Projects Crosswalk\n",
    "This notebook analyses CCI funded programs and projects by connecting each CCI project with a primary associated climate risk, as defined by the California Climate Risk and Adaptation Index (Cal-CRAI). For the purposes of this project, the term 'climate risk' includes the following: \n",
    "* Extreme heat\n",
    "* Inland flooding\n",
    "* Sea level rise\n",
    "* Wildfire\n",
    "* Drought\n",
    "\n",
    "A sixth, non-climate risk categorization is provided for *greenhouse gas (GHG) mitigation*, as many CCI projects are funded to broadly reduce GHG efforts. \n",
    "\n",
    "Analysis Steps:\n",
    "- CCI data is scanned for common keywords associated with the defined climate risks via a dictionary to automatically assign a climate risk based on any keyword found in the project description, program description, sector, category, or action.\n",
    "- When a project is assigned more than one risk:\n",
    "   - If it is a defined climate risk and greenhouse gas mitigation, the project is assigned to the climate risk.\n",
    "   - If it is more than one climate risk (excluding greenhouse gas mitigation), keywords are assessed in other data columns (SECTOR, CATEGORY, ACTION) to identify if there is a primary risk. If not, the project is manually assessed and assigned a primary risk classification.  \n",
    "\n",
    "At present, the CCI data comprises 133,696 funded projects between 2015 and 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:46:57.713362Z",
     "iopub.status.busy": "2024-03-13T15:46:57.713114Z",
     "iopub.status.idle": "2024-03-13T15:46:58.165715Z",
     "shell.execute_reply": "2024-03-13T15:46:58.165236Z",
     "shell.execute_reply.started": "2024-03-13T15:46:57.713335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:46:58.167114Z",
     "iopub.status.busy": "2024-03-13T15:46:58.166962Z",
     "iopub.status.idle": "2024-03-13T15:47:09.689141Z",
     "shell.execute_reply": "2024-03-13T15:47:09.686875Z",
     "shell.execute_reply.started": "2024-03-13T15:46:58.167104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Bucket name and file paths\n",
    "bucket_name = 'ca-climate-index'\n",
    "directory = '0_map_data/crosswalk_data/CCI_Projects_Project_Category_Update_02142024.xlsm'\n",
    "\n",
    "print('Pulling file')\n",
    "s3_client.download_file(bucket_name, directory, 'CCI_Projects_Project_Category_Update_02142024.xlsm')\n",
    "print('File pulled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:47:09.692948Z",
     "iopub.status.busy": "2024-03-13T15:47:09.691316Z",
     "iopub.status.idle": "2024-03-13T15:48:51.855492Z",
     "shell.execute_reply": "2024-03-13T15:48:51.854947Z",
     "shell.execute_reply.started": "2024-03-13T15:47:09.692900Z"
    }
   },
   "outputs": [],
   "source": [
    "crosswalk_data = pd.read_excel('CCI_Projects_Project_Category_Update_02142024.xlsm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many rows within the original dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.856194Z",
     "iopub.status.busy": "2024-03-13T15:48:51.856045Z",
     "iopub.status.idle": "2024-03-13T15:48:51.858657Z",
     "shell.execute_reply": "2024-03-13T15:48:51.858240Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.856184Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print('Number of rows within dataset:', len(crosswalk_data))\n",
    "#display(crosswalk_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.859191Z",
     "iopub.status.busy": "2024-03-13T15:48:51.859088Z",
     "iopub.status.idle": "2024-03-13T15:48:51.863615Z",
     "shell.execute_reply": "2024-03-13T15:48:51.863338Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.859183Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of columns:', len(crosswalk_data.columns.tolist()))\n",
    "display(crosswalk_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting columns relevant to initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.864237Z",
     "iopub.status.busy": "2024-03-13T15:48:51.864134Z",
     "iopub.status.idle": "2024-03-13T15:48:51.866538Z",
     "shell.execute_reply": "2024-03-13T15:48:51.866233Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.864228Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_columns = [\n",
    "    'Program Name',\n",
    "    'Program Description',\n",
    "    'Sub Program Name',\n",
    "    'Project Type',\n",
    "    'Project Description',\n",
    "    'SECTOR',\n",
    "    'CATEGORY',\n",
    "    'ACTION',\n",
    "    'Census Tract',\n",
    "    'Total Project GHGReductions',\n",
    "    'Project Count'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.868512Z",
     "iopub.status.busy": "2024-03-13T15:48:51.868376Z",
     "iopub.status.idle": "2024-03-13T15:48:51.878224Z",
     "shell.execute_reply": "2024-03-13T15:48:51.877833Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.868502Z"
    }
   },
   "outputs": [],
   "source": [
    "data_of_interest = crosswalk_data[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.879040Z",
     "iopub.status.busy": "2024-03-13T15:48:51.878855Z",
     "iopub.status.idle": "2024-03-13T15:48:51.889992Z",
     "shell.execute_reply": "2024-03-13T15:48:51.889569Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.879019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns and rows\n",
    "# pd.set_option('display.max_columns', None)  # To display all columns\n",
    "# pd.set_option('display.max_rows', None)     # To display all rows\n",
    "\n",
    "# Now display data_of_interest\n",
    "display(data_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a climate risk dictionary to scan through data based on dictionary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.890831Z",
     "iopub.status.busy": "2024-03-13T15:48:51.890680Z",
     "iopub.status.idle": "2024-03-13T15:48:51.894701Z",
     "shell.execute_reply": "2024-03-13T15:48:51.894371Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.890820Z"
    }
   },
   "outputs": [],
   "source": [
    "climate_risk_dict = {\n",
    "    'wildfire mitigation': ['wildfire', 'prescribed fire', 'fire prevention', 'controlled burn', 'controlled_burning', \n",
    "                            'prescribed burn', 'prescribed burning' 'firefighting', 'reforest', 'reforestation', 'vegetation management', \n",
    "                            'roadside brushing', 'fuel break', 'fuel reduction', 'ignition', 'crown', 'fuel load', 'Fire and Forest Management'],\n",
    "    \n",
    "    'sea level rise mitigation': ['sea level rise', 'slr', 'seawall', 'seawalls', 'shoreline', 'wetland', 'mangrove', 'coastal','Restoration of riparian', 'sea-level rise'],\n",
    "    \n",
    "    'extreme heat mitigation': ['extreme heat', 'shade', 'shading', 'cooling center', 'cooling centers', 'heat-resistant', \n",
    "                                'heat resistant', 'heat reducing', 'heat-reducing', 'energy savings', 'urban forestry'],\n",
    "    \n",
    "    'drought mitigation': ['drought', 'irrigation', 'soil moisture', 'rainwater harvest', 'rainwater harvesting', 'water storage', \n",
    "                           'water allocation', 'water management', 'soil health', 'soil management', 'organic matter', 'water efficiency'],\n",
    "    \n",
    "    'inland flooding mitigation': ['flooding', 'runoff', 'inland flood', 'inland flooding', 'floodplain', 'flood proof', 'floodproofing', \n",
    "                                   'elevated flood', 'flood barrier', 'flood barriers', 'drainage', 'riparian', 'stormwater'],\n",
    "    \n",
    "    'greenhouse gas mitigation': ['ghg', 'GHG', 'greenhouse gas', 'emission', 'emissions', 'carbon sequestration', 'electrification', \n",
    "                                  'carbon capture', 'solar power', 'renewable energy', 'wind energy', 'hydroelectricity', 'geothermal energy', \n",
    "                                  'biomass energy', 'Energy-efficiency', 'carbon sequestering, low-carbon', 'clean vehicles']\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total and unique entries for each column? Will help decide which column to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.895378Z",
     "iopub.status.busy": "2024-03-13T15:48:51.895279Z",
     "iopub.status.idle": "2024-03-13T15:48:51.951519Z",
     "shell.execute_reply": "2024-03-13T15:48:51.951127Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.895369Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_entries(dataframe):\n",
    "    total_entries = dataframe.count()\n",
    "    unique_entries = dataframe.nunique()\n",
    "    return total_entries, unique_entries\n",
    "\n",
    "total_entries, unique_entries = count_entries(data_of_interest)\n",
    "print(\"Total entries per column:\")\n",
    "print(total_entries)\n",
    "print(\"\\nUnique entries per column:\")\n",
    "print(unique_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through 'Project Description' first as it has a large number of variation to capture many datasets, and makes most practical scense for filtering climate keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_climate_risk_column(df, keyword_dict, output_csv=None):\n",
    "    # Initialize new columns to store climate risk mitigation keywords, detected values, repeat counts, and total unique descriptions\n",
    "    df['Climate_Risk_Mitigation'] = ''\n",
    "    df['Detected_Climate_Risk_Mitigation_Keyword'] = ''\n",
    "    df['Repeat_Project_Description_Count'] = 0\n",
    "\n",
    "    # Initialize a counter for each keyword\n",
    "    keyword_counter = {keyword: 0 for keyword in keyword_dict}\n",
    "\n",
    "    # Create a dictionary to store the repeat count for each unique project description\n",
    "    description_counts = {}\n",
    "\n",
    "    # Create a dictionary to store the unique count for each keyword\n",
    "    unique_keyword_counts = {keyword: set() for keyword in keyword_dict}\n",
    "\n",
    "    # Iterate through each unique description\n",
    "    unique_descriptions = df['Project Description'].unique()\n",
    "    total_unique_descriptions = len(unique_descriptions)\n",
    "\n",
    "    for description in unique_descriptions:\n",
    "        # Find all rows with this description\n",
    "        description_rows = df[df['Project Description'] == description]\n",
    "        repeat_count = len(description_rows)\n",
    "        # Update the repeat count for this description\n",
    "        description_counts[description] = repeat_count\n",
    "\n",
    "        # Iterate through each row with this description\n",
    "        for index, row in description_rows.iterrows():\n",
    "            keywords_found = set()  # To store unique keywords found in each row\n",
    "            detected_values = []    # To store the detected values for each row\n",
    "            # Iterate through each keyword in the dictionary\n",
    "            for keyword, values in keyword_dict.items():\n",
    "                # Check if any value of the keyword is present in the description (case-insensitive)\n",
    "                detected = [val for val in values if val.lower() in description.lower()]\n",
    "                if detected:\n",
    "                    keywords_found.add(keyword)\n",
    "                    keyword_counter[keyword] += 1\n",
    "                    detected_values.extend(detected)\n",
    "                    # Add the description to unique count for this keyword\n",
    "                    unique_keyword_counts[keyword].add(description)\n",
    "\n",
    "            # If no keywords are found in Project Description, search Program Description\n",
    "            if not keywords_found:\n",
    "                program_description = row['Program Description']\n",
    "                if isinstance(program_description, str):  # Check if it's a string\n",
    "                    for keyword, values in keyword_dict.items():\n",
    "                        detected = [val for val in values if val.lower() in program_description.lower()]\n",
    "                        if detected:\n",
    "                            keywords_found.add(keyword)\n",
    "                            keyword_counter[keyword] += 1\n",
    "                            detected_values.extend(detected)\n",
    "\n",
    "            # Update the 'Climate_Risk_Mitigation' column with unique keywords found\n",
    "            df.at[index, 'Climate_Risk_Mitigation'] = ', '.join(keywords_found)\n",
    "            # Update the 'Detected_Values' column with detected values\n",
    "            df.at[index, 'Detected_Climate_Risk_Mitigation_Keyword'] = ', '.join(detected_values)\n",
    "            # Update the 'Repeat_Project_Description_Count' column with the repeat count for this description\n",
    "            df.at[index, 'Repeat_Project_Description_Count'] = repeat_count\n",
    "\n",
    "    # Print keyword counts\n",
    "    print(\"Keyword Counts:\")\n",
    "    for keyword, count in keyword_counter.items():\n",
    "        print(f\"{keyword}: {count}\")\n",
    "    print('')\n",
    "    # Print total unique descriptions count\n",
    "    print(f\"Total Unique Project Descriptions: {total_unique_descriptions}\")\n",
    "    print('')\n",
    "\n",
    "    # Save DataFrame as CSV if output_csv is provided\n",
    "    if output_csv:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"DataFrame saved as {output_csv}\")\n",
    "        print('')\n",
    "        # Initialize the S3 client\n",
    "        s3_client = boto3.client('s3')\n",
    "\n",
    "        # Bucket name and file paths\n",
    "        bucket_name = 'ca-climate-index'\n",
    "        directory = f'0_map_data/crosswalk_data/{output_csv}'\n",
    "        # Upload the CSV file to S3\n",
    "        print(f'Uploading {output_csv} to AWS')\n",
    "        with open(output_csv, 'rb') as file:\n",
    "            s3_client.upload_fileobj(file, bucket_name, directory)\n",
    "            print(f'Upload complete! File is in {directory}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing function on whole dataset, the function will:\n",
    "- loop through each 'Project Description' and look for words/phrases in our climate risk dictionary and append to keyword counter\n",
    "- total keywords are counted\n",
    "- number of unique 'Project Description' entries are counted\n",
    "    * rows that have identical project descriptions are counted as a single unique project description\n",
    "    * this helps reduce a bit of noise from some projects that have thousands of identical entries\n",
    "- makes two new columns: 'Repeat Project Description Count' and 'Detected Climate Risk Mitigation Keyword' to add more context and improve dictionary keywords\n",
    "\n",
    "#### The cell below runs the function but also adds a few things:\n",
    "- makes a data preview, just selecting relevant columns that were made and help interpret Project Description screening results\n",
    "- orders the data in decending order from the Repeat Project Description Count to show Project Descriptions with multiple entries first (make sure dictionary is properly assigning large entries with correct climate risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:48:51.960165Z",
     "iopub.status.busy": "2024-03-13T15:48:51.960074Z",
     "iopub.status.idle": "2024-03-13T15:49:27.209677Z",
     "shell.execute_reply": "2024-03-13T15:49:27.209322Z",
     "shell.execute_reply.started": "2024-03-13T15:48:51.960157Z"
    }
   },
   "outputs": [],
   "source": [
    "add_climate_risk_column(crosswalk_data, climate_risk_dict) #, 'climate_risk_attributed_crosswalk_data.csv')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "data_preview = crosswalk_data[['Project Description', 'Program Description', 'Repeat_Project_Description_Count', 'Detected_Climate_Risk_Mitigation_Keyword', 'Climate_Risk_Mitigation']]\n",
    "\n",
    "# Filter the DataFrame to show only rows with entries in the 'Climate_Risk_Mitigation' column\n",
    "data_preview_filtered = data_preview[data_preview['Climate_Risk_Mitigation'] != '']\n",
    "\n",
    "# Sort the DataFrame based on 'Repeat_Project_Description_Count' in descending order\n",
    "data_preview_filtered_sorted = data_preview_filtered.sort_values(by='Repeat_Project_Description_Count', ascending=False)\n",
    "\n",
    "# Drop duplicates based on both 'Repeat_Project_Description_Count' and 'Project Description' to keep only one row per unique combination\n",
    "data_preview_filtered_unique = data_preview_filtered_sorted.drop_duplicates(subset=['Repeat_Project_Description_Count', 'Project Description'])\n",
    "\n",
    "#display(data_preview_filtered_unique)\n",
    "display(data_preview_filtered_unique[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding in tests to understand where more than one risk is assigned\n",
    "- If 2 are provided, but one is GHG --> assign the category to the associated climate risk (i.e., \"greenhouse gas mitigation, sea level rise mitigation\" should end up as \"sea level rise mitigation\")\n",
    "   - 654 instances\n",
    "- If 2+ climate risks are assigned, need manual intervention to identify climate risk to be final assigned\n",
    "   - Strip out all instances of \"greenhouse gas mitigation\" to reduce # of manual intervention\n",
    "   - Identify the \"main\" or \"priority\" risk denoted in the project description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:27.210355Z",
     "iopub.status.busy": "2024-03-13T15:49:27.210256Z",
     "iopub.status.idle": "2024-03-13T15:49:27.253493Z",
     "shell.execute_reply": "2024-03-13T15:49:27.253150Z",
     "shell.execute_reply.started": "2024-03-13T15:49:27.210346Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_risk = crosswalk_data.loc[(crosswalk_data['Climate_Risk_Mitigation'].str.count(',') == 1)]\n",
    "print('Number of rows with multiple climate risk mitigation entries:', len(multi_risk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminating 'greenhouse gas mitigation' entries when other climate risks present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:27.254248Z",
     "iopub.status.busy": "2024-03-13T15:49:27.254066Z",
     "iopub.status.idle": "2024-03-13T15:49:27.404186Z",
     "shell.execute_reply": "2024-03-13T15:49:27.403849Z",
     "shell.execute_reply.started": "2024-03-13T15:49:27.254226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame to avoid modifying the original data\n",
    "crosswalk_data_copy = crosswalk_data.copy()\n",
    "\n",
    "# Filter rows containing 'greenhouse gas mitigation'\n",
    "multi_risk = crosswalk_data_copy.loc[(crosswalk_data_copy['Climate_Risk_Mitigation'].str.count(',') == 1) & \n",
    "                                (crosswalk_data_copy['Climate_Risk_Mitigation'].str.contains('greenhouse gas mitigation'))]\n",
    "\n",
    "# Replace 'greenhouse gas mitigation' with an empty string in the 'Climate_Risk_Mitigation' column\n",
    "crosswalk_data_copy.loc[multi_risk.index, 'Climate_Risk_Mitigation'] = multi_risk['Climate_Risk_Mitigation'].str.replace('greenhouse gas mitigation', '')\n",
    "\n",
    "# Remove any remaining commas\n",
    "crosswalk_data_copy.loc[multi_risk.index, 'Climate_Risk_Mitigation'] = crosswalk_data_copy.loc[multi_risk.index, 'Climate_Risk_Mitigation'].str.replace(',', '')\n",
    "\n",
    "# Clean-up view for easier access\n",
    "data_preview = multi_risk[['Project Description', 'Program Description', 'Repeat_Project_Description_Count', 'Detected_Climate_Risk_Mitigation_Keyword', 'Climate_Risk_Mitigation']]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(crosswalk_data)\n",
    "\n",
    "print('Number of rows with two climate risk mitigations, one being greenhouse gas mitigation:', len(data_preview))\n",
    "data_preview.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look through other entries with multiple detected climate risk mitigations (not selected for greenhouse gas mitigation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:27.404789Z",
     "iopub.status.busy": "2024-03-13T15:49:27.404691Z",
     "iopub.status.idle": "2024-03-13T15:49:27.448382Z",
     "shell.execute_reply": "2024-03-13T15:49:27.448048Z",
     "shell.execute_reply.started": "2024-03-13T15:49:27.404780Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many rows with multiple climate risk mitigations\n",
    "multi_risk = crosswalk_data_copy.loc[crosswalk_data_copy['Climate_Risk_Mitigation'].str.count(',') >= 1]\n",
    "data_preview = multi_risk[['Project Description', 'Program Description', 'CATEGORY', 'SECTOR', 'Repeat_Project_Description_Count', 'Detected_Climate_Risk_Mitigation_Keyword', 'Climate_Risk_Mitigation']]\n",
    "\n",
    "print('Number of rows with multiple climate risk entries, greenhouse gas mitigation not included:',len(data_preview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* further filter by running keyword dictionary filter across the 'CATEGORY' and 'SECTOR' columns\n",
    "* attribute just the newly found climate mitigation to the climate risk mitigation column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:27.449094Z",
     "iopub.status.busy": "2024-03-13T15:49:27.448983Z",
     "iopub.status.idle": "2024-03-13T15:49:33.017124Z",
     "shell.execute_reply": "2024-03-13T15:49:33.016649Z",
     "shell.execute_reply.started": "2024-03-13T15:49:27.449084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the climate risk dictionary to filter rows and update the DataFrame\n",
    "for mitigation_type, keywords in climate_risk_dict.items():\n",
    "    # Create a boolean mask to filter rows containing any of the keywords\n",
    "    mask = crosswalk_data_copy['CATEGORY'].str.contains('|'.join(keywords), case=False) | \\\n",
    "           crosswalk_data_copy['SECTOR'].str.contains('|'.join(keywords), case=False)\n",
    "    \n",
    "    # Filter rows based on the mask\n",
    "    filtered_rows = multi_risk[mask]\n",
    "    \n",
    "    # Update the 'Climate_Risk_Mitigation' column for the filtered rows\n",
    "    crosswalk_data_copy.loc[filtered_rows.index, 'Climate_Risk_Mitigation'] = mitigation_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:33.018120Z",
     "iopub.status.busy": "2024-03-13T15:49:33.017865Z",
     "iopub.status.idle": "2024-03-13T15:49:33.061545Z",
     "shell.execute_reply": "2024-03-13T15:49:33.061201Z",
     "shell.execute_reply.started": "2024-03-13T15:49:33.018108Z"
    }
   },
   "outputs": [],
   "source": [
    "# identify how many have 1+ risks assigned\n",
    "multi_risk = crosswalk_data_copy.loc[(crosswalk_data_copy['Climate_Risk_Mitigation'].str.count(',') >= 1)]\n",
    "data_preview = multi_risk[['Project Description', 'CATEGORY', 'SECTOR', 'Repeat_Project_Description_Count', 'Detected_Climate_Risk_Mitigation_Keyword', 'Climate_Risk_Mitigation']]\n",
    "print(len(data_preview))\n",
    "pd.set_option('display.max_rows', None)  \n",
    "#data_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually go through remaining sources that have multiple climate risk mitigation entries and didnt get further filtered with other column subsetting\n",
    "* get their row number, read the project description, and attribute the number to one of the climate risks\n",
    "* descriptions that seemingly address 2+ climate risk mitigations somewhat equally are give both risk mitigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:49:33.062568Z",
     "iopub.status.busy": "2024-03-13T15:49:33.062361Z",
     "iopub.status.idle": "2024-03-13T15:49:33.198443Z",
     "shell.execute_reply": "2024-03-13T15:49:33.198121Z",
     "shell.execute_reply.started": "2024-03-13T15:49:33.062552Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_crosswalk_data = crosswalk_data_copy.copy()\n",
    "\n",
    "# Define the rows to update based on the specified criteria\n",
    "sea_level_rise_rows = [15693, 62317, 74956, 89774, 75856, 116130, 116131, 116132, 116133, 112994]\n",
    "inland_flooding_rows = [60114, 60160, 74973, 75775, 89750, 89847, 89918, 91016,\n",
    "                        128903, 60253, 60265, 60292, 89679, 89716, 89732]\n",
    "drought_rows = [41034, 75775, 89918, 113037, 119459, 75188, 75107, 75814, 89828, 89846, 109976, \n",
    "                110600, 89819, 89798, 60110, 60113, 89677, 89680, 89715, 89793, 89794, 89881,\n",
    "                89985, 99696, 99708, 110954, 112998]\n",
    "wildfire_rows = [89455, 90049, 110288, 110291, 110294, 110297, 110298, 110303, 110305, 110333,\n",
    "                110337, 110339, 110347, 110361, 110368, 110372, 110447, 110466, 111867, 111874,\n",
    "                116515, 116520, 116541, 116543, 116548, 116582, 116583, 119503, 119516, 119518,\n",
    "                119554, 124581, 124582, 127999, 128030, 128063, 128083, 128144, 128262, 128280,\n",
    "                110373, 119509, 62321, 75163, 75165, 75166, 75167, 75168, 75169, 75170, 75171, \n",
    "                75172, 75173, 75174, 89705, 89894]\n",
    "extreme_heat_rows = [75775, 124736]\n",
    "greenhouse_gas_rows = [60117, 89961, 113029, 113036, 110373, 113030, 113026, 60109]\n",
    "\n",
    "# Create a dictionary mapping mitigation types to their corresponding rows\n",
    "mitigation_mapping = {\n",
    "    'sea level rise mitigation': sea_level_rise_rows,\n",
    "    'inland flooding mitigation': inland_flooding_rows,\n",
    "    'drought mitigation': drought_rows,\n",
    "    'wildfire mitigation': wildfire_rows,\n",
    "    'extreme heat mitigation': extreme_heat_rows,\n",
    "    'greenhouse gas mitigation': greenhouse_gas_rows,\n",
    "}\n",
    "\n",
    "# Iterate through the mitigation types and their corresponding rows\n",
    "for mitigation_type, rows_to_update in mitigation_mapping.items():\n",
    "    # Update the 'Climate_Risk_Mitigation' column for each row\n",
    "    for row_index in rows_to_update:\n",
    "        cleaned_crosswalk_data.loc[row_index, 'Climate_Risk_Mitigation'] = mitigation_type\n",
    "\n",
    "multi_risk = cleaned_crosswalk_data.loc[(cleaned_crosswalk_data['Climate_Risk_Mitigation'].str.count(',') >= 1)]\n",
    "# How many rows that have multiple climate risk mitigation entries\n",
    "print('Number of rows with multiple climate risk mitigations:', len(multi_risk))\n",
    "#multi_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count entries for each climate risk\n",
    "- remove blank space preceeding some entries\n",
    "- add 'NA' to blank entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty entries with 'NA' in the 'Climate_Risk_Mitigation' column\n",
    "cleaned_crosswalk_data['Climate_Risk_Mitigation'].replace('', 'NA', inplace=True)\n",
    "\n",
    "# Remove leading and trailing spaces from the entries in the 'Climate_Risk_Mitigation' column\n",
    "cleaned_crosswalk_data['Climate_Risk_Mitigation'] = cleaned_crosswalk_data['Climate_Risk_Mitigation'].str.strip()\n",
    "\n",
    "# Flatten the 'Climate_Risk_Mitigation' column into a single list of keywords\n",
    "all_keywords = cleaned_crosswalk_data['Climate_Risk_Mitigation'].explode().dropna()\n",
    "\n",
    "# Count the occurrences of each keyword\n",
    "keyword_counts = all_keywords.value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(keyword_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of columns used for analysis, create csv, and upload to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T15:50:06.475797Z",
     "iopub.status.busy": "2024-03-13T15:50:06.475676Z",
     "iopub.status.idle": "2024-03-13T15:51:23.891699Z",
     "shell.execute_reply": "2024-03-13T15:51:23.890534Z",
     "shell.execute_reply.started": "2024-03-13T15:50:06.475787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the specified columns from cleaned_crosswalk_data to create a new DataFrame\n",
    "final_crosswalk_data = cleaned_crosswalk_data.drop(columns=['Detected_Climate_Risk_Mitigation_Keyword', 'Repeat_Project_Description_Count'])\n",
    "\n",
    "output_csv = 'cci_projects_climate_risk_crosswalk.csv'\n",
    "\n",
    "final_crosswalk_data.to_csv(output_csv, index=False)\n",
    "print(f\"DataFrame saved as {output_csv}\")\n",
    "print('')\n",
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Bucket name and file paths\n",
    "bucket_name = 'ca-climate-index'\n",
    "directory = f'0_map_data/crosswalk_data/{output_csv}'\n",
    "# Upload the CSV file to S3\n",
    "print(f'Uploading {output_csv} to AWS')\n",
    "with open(output_csv, 'rb') as file:\n",
    "    s3_client.upload_fileobj(file, bucket_name, directory)\n",
    "    print(f'Upload complete! File is in {directory}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
